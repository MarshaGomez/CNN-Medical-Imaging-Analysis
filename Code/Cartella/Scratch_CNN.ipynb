{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Scratch_CNN_masses_vs_calc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarshaGomez/CNN-Medical-Imaging-Analysis/blob/main/Code/Scratch_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPQ8gkXb0NY0"
      },
      "source": [
        "# **Scratch CNN**\r\n",
        "---\r\n",
        "Classification model for discriminating between 2 classes: **masses and calcification**. *Ad-hoc CNN architecture*.\r\n",
        "\r\n",
        "**Students:**   *A. Schiavo - M. GÃ³mez - M. Daole*\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95hM4MvWjwfO",
        "outputId": "58cd6fa0-010b-47cd-bbc8-6e78fe85f350"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive', force_remount=True) \n",
        "\n",
        "_BASE_PATH = \"D:\\\\Documents\\\\Secondo Anno\\Computational Intelligence\\\\2021-20201211T231247Z-001\\\\[AIDE] Computational Intelligence and Deep Learning 2020-2021\\\\Final Project\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iduaD281krFD",
        "outputId": "fb4f65ef-0535-4b33-c9b8-9982c8e51a79"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import os \n",
        "\n",
        "base_path = os.path.join(_BASE_PATH, \"numpy data\")\n",
        "train_img_path = os.path.join(base_path, 'train_tensor.npy')\n",
        "train_label_path = os.path.join(base_path, 'train_labels.npy')\n",
        "test_img_path = os.path.join(base_path, 'public_test_tensor.npy')\n",
        "test_label_path = os.path.join(base_path, 'public_test_labels.npy')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-6-111c53afd996>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek9JMlmD6GsU"
      },
      "source": [
        "# Load Arrays from Numpy Files\r\n",
        "def load_training():\r\n",
        "  train_images = np.load(train_img_path)\r\n",
        "  train_labels = np.load(train_label_path)\r\n",
        "  test_images = np.load(test_img_path)\r\n",
        "  test_labels = np.load(test_label_path)\r\n",
        "\r\n",
        "  return train_images, train_labels, test_images, test_labels\r\n",
        "\r\n",
        "# Remove baseline samples\r\n",
        "def remove_baseline(tensor): \r\n",
        "  max_ind = int(len(tensor)/2)\r\n",
        "  indexes = [2*i + 1 for i in range(0, max_ind)]\r\n",
        "\r\n",
        "  return tensor[indexes]\r\n",
        "\r\n",
        "# Interchange the dataset index\r\n",
        "def shuffle_dataset(x, y):\r\n",
        "  indices = tf.range(start=0, limit=tf.shape(x)[0], dtype=tf.int32)\r\n",
        "  shuffled_indices = tf.random.shuffle(indices)\r\n",
        "\r\n",
        "  x = tf.gather(x, shuffled_indices)\r\n",
        "  y = tf.gather(y, shuffled_indices)\r\n",
        "\r\n",
        "  x = x.numpy()\r\n",
        "  y = y.numpy()\r\n",
        "\r\n",
        "  return x, y"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gowt9JUQ6sdj",
        "outputId": "c37dff5e-5663-4e47-89fa-a6f82ca325a5"
      },
      "source": [
        "# Get images and labels (test, train)\r\n",
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "# Get abnormalities only \r\n",
        "train_images = remove_baseline(train_images)\r\n",
        "train_labels = remove_baseline(train_labels)\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "\r\n",
        "# Suffle index (Previous dataset is ordered)\r\n",
        "train_images, train_labels = shuffle_dataset(train_images, train_labels)\r\n",
        "\r\n",
        "print(\"Train shape: \", train_images.shape)\r\n",
        "print(\"Test shape: \", test_images.shape)\r\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'load_training' is not defined",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-8-d272a0f15f4a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Get images and labels (test, train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_training\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get abnormalities only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_baseline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'load_training' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t4iLd0ExZho"
      },
      "source": [
        "## Data preprocessing\r\n",
        "\r\n",
        "Currently, our data sits on a drive as numpy files (**.npy**), so the steps for getting it into our network are roughly:\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2peY8SWutuA"
      },
      "source": [
        "# Unify masses and calcifications \r\n",
        "def labels_mapping(labels):\r\n",
        "  labels_local = np.zeros(shape=labels.shape, dtype=\"float32\")\r\n",
        "  idx = 0\r\n",
        "  for label in labels:\r\n",
        "    # masses\r\n",
        "    if label == 1 or label == 2:\r\n",
        "      labels_local[idx] = 0\r\n",
        "    # calcifications\r\n",
        "    else:\r\n",
        "      labels_local[idx] = 1\r\n",
        "    idx += 1\r\n",
        "\r\n",
        "  return labels_local\r\n",
        "\r\n",
        "labels = labels_mapping(train_labels)\r\n",
        "test_labels = labels_mapping(test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQJRM4Kc33Nf",
        "outputId": "3016a7b2-53eb-419c-846a-834a2c969427"
      },
      "source": [
        "#print(train_labels[2000])\r\n",
        "#print(labels[:10])\r\n",
        "print(train_images.shape)\r\n",
        "\r\n",
        "# verify values range: getting max value \r\n",
        "print(max([np.max(image) for image in train_images])) # max is 65'535 \r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2676, 150, 150)\n",
            "65535\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMdDBt9N3tBU",
        "outputId": "f2bf1451-d94d-455a-bb2e-0aa51317fc26"
      },
      "source": [
        "train_images = train_images.reshape(train_images.shape + (1,)) #(2676, 150, 150, 1)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,)) #(2676, 150, 150, 1)\r\n",
        "print(train_images.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2676, 150, 150, 1)\n",
            "(336, 150, 150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfMviUsBn-gX",
        "outputId": "250971ac-fbbc-46ae-95c6-fd08ff62894a"
      },
      "source": [
        "# split dataset into training and validation set 70-30\r\n",
        "train_images_split = train_images[:int(0.7*len(train_images))]\r\n",
        "valid_images_split = train_images[int(0.7*len(train_images)):]\r\n",
        "train_labels_split = labels[:int(0.7*len(labels))]\r\n",
        "valid_labels_split = labels[int(0.7*len(labels)):]\r\n",
        "\r\n",
        "print(train_images_split.shape)\r\n",
        "print(valid_images_split.shape)                                       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1873, 150, 150, 1)\n",
            "(803, 150, 150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvBDEjKBOiFV"
      },
      "source": [
        "BATCH_SIZE = 20\r\n",
        "EPOCHS = 100\r\n",
        "IMAGE_HEIGHT = 150\r\n",
        "IMAGE_WIDTH = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm9x-21nzEoE",
        "outputId": "535e2ed5-9429-4cf2-a9c9-951da8ad6e7e"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "# All images will be rescaled by 1./65535\r\n",
        "train_datagen = ImageDataGenerator(rescale=1./65535)\r\n",
        "valid_datagen = ImageDataGenerator(rescale=1./65535)\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./65535) \r\n",
        "\r\n",
        "for batch, labels_batch in train_datagen.flow(train_images, labels, batch_size=BATCH_SIZE):\r\n",
        "  print(batch.shape)\r\n",
        "  print(labels_batch.shape)\r\n",
        "  break\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 150, 150, 1)\n",
            "(20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi0ZJVf1vA31"
      },
      "source": [
        "## Defining CNN \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwQTeDPEvKql"
      },
      "source": [
        "from keras import layers\r\n",
        "from keras import optimizers \r\n",
        "from keras import models\r\n",
        "from keras import regularizers\r\n",
        "\r\n",
        "def build_model(loss_function, eval_metric):\r\n",
        "  model = models.Sequential()\r\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  #model.add(layers.Dense(512, activation='relu'))\r\n",
        "  #model.add(layers.Dropout(0.5))\r\n",
        "  model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\r\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "  model.compile(loss=loss_function,\r\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4), # lr = 0.0001\r\n",
        "              metrics=[\"acc\"]) \r\n",
        "  \r\n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZIemXxawWLm"
      },
      "source": [
        "## CNN Compilation:\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iumGmf1whk1",
        "outputId": "b3adf34e-3ca7-419d-ed9c-4df7d715e663"
      },
      "source": [
        "from keras import optimizers \r\n",
        "\r\n",
        "model = build_model(\"binary_crossentropy\", \"acc\")\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,452,545\n",
            "Trainable params: 3,452,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-V8cw96y_3Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "52e7aae5-9621-4bc4-801b-ee43cb44a58e"
      },
      "source": [
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "93/93 [==============================] - 3s 23ms/step - loss: 1.4376 - acc: 0.5409 - val_loss: 1.0533 - val_acc: 0.5300\n",
            "Epoch 2/100\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.9753 - acc: 0.5859 - val_loss: 0.7825 - val_acc: 0.7362\n",
            "Epoch 3/100\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.7565 - acc: 0.6739 - val_loss: 0.7703 - val_acc: 0.5537\n",
            "Epoch 4/100\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.6583 - acc: 0.7288 - val_loss: 0.6054 - val_acc: 0.7312\n",
            "Epoch 5/100\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.6084 - acc: 0.7647 - val_loss: 0.5904 - val_acc: 0.7337\n",
            "Epoch 6/100\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.5806 - acc: 0.7804 - val_loss: 0.5964 - val_acc: 0.7150\n",
            "Epoch 7/100\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.5829 - acc: 0.7713 - val_loss: 0.7992 - val_acc: 0.6112\n",
            "Epoch 8/100\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.5284 - acc: 0.8065 - val_loss: 0.4916 - val_acc: 0.8238\n",
            "Epoch 9/100\n",
            "66/93 [====================>.........] - ETA: 0s - loss: 0.4976 - acc: 0.8052"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-58915cb74fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                        shuffle=False),\n\u001b[0;32m---> 11\u001b[0;31m                     validation_steps=len(valid_labels_split) // BATCH_SIZE)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "nI8FjTjY4KIe",
        "outputId": "7fa826ef-fc3c-4898-d3b5-10f26ecca95f"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH89us9R_o_F",
        "outputId": "d2dd19c4-db2d-4686-9241-2da580546c09"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                       test_labels,\r\n",
        "                                                       batch_size=BATCH_SIZE,\r\n",
        "                                                       shuffle=False),\r\n",
        "                                     steps=len(test_images) // BATCH_SIZE\r\n",
        ")\r\n",
        "\r\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3748 - acc: 0.8438\n",
            "0.84375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2v_-h75Z3aZ"
      },
      "source": [
        "These plots are characteristic of **overfitting**. Training accuracy keeps increasing linearly while validation accuracy stalls around **82%**.\r\n",
        "\r\n",
        "##Fighting overfitting: 1. Data Augmentation:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ojvyPceIaunR",
        "outputId": "4af83cc1-fc3c-4892-b34c-c527b572ff7b"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\r\n",
        "\r\n",
        "# train data augmentation \r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./65535,\r\n",
        "    rotation_range=40,\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        "    shear_range=20,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True,\r\n",
        "    fill_mode='nearest')\r\n",
        "\r\n",
        "valid_datagen = ImageDataGenerator(rescale=1./65535)\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./65535) \r\n",
        "\r\n",
        "\"\"\"\r\n",
        "x = train_images[0].reshape((1,) + train_images[0].shape)\r\n",
        "\r\n",
        "i = 0\r\n",
        "for batch in train_datagen.flow(x, batch_size=1):\r\n",
        "  plt.figure(i)\r\n",
        "  imgplot = plt.imshow(image.array_to_img(batch[0]))\r\n",
        "  i += 1\r\n",
        "  if i % 4 == 0:\r\n",
        "    break\r\n",
        "\r\n",
        "plt.show()\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nx = train_images[0].reshape((1,) + train_images[0].shape)\\n\\ni = 0\\nfor batch in train_datagen.flow(x, batch_size=1):\\n  plt.figure(i)\\n  imgplot = plt.imshow(image.array_to_img(batch[0]))\\n  i += 1\\n  if i % 4 == 0:\\n    break\\n\\nplt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ex5WyyOwir4",
        "outputId": "7acba14c-8a52-45a5-cf13-a424952474db"
      },
      "source": [
        "model = build_model(\"binary_crossentropy\", \"acc\")\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_4 (Conv2D)            (None, 148, 148, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,452,545\n",
            "Trainable params: 3,452,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_LVsSUEj0Vx",
        "outputId": "3810f7a7-8a7f-4af0-a244-5ce76882c648"
      },
      "source": [
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "93/93 [==============================] - 5s 47ms/step - loss: 0.6919 - acc: 0.5495 - val_loss: 0.6902 - val_acc: 0.5362\n",
            "Epoch 2/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.6885 - acc: 0.5487 - val_loss: 0.6680 - val_acc: 0.5362\n",
            "Epoch 3/100\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.6726 - acc: 0.5703 - val_loss: 0.6351 - val_acc: 0.6925\n",
            "Epoch 4/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.6428 - acc: 0.6235 - val_loss: 0.5710 - val_acc: 0.7800\n",
            "Epoch 5/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.6074 - acc: 0.6837 - val_loss: 0.5163 - val_acc: 0.8175\n",
            "Epoch 6/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.5903 - acc: 0.7037 - val_loss: 0.5499 - val_acc: 0.6825\n",
            "Epoch 7/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.5758 - acc: 0.7104 - val_loss: 0.4816 - val_acc: 0.8075\n",
            "Epoch 8/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.5538 - acc: 0.7258 - val_loss: 0.4562 - val_acc: 0.8238\n",
            "Epoch 9/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.5506 - acc: 0.7255 - val_loss: 0.4971 - val_acc: 0.7750\n",
            "Epoch 10/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.5283 - acc: 0.7435 - val_loss: 0.4541 - val_acc: 0.7650\n",
            "Epoch 11/100\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.5554 - acc: 0.7332 - val_loss: 0.4341 - val_acc: 0.8250\n",
            "Epoch 12/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.5346 - acc: 0.7269 - val_loss: 0.4144 - val_acc: 0.8325\n",
            "Epoch 13/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.5471 - acc: 0.7280 - val_loss: 0.4407 - val_acc: 0.7738\n",
            "Epoch 14/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.5413 - acc: 0.7540 - val_loss: 0.4098 - val_acc: 0.8363\n",
            "Epoch 15/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.5100 - acc: 0.7533 - val_loss: 0.4403 - val_acc: 0.8087\n",
            "Epoch 16/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.5046 - acc: 0.7680 - val_loss: 0.4012 - val_acc: 0.8425\n",
            "Epoch 17/100\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.4861 - acc: 0.7707 - val_loss: 0.4628 - val_acc: 0.7437\n",
            "Epoch 18/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4927 - acc: 0.7602 - val_loss: 0.4411 - val_acc: 0.7912\n",
            "Epoch 19/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4836 - acc: 0.7671 - val_loss: 0.3778 - val_acc: 0.8587\n",
            "Epoch 20/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4973 - acc: 0.7653 - val_loss: 0.3717 - val_acc: 0.8487\n",
            "Epoch 21/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4752 - acc: 0.7752 - val_loss: 0.3755 - val_acc: 0.8537\n",
            "Epoch 22/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4724 - acc: 0.7944 - val_loss: 0.3994 - val_acc: 0.8525\n",
            "Epoch 23/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4523 - acc: 0.7945 - val_loss: 0.3787 - val_acc: 0.8400\n",
            "Epoch 24/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4666 - acc: 0.7953 - val_loss: 0.3696 - val_acc: 0.8487\n",
            "Epoch 25/100\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.4496 - acc: 0.7952 - val_loss: 0.3594 - val_acc: 0.8500\n",
            "Epoch 26/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4415 - acc: 0.8041 - val_loss: 0.4016 - val_acc: 0.8112\n",
            "Epoch 27/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4591 - acc: 0.7988 - val_loss: 0.3452 - val_acc: 0.8625\n",
            "Epoch 28/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4282 - acc: 0.8144 - val_loss: 0.3399 - val_acc: 0.8650\n",
            "Epoch 29/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.4513 - acc: 0.8102 - val_loss: 0.3677 - val_acc: 0.8575\n",
            "Epoch 30/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4622 - acc: 0.8021 - val_loss: 0.3657 - val_acc: 0.8413\n",
            "Epoch 31/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4360 - acc: 0.7950 - val_loss: 0.3771 - val_acc: 0.8637\n",
            "Epoch 32/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.4431 - acc: 0.8220 - val_loss: 0.3434 - val_acc: 0.8650\n",
            "Epoch 33/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4447 - acc: 0.7973 - val_loss: 0.3713 - val_acc: 0.8375\n",
            "Epoch 34/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4372 - acc: 0.8121 - val_loss: 0.3508 - val_acc: 0.8425\n",
            "Epoch 35/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4222 - acc: 0.8206 - val_loss: 0.3138 - val_acc: 0.8737\n",
            "Epoch 36/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4449 - acc: 0.8089 - val_loss: 0.3668 - val_acc: 0.8313\n",
            "Epoch 37/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4262 - acc: 0.8193 - val_loss: 0.3899 - val_acc: 0.8100\n",
            "Epoch 38/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4218 - acc: 0.8142 - val_loss: 0.3518 - val_acc: 0.8637\n",
            "Epoch 39/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4168 - acc: 0.8010 - val_loss: 0.3274 - val_acc: 0.8637\n",
            "Epoch 40/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3962 - acc: 0.8285 - val_loss: 0.3233 - val_acc: 0.8800\n",
            "Epoch 41/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4160 - acc: 0.8287 - val_loss: 0.3169 - val_acc: 0.8662\n",
            "Epoch 42/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4020 - acc: 0.8365 - val_loss: 0.3387 - val_acc: 0.8600\n",
            "Epoch 43/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4293 - acc: 0.8252 - val_loss: 0.4101 - val_acc: 0.8562\n",
            "Epoch 44/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4333 - acc: 0.8125 - val_loss: 0.3865 - val_acc: 0.8263\n",
            "Epoch 45/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4125 - acc: 0.8246 - val_loss: 0.3566 - val_acc: 0.8425\n",
            "Epoch 46/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.4229 - acc: 0.8173 - val_loss: 0.3366 - val_acc: 0.8788\n",
            "Epoch 47/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3922 - acc: 0.8300 - val_loss: 0.3093 - val_acc: 0.8662\n",
            "Epoch 48/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3830 - acc: 0.8366 - val_loss: 0.4671 - val_acc: 0.7788\n",
            "Epoch 49/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.4049 - acc: 0.8404 - val_loss: 0.3153 - val_acc: 0.8687\n",
            "Epoch 50/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3726 - acc: 0.8391 - val_loss: 0.4444 - val_acc: 0.8037\n",
            "Epoch 51/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3972 - acc: 0.8398 - val_loss: 0.3249 - val_acc: 0.8600\n",
            "Epoch 52/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3893 - acc: 0.8383 - val_loss: 0.3982 - val_acc: 0.8587\n",
            "Epoch 53/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3576 - acc: 0.8563 - val_loss: 0.3174 - val_acc: 0.8775\n",
            "Epoch 54/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3624 - acc: 0.8452 - val_loss: 0.3273 - val_acc: 0.8650\n",
            "Epoch 55/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3601 - acc: 0.8576 - val_loss: 0.3616 - val_acc: 0.8600\n",
            "Epoch 56/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3779 - acc: 0.8425 - val_loss: 0.3149 - val_acc: 0.8863\n",
            "Epoch 57/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3959 - acc: 0.8259 - val_loss: 0.2968 - val_acc: 0.8763\n",
            "Epoch 58/100\n",
            "93/93 [==============================] - 4s 46ms/step - loss: 0.3677 - acc: 0.8489 - val_loss: 0.2872 - val_acc: 0.8850\n",
            "Epoch 59/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3732 - acc: 0.8493 - val_loss: 0.2924 - val_acc: 0.8788\n",
            "Epoch 60/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3621 - acc: 0.8446 - val_loss: 0.2919 - val_acc: 0.8838\n",
            "Epoch 61/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3793 - acc: 0.8394 - val_loss: 0.2909 - val_acc: 0.8763\n",
            "Epoch 62/100\n",
            "93/93 [==============================] - 4s 46ms/step - loss: 0.3414 - acc: 0.8703 - val_loss: 0.2834 - val_acc: 0.8863\n",
            "Epoch 63/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3474 - acc: 0.8535 - val_loss: 0.3324 - val_acc: 0.8450\n",
            "Epoch 64/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3848 - acc: 0.8391 - val_loss: 0.2904 - val_acc: 0.8788\n",
            "Epoch 65/100\n",
            "93/93 [==============================] - 4s 46ms/step - loss: 0.3389 - acc: 0.8487 - val_loss: 0.3286 - val_acc: 0.8725\n",
            "Epoch 66/100\n",
            "93/93 [==============================] - 4s 47ms/step - loss: 0.3630 - acc: 0.8333 - val_loss: 0.2758 - val_acc: 0.8838\n",
            "Epoch 67/100\n",
            "93/93 [==============================] - 4s 47ms/step - loss: 0.3372 - acc: 0.8553 - val_loss: 0.3098 - val_acc: 0.8737\n",
            "Epoch 68/100\n",
            "93/93 [==============================] - 4s 46ms/step - loss: 0.3644 - acc: 0.8339 - val_loss: 0.2914 - val_acc: 0.8838\n",
            "Epoch 69/100\n",
            "93/93 [==============================] - 4s 46ms/step - loss: 0.3245 - acc: 0.8654 - val_loss: 0.2932 - val_acc: 0.8737\n",
            "Epoch 70/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3612 - acc: 0.8481 - val_loss: 0.2925 - val_acc: 0.8737\n",
            "Epoch 71/100\n",
            "93/93 [==============================] - 4s 43ms/step - loss: 0.3705 - acc: 0.8530 - val_loss: 0.2996 - val_acc: 0.8763\n",
            "Epoch 72/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3571 - acc: 0.8224 - val_loss: 0.3808 - val_acc: 0.8375\n",
            "Epoch 73/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3643 - acc: 0.8504 - val_loss: 0.3447 - val_acc: 0.8562\n",
            "Epoch 74/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3524 - acc: 0.8451 - val_loss: 0.2835 - val_acc: 0.8850\n",
            "Epoch 75/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3506 - acc: 0.8566 - val_loss: 0.2961 - val_acc: 0.8763\n",
            "Epoch 76/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3462 - acc: 0.8489 - val_loss: 0.3204 - val_acc: 0.8763\n",
            "Epoch 77/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3560 - acc: 0.8470 - val_loss: 0.2992 - val_acc: 0.8650\n",
            "Epoch 78/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3337 - acc: 0.8615 - val_loss: 0.3340 - val_acc: 0.8750\n",
            "Epoch 79/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3410 - acc: 0.8518 - val_loss: 0.3102 - val_acc: 0.8750\n",
            "Epoch 80/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3694 - acc: 0.8470 - val_loss: 0.2783 - val_acc: 0.8875\n",
            "Epoch 81/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3395 - acc: 0.8676 - val_loss: 0.2743 - val_acc: 0.8913\n",
            "Epoch 82/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3546 - acc: 0.8569 - val_loss: 0.2806 - val_acc: 0.8950\n",
            "Epoch 83/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3622 - acc: 0.8552 - val_loss: 0.4031 - val_acc: 0.8050\n",
            "Epoch 84/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3277 - acc: 0.8681 - val_loss: 0.2898 - val_acc: 0.8737\n",
            "Epoch 85/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3118 - acc: 0.8627 - val_loss: 0.3092 - val_acc: 0.8650\n",
            "Epoch 86/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3255 - acc: 0.8634 - val_loss: 0.2819 - val_acc: 0.8788\n",
            "Epoch 87/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3652 - acc: 0.8438 - val_loss: 0.2763 - val_acc: 0.8863\n",
            "Epoch 88/100\n",
            "93/93 [==============================] - 4s 45ms/step - loss: 0.3796 - acc: 0.8434 - val_loss: 0.2674 - val_acc: 0.8850\n",
            "Epoch 89/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3386 - acc: 0.8514 - val_loss: 0.2943 - val_acc: 0.8788\n",
            "Epoch 90/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3409 - acc: 0.8524 - val_loss: 0.2748 - val_acc: 0.8850\n",
            "Epoch 91/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.2973 - acc: 0.8723 - val_loss: 0.3109 - val_acc: 0.8800\n",
            "Epoch 92/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3595 - acc: 0.8514 - val_loss: 0.4027 - val_acc: 0.8188\n",
            "Epoch 93/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3299 - acc: 0.8647 - val_loss: 0.3648 - val_acc: 0.8562\n",
            "Epoch 94/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3522 - acc: 0.8456 - val_loss: 0.2667 - val_acc: 0.8950\n",
            "Epoch 95/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3219 - acc: 0.8711 - val_loss: 0.2822 - val_acc: 0.8863\n",
            "Epoch 96/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3248 - acc: 0.8636 - val_loss: 0.3847 - val_acc: 0.8338\n",
            "Epoch 97/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3549 - acc: 0.8591 - val_loss: 0.3018 - val_acc: 0.8850\n",
            "Epoch 98/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3275 - acc: 0.8656 - val_loss: 0.3295 - val_acc: 0.8600\n",
            "Epoch 99/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3155 - acc: 0.8674 - val_loss: 0.2691 - val_acc: 0.8888\n",
            "Epoch 100/100\n",
            "93/93 [==============================] - 4s 44ms/step - loss: 0.3209 - acc: 0.8660 - val_loss: 0.3047 - val_acc: 0.8888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "DNJBV5khoFEA",
        "outputId": "52ba77cc-c4fd-4cb2-bf69-8ba4fa9f6802"
      },
      "source": [
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYDj_8GquRRh",
        "outputId": "42ce8ffd-7e3a-469d-9609-00a6f49bacd6"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                       test_labels,\r\n",
        "                                                       batch_size=BATCH_SIZE,\r\n",
        "                                                       shuffle=False),\r\n",
        "                                     steps=len(test_images) // BATCH_SIZE\r\n",
        ")\r\n",
        "\r\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3545 - acc: 0.8500\n",
            "0.8500000238418579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrLD4fBGtc6k"
      },
      "source": [
        "##K-fold cross validation.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuiUODCT97Bq",
        "outputId": "b62fccc3-b8d2-4593-a91d-6cd45c6e0bac"
      },
      "source": [
        "print(train_images.shape)\r\n",
        "\r\n",
        "# train data augmentation for k-fold-cross-validation \r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./65535,\r\n",
        "    rotation_range=40,\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        "    shear_range=20,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True,\r\n",
        "    fill_mode='nearest')\r\n",
        "\r\n",
        "valid_datagen = ImageDataGenerator(rescale=1./65535)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2676, 150, 150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgdAZtZ1wMf3"
      },
      "source": [
        "def cross_validate(k, batch_size, num_epochs, dataset, targets, verbosity):\r\n",
        "  #10-Fold-Cross-Validation\r\n",
        "  num_val_samples = len(dataset) // k \r\n",
        "  validation_accuracies = []\r\n",
        "  validation_losses = []\r\n",
        "\r\n",
        "  for i in range(k):\r\n",
        "    # rigen augmented data \r\n",
        "    \r\n",
        "    print(\"processing fold #\", i)\r\n",
        "    validation_data = dataset[i * num_val_samples : (i + 1) * num_val_samples]\r\n",
        "    validation_labels = targets[i * num_val_samples : (i + 1) * num_val_samples]\r\n",
        "\r\n",
        "    partial_train_data = np.concatenate(\r\n",
        "        [dataset[:i * num_val_samples],\r\n",
        "        dataset[(i + 1) * num_val_samples:]], \r\n",
        "        axis=0)\r\n",
        "\r\n",
        "    partial_train_targets = np.concatenate(\r\n",
        "        [targets[:i * num_val_samples],\r\n",
        "        targets[(i + 1) * num_val_samples:]], \r\n",
        "        axis=0)\r\n",
        "\r\n",
        "    model = build_model(\"binary_crossentropy\", \"acc\")\r\n",
        "    \r\n",
        "    history = model.fit(train_datagen.flow(partial_train_data, \r\n",
        "                                          partial_train_targets,\r\n",
        "                                          batch_size=batch_size,\r\n",
        "                                          shuffle=False),\r\n",
        "                        epochs=num_epochs,\r\n",
        "                        steps_per_epoch=len(partial_train_data) // batch_size,\r\n",
        "                        verbose=verbosity)\r\n",
        "    \r\n",
        "    val_loss, val_acc = model.evaluate(valid_datagen.flow(validation_data,\r\n",
        "                                                          validation_labels,\r\n",
        "                                                          batch_size=batch_size,\r\n",
        "                                                          shuffle=False),\r\n",
        "                                      steps=len(validation_data) // batch_size)\r\n",
        "    \r\n",
        "    validation_accuracies.append(val_acc)\r\n",
        "    validation_losses.append(val_loss)\r\n",
        "\r\n",
        "  return validation_accuracies, validation_losses \r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdmZ-0dKuKlG"
      },
      "source": [
        "acc, loss = cross_validate(k=10, batch_size=20, num_epochs=100, dataset=train_images, targets=labels, verbosity=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3hbM3c6RxTq"
      },
      "source": [
        "print(len(acc))\r\n",
        "print(len(loss))\r\n",
        "print()\r\n",
        "print(np.mean(acc))\r\n",
        "print(np.mean(loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqQKeyLVTVi7"
      },
      "source": [
        "##Hyperparameters Tuning:\r\n",
        "\r\n",
        "*   add Dropout or L2 Regularization\r\n",
        "*   varying of convolutional layers: [3, 5, 7]\r\n",
        "*   varying # of units per layer:\r\n",
        "\r\n",
        "| Layer  | Unit per Layer  |  \r\n",
        "|---|---|\r\n",
        "| 1  | [32,32,64,128]  |\r\n",
        "| 2  | [32,64,128,128]  |\r\n",
        "| 3  | [32,64,128,256]  |\r\n",
        "| 4  | [64,64,128,256]  |\r\n",
        "\r\n",
        "*   change Optimizer (try Adam)\r\n",
        "*   varying batch size: [20, 32, 64, 128]\r\n",
        "*   varying learning rate \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQgC-nrCTcn7"
      },
      "source": [
        "from keras import optimizers\r\n",
        "import time\r\n",
        "\r\n",
        "#Parameters Grid \r\n",
        "dropout_regularization = True                                               # grafico comparativo: sembra leggermente meglio con Dropout\r\n",
        "batch_sizes = [20, 32, 64, 128]                                             # 4 \r\n",
        "layers_number = 4                                                           # 1\r\n",
        "units_per_layer_dict = [[32,64,128,128], [32,64,128,256]]                   # 2\r\n",
        "learning_rates = [1e-2, 1e-3, 1e-4]                                         # 3\r\n",
        "opts = [optimizers.RMSprop(lr=1e-4), optimizers.Adam(learning_rate=0.01)]   # 2\r\n",
        "num_epochs = 100\r\n",
        "num_folds = 5\r\n",
        "\r\n",
        "def build_custom_model(layers_number, units_per_layer, batch_size, dropout, optimizer):\r\n",
        "  model = models.Sequential()\r\n",
        "\r\n",
        "  for i in range(layers_number):\r\n",
        "    if i == 0:  #first layer\r\n",
        "      model.add(layers.Conv2D(units_per_layer[i], (3, 3), activation='relu', input_shape=(150, 150, 1)))\r\n",
        "      model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "    else:\r\n",
        "      model.add(layers.Conv2D(units_per_layer[i], (3, 3), activation='relu'))\r\n",
        "      model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(512, activation='relu'))\r\n",
        "  \r\n",
        "  if dropout:\r\n",
        "    model.add(layers.Dropout(0.5))\r\n",
        "\r\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "  #model.summary()\r\n",
        "  model.compile(loss=\"binary_crossentropy\",\r\n",
        "              optimizer=optimizer,\r\n",
        "              metrics=[\"acc\"]) \r\n",
        "  \r\n",
        "  return model \r\n",
        "\r\n",
        "def CNN_tuning(num_folds, batch_sizes, num_epochs, layers_number, units_per_layer_dict, learning_rates, dropout_reg, dataset, targets):\r\n",
        "  lr = learning_rates[2]  \r\n",
        "  opts = [optimizers.RMSprop(lr=lr), optimizers.Adam(learning_rate=lr)]\r\n",
        "\r\n",
        "  with open(file_path, 'w') as f:\r\n",
        "    header = \"batch_size, num_epochs, units_per_layer, optimizer, learning_rate, mean_val_acc, std_acc, mean_val_loss, std_loss, num_folds \\n\"\r\n",
        "    f.write(header)\r\n",
        "\r\n",
        "  for batch_size in batch_sizes:                # 4\r\n",
        "    for opt in opts:                            # 2\r\n",
        "      for values_set in units_per_layer_dict:   # 2\r\n",
        "        #build CNN model \r\n",
        "        model = build_custom_model(layers_number, values_set, batch_size, dropout_reg, opt)\r\n",
        "\r\n",
        "        if \"RMSprop\" in str(opt):\r\n",
        "          str_opt = \"RMSprop\"  \r\n",
        "        else:\r\n",
        "          str_opt = \"Adam\"\r\n",
        "\r\n",
        "        #print info \r\n",
        "        print(\"-----------------------------------------------------\")\r\n",
        "        print(\"batch_size: \\t\", batch_size)\r\n",
        "        print(\"num_epochs: \\t\", num_epochs)\r\n",
        "        print(\"units_per_layer:\", str(values_set).replace(\",\", \" \"))\r\n",
        "        print(\"optimizer: \\t\", str_opt)\r\n",
        "        print(\"learning_rate: \\t\", str(lr))\r\n",
        "        print(\"num_folds CV: \\t\", num_folds)\r\n",
        "        print(\"-----------------------------------------------------\")\r\n",
        "\r\n",
        "        #cross validate CNN model\r\n",
        "        val_acc, val_loss = cross_validate(num_folds, batch_size, num_epochs, dataset, targets, 1)\r\n",
        "\r\n",
        "        #save results on csv file \r\n",
        "        with open(file_path, 'a') as f:\r\n",
        "          row = str(batch_size) + \",\" \\\r\n",
        "              + str(num_epochs) + \",\" \\\r\n",
        "              + str(values_set).replace(\",\", \" \") + \",\" \\\r\n",
        "              + str_opt + \",\" \\\r\n",
        "              + str(lr) + \",\" \\\r\n",
        "              + str(round(np.mean(val_acc), 4)) + \",\" \\\r\n",
        "              + str(\"%0.4f (+/- %0.4f)\" % (np.mean(val_acc)), np.std(val_acc) * 2)) + \",\" \\\r\n",
        "              + str(round(np.std(val_acc))\r\n",
        "              + str(round(np.mean(val_acc), 4)) + \",\" \\\r\n",
        "              + str(num_folds) + \"\\n\"\r\n",
        "          f.write(row)\r\n",
        "          \r\n",
        "          time.sleep(20)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0fLlSfbPOWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043b3827-d5b7-4b10-f7d9-6dbdd68c3125"
      },
      "source": [
        "file_path = \"/content/gdrive/My Drive/Colab_Notebooks/CIDL/DL Project/results_proof.csv\"\r\n",
        "\r\n",
        "CNN_tuning(num_folds, batch_sizes, num_epochs, layers_number, units_per_layer_dict, learning_rates, dropout_regularization, train_images, labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4360 - acc: 0.8109\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4302 - acc: 0.8300\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4370 - acc: 0.8232\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3966 - acc: 0.8390\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4327 - acc: 0.8237\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4476 - acc: 0.8314\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4471 - acc: 0.8234\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4125 - acc: 0.8230\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4353 - acc: 0.8346\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4168 - acc: 0.8255\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3976 - acc: 0.8371\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4397 - acc: 0.8248\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4261 - acc: 0.8344\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4155 - acc: 0.8382\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4170 - acc: 0.8407\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4275 - acc: 0.8268\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4184 - acc: 0.8261\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4265 - acc: 0.8218\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3749 - acc: 0.8530\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4412 - acc: 0.8217\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3980 - acc: 0.8406\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4128 - acc: 0.8282\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4070 - acc: 0.8289\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4177 - acc: 0.8230\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3750 - acc: 0.8498\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3860 - acc: 0.8520\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4028 - acc: 0.8392\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4033 - acc: 0.8315\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4186 - acc: 0.8338\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3998 - acc: 0.8427\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3564 - acc: 0.8584\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4045 - acc: 0.8435\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3949 - acc: 0.8486\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3926 - acc: 0.8430\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3913 - acc: 0.8415\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3814 - acc: 0.8527\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4090 - acc: 0.8308\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4079 - acc: 0.8313\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3929 - acc: 0.8394\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3733 - acc: 0.8587\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3872 - acc: 0.8449\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3912 - acc: 0.8449\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3925 - acc: 0.8452\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3949 - acc: 0.8402\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3729 - acc: 0.8568\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3926 - acc: 0.8322\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3789 - acc: 0.8615\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3678 - acc: 0.8492\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3832 - acc: 0.8504\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3810 - acc: 0.8465\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3501 - acc: 0.8615\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3777 - acc: 0.8557\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4151 - acc: 0.8332\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3517 - acc: 0.8622\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3926 - acc: 0.8314\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3543 - acc: 0.8525\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3882 - acc: 0.8411\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3551 - acc: 0.8567\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3700 - acc: 0.8459\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3651 - acc: 0.8537\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.2825 - acc: 0.8885\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 39ms/step - loss: 1.4087 - acc: 0.5406\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.9035 - acc: 0.5557\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.7355 - acc: 0.6141\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6870 - acc: 0.6272\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6478 - acc: 0.7040\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6094 - acc: 0.7310\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5900 - acc: 0.7093\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6013 - acc: 0.7298\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5888 - acc: 0.7230\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5681 - acc: 0.7224\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5740 - acc: 0.7386\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5794 - acc: 0.7244\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5586 - acc: 0.7462\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5689 - acc: 0.7377\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5324 - acc: 0.7559\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5481 - acc: 0.7541\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5457 - acc: 0.7495\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5242 - acc: 0.7710\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5358 - acc: 0.7567\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5377 - acc: 0.7519\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5289 - acc: 0.7719\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5212 - acc: 0.7629\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5128 - acc: 0.7760\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5064 - acc: 0.7922\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4992 - acc: 0.7801\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4988 - acc: 0.7780\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4915 - acc: 0.7850\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4783 - acc: 0.7891\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5083 - acc: 0.7726\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4920 - acc: 0.7811\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4865 - acc: 0.7916\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4646 - acc: 0.8060\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4748 - acc: 0.7986\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4670 - acc: 0.8158\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4928 - acc: 0.7873\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4733 - acc: 0.7812\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4554 - acc: 0.8070\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4580 - acc: 0.8058\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4911 - acc: 0.7995\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4783 - acc: 0.7976\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4657 - acc: 0.7946\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4863 - acc: 0.7831\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4587 - acc: 0.8093\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4429 - acc: 0.8202\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4541 - acc: 0.8063\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4315 - acc: 0.8265\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4572 - acc: 0.7965\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4823 - acc: 0.7992\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4269 - acc: 0.8178\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4645 - acc: 0.8092\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4217 - acc: 0.8218\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4454 - acc: 0.8241\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4236 - acc: 0.8220\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4429 - acc: 0.8101\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4264 - acc: 0.8283\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4390 - acc: 0.8221\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4118 - acc: 0.8319\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4061 - acc: 0.8442\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4548 - acc: 0.7996\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4330 - acc: 0.8193\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4202 - acc: 0.8397\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4300 - acc: 0.8261\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4150 - acc: 0.8361\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3894 - acc: 0.8380\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4034 - acc: 0.8427\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4290 - acc: 0.8309\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4290 - acc: 0.8274\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4211 - acc: 0.8230\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3930 - acc: 0.8542\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3809 - acc: 0.8379\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4143 - acc: 0.8271\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4060 - acc: 0.8272\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3858 - acc: 0.8477\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4011 - acc: 0.8357\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3975 - acc: 0.8324\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4070 - acc: 0.8416\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3858 - acc: 0.8420\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4021 - acc: 0.8398\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4020 - acc: 0.8447\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3587 - acc: 0.8697\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3935 - acc: 0.8600\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3783 - acc: 0.8515\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3888 - acc: 0.8534\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4014 - acc: 0.8327\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3733 - acc: 0.8434\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3829 - acc: 0.8534\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3721 - acc: 0.8564\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3587 - acc: 0.8496\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3783 - acc: 0.8509\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3981 - acc: 0.8269\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3686 - acc: 0.8664\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3789 - acc: 0.8550\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3642 - acc: 0.8621\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3710 - acc: 0.8422\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3693 - acc: 0.8480\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3797 - acc: 0.8560\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3752 - acc: 0.8635\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3930 - acc: 0.8287\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3840 - acc: 0.8505\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3666 - acc: 0.8625\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.4380 - acc: 0.8154\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 38ms/step - loss: 1.4175 - acc: 0.5255\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.9185 - acc: 0.5616\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.7536 - acc: 0.5827\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6847 - acc: 0.6307\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6154 - acc: 0.7223\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6009 - acc: 0.7312\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5842 - acc: 0.7359\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5729 - acc: 0.7604\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5850 - acc: 0.7388\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5892 - acc: 0.7316\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5449 - acc: 0.7752\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5339 - acc: 0.7580\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5416 - acc: 0.7568\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5587 - acc: 0.7559\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5457 - acc: 0.7603\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5266 - acc: 0.7657\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5098 - acc: 0.7644\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5251 - acc: 0.7646\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5112 - acc: 0.7705\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4899 - acc: 0.7853\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5134 - acc: 0.7821\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5038 - acc: 0.7858\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5144 - acc: 0.7769\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4823 - acc: 0.7823\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5016 - acc: 0.7777\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4810 - acc: 0.8043\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4959 - acc: 0.7920\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4910 - acc: 0.7997\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4946 - acc: 0.7894\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4649 - acc: 0.8210\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4728 - acc: 0.7999\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4662 - acc: 0.8063\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4469 - acc: 0.8234\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4533 - acc: 0.8164\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4783 - acc: 0.8085\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4411 - acc: 0.8201\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4692 - acc: 0.8044\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4276 - acc: 0.8107\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4390 - acc: 0.8151\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4414 - acc: 0.8256\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4283 - acc: 0.8261\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4315 - acc: 0.8303\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4062 - acc: 0.8373\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4167 - acc: 0.8310\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4407 - acc: 0.8137\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3930 - acc: 0.8380\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4427 - acc: 0.8203\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4141 - acc: 0.8322\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4244 - acc: 0.8258\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3822 - acc: 0.8522\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4046 - acc: 0.8252\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4120 - acc: 0.8191\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4110 - acc: 0.8310\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4346 - acc: 0.8169\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4115 - acc: 0.8401\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4284 - acc: 0.8212\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4088 - acc: 0.8308\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4032 - acc: 0.8539\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3988 - acc: 0.8449\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3889 - acc: 0.8432\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4255 - acc: 0.8124\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3984 - acc: 0.8438\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3876 - acc: 0.8539\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3814 - acc: 0.8384\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3839 - acc: 0.8503\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4257 - acc: 0.8190\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4101 - acc: 0.8290\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4147 - acc: 0.8299\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3887 - acc: 0.8486\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3897 - acc: 0.8434\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4022 - acc: 0.8305\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4006 - acc: 0.8426\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3956 - acc: 0.8354\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3836 - acc: 0.8448\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3705 - acc: 0.8486\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3778 - acc: 0.8445\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3666 - acc: 0.8525\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3955 - acc: 0.8425\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3543 - acc: 0.8591\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3941 - acc: 0.8310\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3750 - acc: 0.8461\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3774 - acc: 0.8428\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3842 - acc: 0.8419\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3497 - acc: 0.8684\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3589 - acc: 0.8483\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3715 - acc: 0.8514\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3682 - acc: 0.8520\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3436 - acc: 0.8655\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3591 - acc: 0.8647\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3611 - acc: 0.8599\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3747 - acc: 0.8556\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3481 - acc: 0.8685\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3652 - acc: 0.8444\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3612 - acc: 0.8751\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3684 - acc: 0.8513\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3199 - acc: 0.8787\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3576 - acc: 0.8631\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3435 - acc: 0.8658\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3605 - acc: 0.8566\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3452 - acc: 0.8544\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.3153 - acc: 0.8692\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 39ms/step - loss: 1.4070 - acc: 0.5463\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.9125 - acc: 0.5487\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.7403 - acc: 0.5878\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6746 - acc: 0.6797\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6182 - acc: 0.7448\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5993 - acc: 0.7610\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6168 - acc: 0.7232\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5777 - acc: 0.7528\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5641 - acc: 0.7556\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5746 - acc: 0.7505\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5663 - acc: 0.7473\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5673 - acc: 0.7413\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5527 - acc: 0.7461\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5590 - acc: 0.7592\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5275 - acc: 0.7751\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5610 - acc: 0.7564\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5601 - acc: 0.7604\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5313 - acc: 0.7604\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5425 - acc: 0.7601\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5077 - acc: 0.7663\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5158 - acc: 0.7755\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4867 - acc: 0.7878\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4924 - acc: 0.7923\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4993 - acc: 0.7753\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5002 - acc: 0.7885\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4861 - acc: 0.8014\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4918 - acc: 0.8007\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4544 - acc: 0.8124\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4915 - acc: 0.7889\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4629 - acc: 0.8178\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4387 - acc: 0.8390\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4734 - acc: 0.7990\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4433 - acc: 0.8184\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4400 - acc: 0.8240\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4313 - acc: 0.8174\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4561 - acc: 0.8078\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4549 - acc: 0.8162\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4179 - acc: 0.8385\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4369 - acc: 0.8232\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4457 - acc: 0.8296\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4361 - acc: 0.8294\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4263 - acc: 0.8186\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4279 - acc: 0.8306\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4195 - acc: 0.8300\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3997 - acc: 0.8374\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4134 - acc: 0.8446\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4083 - acc: 0.8498\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4197 - acc: 0.8442\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4298 - acc: 0.8315\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4323 - acc: 0.8370\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4170 - acc: 0.8293\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4309 - acc: 0.8343\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4067 - acc: 0.8348\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4111 - acc: 0.8338\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3924 - acc: 0.8435\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3949 - acc: 0.8528\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4006 - acc: 0.8285\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3934 - acc: 0.8444\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3949 - acc: 0.8417\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4024 - acc: 0.8248\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3937 - acc: 0.8495\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3948 - acc: 0.8446\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3850 - acc: 0.8422\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3709 - acc: 0.8566\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3785 - acc: 0.8494\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3966 - acc: 0.8527\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3942 - acc: 0.8411\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3605 - acc: 0.8651\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3695 - acc: 0.8607\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3853 - acc: 0.8493\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3631 - acc: 0.8646\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3538 - acc: 0.8617\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3836 - acc: 0.8387\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3503 - acc: 0.8516\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3690 - acc: 0.8509\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3738 - acc: 0.8529\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3629 - acc: 0.8525\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3647 - acc: 0.8613\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3730 - acc: 0.8400\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3637 - acc: 0.8601\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3444 - acc: 0.8663\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3455 - acc: 0.8704\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3517 - acc: 0.8614\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3525 - acc: 0.8612\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3396 - acc: 0.8694\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3408 - acc: 0.8649\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3582 - acc: 0.8587\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3386 - acc: 0.8645\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3522 - acc: 0.8659\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3147 - acc: 0.8833\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3360 - acc: 0.8695\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3685 - acc: 0.8487\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3505 - acc: 0.8551\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3479 - acc: 0.8625\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3336 - acc: 0.8605\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3509 - acc: 0.8634\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3672 - acc: 0.8514\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3472 - acc: 0.8530\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3407 - acc: 0.8638\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3380 - acc: 0.8764\n",
            "26/26 [==============================] - 0s 6ms/step - loss: 0.3211 - acc: 0.8635\n",
            "processing fold # 4\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 39ms/step - loss: 1.4074 - acc: 0.5532\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.9117 - acc: 0.5549\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.7327 - acc: 0.5927\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6478 - acc: 0.7065\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6214 - acc: 0.7257\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.6113 - acc: 0.7299\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5849 - acc: 0.7231\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5870 - acc: 0.7270\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5688 - acc: 0.7513\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6028 - acc: 0.7365\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5389 - acc: 0.7685\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5551 - acc: 0.7609\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5269 - acc: 0.7681\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5480 - acc: 0.7624\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5583 - acc: 0.7351\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5521 - acc: 0.7691\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5119 - acc: 0.7842\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5138 - acc: 0.7649\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5183 - acc: 0.7586\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5570 - acc: 0.7399\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5078 - acc: 0.7997\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5017 - acc: 0.7857\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4947 - acc: 0.7913\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4880 - acc: 0.7980\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5070 - acc: 0.7781\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5038 - acc: 0.7684\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.5140 - acc: 0.7850\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4950 - acc: 0.7973\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4960 - acc: 0.7858\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4906 - acc: 0.7759\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4710 - acc: 0.7918\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4556 - acc: 0.8002\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4553 - acc: 0.8170\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4636 - acc: 0.8063\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4847 - acc: 0.7936\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4885 - acc: 0.7932\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4318 - acc: 0.8259\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4749 - acc: 0.7968\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4391 - acc: 0.8187\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4919 - acc: 0.7913\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4372 - acc: 0.8237\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4566 - acc: 0.8074\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4354 - acc: 0.8221\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4557 - acc: 0.8152\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4691 - acc: 0.7860\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4398 - acc: 0.8357\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4295 - acc: 0.8380\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4536 - acc: 0.8121\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4157 - acc: 0.8349\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4372 - acc: 0.8205\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4386 - acc: 0.8134\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4205 - acc: 0.8360\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4165 - acc: 0.8464\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3916 - acc: 0.8343\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4246 - acc: 0.8316\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4282 - acc: 0.8253\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4198 - acc: 0.8366\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4028 - acc: 0.8332\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3885 - acc: 0.8499\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4151 - acc: 0.8297\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3975 - acc: 0.8450\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4171 - acc: 0.8262\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4322 - acc: 0.8316\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4030 - acc: 0.8394\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4007 - acc: 0.8482\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3551 - acc: 0.8645\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3815 - acc: 0.8571\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3992 - acc: 0.8383\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3910 - acc: 0.8423\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.4019 - acc: 0.8362\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3789 - acc: 0.8446\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3807 - acc: 0.8489\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3787 - acc: 0.8435\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3887 - acc: 0.8469\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3595 - acc: 0.8583\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3861 - acc: 0.8406\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4057 - acc: 0.8229\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3970 - acc: 0.8446\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3919 - acc: 0.8332\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3721 - acc: 0.8573\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3753 - acc: 0.8501\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3701 - acc: 0.8493\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3827 - acc: 0.8525\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3985 - acc: 0.8383\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3607 - acc: 0.8541\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3523 - acc: 0.8640\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3833 - acc: 0.8406\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3443 - acc: 0.8675\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3639 - acc: 0.8471\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3690 - acc: 0.8514\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3659 - acc: 0.8468\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3619 - acc: 0.8611\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3779 - acc: 0.8501\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3598 - acc: 0.8556\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3679 - acc: 0.8545\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3384 - acc: 0.8695\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3715 - acc: 0.8562\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 4s 38ms/step - loss: 0.3642 - acc: 0.8487\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3667 - acc: 0.8555\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3475 - acc: 0.8638\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.2994 - acc: 0.8827\n",
            "-----------------------------------------------------\n",
            "batch_size: \t 32\n",
            "num_epochs: \t 100\n",
            "units_per_layer: [32  64  128  128]\n",
            "optimizer: \t RMSprop\n",
            "learning_rate: \t 0.0001\n",
            "num_folds CV: \t 5\n",
            "-----------------------------------------------------\n",
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 62ms/step - loss: 1.4751 - acc: 0.5468\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.0890 - acc: 0.5468\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.8654 - acc: 0.5763\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.7574 - acc: 0.6242\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7090 - acc: 0.6334\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6675 - acc: 0.6957\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6398 - acc: 0.7148\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6029 - acc: 0.7509\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5957 - acc: 0.7405\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5760 - acc: 0.7528\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6152 - acc: 0.7161\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5784 - acc: 0.7311\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5882 - acc: 0.7514\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5673 - acc: 0.7515\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5769 - acc: 0.7564\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5659 - acc: 0.7568\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5693 - acc: 0.7342\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5614 - acc: 0.7583\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5465 - acc: 0.7701\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5532 - acc: 0.7489\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5547 - acc: 0.7554\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5416 - acc: 0.7657\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5620 - acc: 0.7533\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5360 - acc: 0.7715\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5177 - acc: 0.7676\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5394 - acc: 0.7745\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5186 - acc: 0.7712\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5442 - acc: 0.7649\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5318 - acc: 0.7431\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5294 - acc: 0.7718\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5435 - acc: 0.7595\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5425 - acc: 0.7554\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5093 - acc: 0.7693\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5263 - acc: 0.7722\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5187 - acc: 0.7745\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5013 - acc: 0.7976\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5328 - acc: 0.7746\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5090 - acc: 0.7613\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5004 - acc: 0.7743\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4868 - acc: 0.7744\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5275 - acc: 0.7763\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4650 - acc: 0.8044\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4999 - acc: 0.7844\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4848 - acc: 0.7881\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5038 - acc: 0.7759\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4907 - acc: 0.7802\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4762 - acc: 0.8160\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4682 - acc: 0.8090\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4739 - acc: 0.8005\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4751 - acc: 0.7908\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4532 - acc: 0.8146\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4840 - acc: 0.7922\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4348 - acc: 0.8238\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4532 - acc: 0.8118\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4401 - acc: 0.8167\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4713 - acc: 0.8043\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4786 - acc: 0.7847\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4717 - acc: 0.8032\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4567 - acc: 0.8074\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4412 - acc: 0.8146\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4754 - acc: 0.7867\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4233 - acc: 0.8392\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4376 - acc: 0.8280\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4349 - acc: 0.8301\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4477 - acc: 0.8261\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4341 - acc: 0.8203\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4349 - acc: 0.8223\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4318 - acc: 0.8239\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4422 - acc: 0.8059\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4264 - acc: 0.8121\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4545 - acc: 0.8098\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4205 - acc: 0.8216\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4600 - acc: 0.7835\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3986 - acc: 0.8384\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4439 - acc: 0.8016\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4219 - acc: 0.8279\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4444 - acc: 0.8070\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4557 - acc: 0.8152\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4237 - acc: 0.8216\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4366 - acc: 0.8228\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4122 - acc: 0.8230\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4150 - acc: 0.8241\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4411 - acc: 0.8102\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4056 - acc: 0.8417\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4274 - acc: 0.8320\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4082 - acc: 0.8320\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3978 - acc: 0.8281\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3847 - acc: 0.8436\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3826 - acc: 0.8427\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4515 - acc: 0.7994\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3997 - acc: 0.8257\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4157 - acc: 0.8279\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4269 - acc: 0.8286\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3921 - acc: 0.8372\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4216 - acc: 0.8195\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4086 - acc: 0.8422\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4030 - acc: 0.8390\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4005 - acc: 0.8494\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4175 - acc: 0.8171\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4066 - acc: 0.8319\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3824 - acc: 0.8398\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 62ms/step - loss: 1.4798 - acc: 0.5344\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 1.0942 - acc: 0.5641\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8748 - acc: 0.5925\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7660 - acc: 0.6270\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7165 - acc: 0.6532\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6679 - acc: 0.7046\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6440 - acc: 0.7371\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6334 - acc: 0.7231\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5887 - acc: 0.7541\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6083 - acc: 0.7600\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5940 - acc: 0.7533\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5736 - acc: 0.7533\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5740 - acc: 0.7597\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5576 - acc: 0.7627\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5968 - acc: 0.7406\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5538 - acc: 0.7684\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5734 - acc: 0.7475\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5599 - acc: 0.7567\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5479 - acc: 0.7635\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5404 - acc: 0.7566\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5507 - acc: 0.7669\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5429 - acc: 0.7645\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5365 - acc: 0.7766\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5380 - acc: 0.7674\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5055 - acc: 0.7882\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5128 - acc: 0.7873\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5109 - acc: 0.7781\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5070 - acc: 0.7852\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4932 - acc: 0.7954\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5235 - acc: 0.7851\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4946 - acc: 0.7939\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4971 - acc: 0.7816\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5032 - acc: 0.7935\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4966 - acc: 0.7864\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4570 - acc: 0.8079\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4958 - acc: 0.7894\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5206 - acc: 0.7677\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4944 - acc: 0.7771\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4841 - acc: 0.7988\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4520 - acc: 0.8078\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4858 - acc: 0.7954\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4613 - acc: 0.7869\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4751 - acc: 0.8060\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4443 - acc: 0.8256\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4521 - acc: 0.8238\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4438 - acc: 0.8291\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4599 - acc: 0.8114\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4755 - acc: 0.8040\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4260 - acc: 0.8308\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4551 - acc: 0.7979\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4435 - acc: 0.8194\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4690 - acc: 0.8026\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4434 - acc: 0.8145\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4481 - acc: 0.8124\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4259 - acc: 0.8266\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4286 - acc: 0.8269\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4269 - acc: 0.8330\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4226 - acc: 0.8162\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4070 - acc: 0.8449\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3936 - acc: 0.8364\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4024 - acc: 0.8464\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4559 - acc: 0.8160\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4092 - acc: 0.8336\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4098 - acc: 0.8375\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4104 - acc: 0.8257\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4238 - acc: 0.8171\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4028 - acc: 0.8299\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4289 - acc: 0.8168\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4118 - acc: 0.8434\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4267 - acc: 0.8316\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4126 - acc: 0.8413\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4105 - acc: 0.8422\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3903 - acc: 0.8505\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3914 - acc: 0.8628\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3828 - acc: 0.8501\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3845 - acc: 0.8425\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4114 - acc: 0.8239\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4085 - acc: 0.8341\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3895 - acc: 0.8454\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4020 - acc: 0.8461\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3763 - acc: 0.8446\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3989 - acc: 0.8259\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3727 - acc: 0.8533\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3842 - acc: 0.8323\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3684 - acc: 0.8501\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4047 - acc: 0.8254\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3737 - acc: 0.8524\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3909 - acc: 0.8506\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3542 - acc: 0.8582\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4025 - acc: 0.8532\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3626 - acc: 0.8598\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4013 - acc: 0.8487\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3896 - acc: 0.8429\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3900 - acc: 0.8393\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4027 - acc: 0.8407\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3628 - acc: 0.8487\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3655 - acc: 0.8583\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3741 - acc: 0.8520\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3984 - acc: 0.8304\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3504 - acc: 0.8674\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3186 - acc: 0.8789\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 61ms/step - loss: 1.4747 - acc: 0.5278\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 1.0771 - acc: 0.5552\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.8504 - acc: 0.5747\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7454 - acc: 0.5949\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6857 - acc: 0.6532\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6479 - acc: 0.7011\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6166 - acc: 0.7270\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6224 - acc: 0.7266\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5854 - acc: 0.7454\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5672 - acc: 0.7527\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5591 - acc: 0.7540\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5695 - acc: 0.7363\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5724 - acc: 0.7515\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5445 - acc: 0.7625\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5466 - acc: 0.7549\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5372 - acc: 0.7705\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5452 - acc: 0.7552\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5480 - acc: 0.7667\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5460 - acc: 0.7603\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5356 - acc: 0.7607\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5233 - acc: 0.7824\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5236 - acc: 0.7797\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5175 - acc: 0.7725\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5102 - acc: 0.7836\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5081 - acc: 0.7684\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5096 - acc: 0.7695\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4871 - acc: 0.7980\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5004 - acc: 0.7875\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4964 - acc: 0.8037\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5140 - acc: 0.7948\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4893 - acc: 0.7954\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5271 - acc: 0.7762\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4816 - acc: 0.7981\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4903 - acc: 0.8024\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4780 - acc: 0.7868\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4622 - acc: 0.8280\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4627 - acc: 0.8101\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4807 - acc: 0.8027\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4666 - acc: 0.8076\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4748 - acc: 0.8057\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4829 - acc: 0.7901\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4628 - acc: 0.8069\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4657 - acc: 0.8028\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4672 - acc: 0.7922\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4385 - acc: 0.8144\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4572 - acc: 0.8193\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4425 - acc: 0.8278\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4535 - acc: 0.8060\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4474 - acc: 0.8115\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4243 - acc: 0.8335\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4057 - acc: 0.8565\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4333 - acc: 0.8235\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4412 - acc: 0.7987\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4424 - acc: 0.8290\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4259 - acc: 0.8307\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4135 - acc: 0.8407\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4263 - acc: 0.8218\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4306 - acc: 0.8194\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4359 - acc: 0.8146\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4331 - acc: 0.8189\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4290 - acc: 0.8354\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4037 - acc: 0.8414\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4091 - acc: 0.8230\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4084 - acc: 0.8352\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4072 - acc: 0.8449\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4133 - acc: 0.8303\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4007 - acc: 0.8455\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4073 - acc: 0.8330\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4083 - acc: 0.8187\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4011 - acc: 0.8350\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3907 - acc: 0.8323\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3866 - acc: 0.8510\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4072 - acc: 0.8417\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3987 - acc: 0.8466\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3958 - acc: 0.8447\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4218 - acc: 0.8189\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3649 - acc: 0.8559\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4000 - acc: 0.8322\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3922 - acc: 0.8395\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4202 - acc: 0.8233\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3666 - acc: 0.8573\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3874 - acc: 0.8373\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4169 - acc: 0.8214\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3935 - acc: 0.8335\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3887 - acc: 0.8407\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3978 - acc: 0.8457\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3921 - acc: 0.8413\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3937 - acc: 0.8286\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3913 - acc: 0.8286\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.3930 - acc: 0.8457\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4108 - acc: 0.8284\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3723 - acc: 0.8495\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3959 - acc: 0.8514\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3890 - acc: 0.8382\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3887 - acc: 0.8367\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3719 - acc: 0.8433\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4066 - acc: 0.8345\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3773 - acc: 0.8413\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3837 - acc: 0.8540\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3805 - acc: 0.8493\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3708 - acc: 0.8418\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 60ms/step - loss: 1.4716 - acc: 0.5404\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.0839 - acc: 0.5495\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.8639 - acc: 0.5809\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7496 - acc: 0.6307\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6829 - acc: 0.6847\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6190 - acc: 0.7361\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6220 - acc: 0.7279\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6207 - acc: 0.7207\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6180 - acc: 0.7252\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5690 - acc: 0.7529\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5981 - acc: 0.7345\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5766 - acc: 0.7470\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5691 - acc: 0.7570\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5677 - acc: 0.7508\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5792 - acc: 0.7523\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5483 - acc: 0.7610\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5594 - acc: 0.7591\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5530 - acc: 0.7539\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5474 - acc: 0.7509\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5208 - acc: 0.7802\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5407 - acc: 0.7919\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5564 - acc: 0.7683\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5197 - acc: 0.7900\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5279 - acc: 0.7603\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5250 - acc: 0.7787\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5170 - acc: 0.7744\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5157 - acc: 0.7786\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5013 - acc: 0.7936\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4953 - acc: 0.7927\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5045 - acc: 0.7756\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4935 - acc: 0.7948\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5096 - acc: 0.7665\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4906 - acc: 0.8021\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4887 - acc: 0.7806\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4778 - acc: 0.7854\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4835 - acc: 0.7985\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4586 - acc: 0.8076\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4638 - acc: 0.8125\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4708 - acc: 0.7911\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4828 - acc: 0.8030\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4780 - acc: 0.7928\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4800 - acc: 0.8000\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4912 - acc: 0.7968\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4704 - acc: 0.7933\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4660 - acc: 0.8064\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4788 - acc: 0.7963\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4771 - acc: 0.8134\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4286 - acc: 0.8252\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4573 - acc: 0.8060\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4413 - acc: 0.8148\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4607 - acc: 0.8130\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4265 - acc: 0.8257\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4352 - acc: 0.8211\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4348 - acc: 0.8173\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4078 - acc: 0.8316\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4434 - acc: 0.8232\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4389 - acc: 0.8228\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4450 - acc: 0.8101\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4249 - acc: 0.8393\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4343 - acc: 0.8263\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4407 - acc: 0.8264\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3901 - acc: 0.8397\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4331 - acc: 0.8303\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4166 - acc: 0.8395\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4209 - acc: 0.8297\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4220 - acc: 0.8256\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4133 - acc: 0.8237\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4028 - acc: 0.8306\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4116 - acc: 0.8334\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3817 - acc: 0.8578\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4050 - acc: 0.8322\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4000 - acc: 0.8333\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3972 - acc: 0.8489\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4129 - acc: 0.8340\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3666 - acc: 0.8570\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3926 - acc: 0.8512\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3560 - acc: 0.8626\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3873 - acc: 0.8426\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3914 - acc: 0.8485\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3836 - acc: 0.8388\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4091 - acc: 0.8294\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3785 - acc: 0.8507\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3645 - acc: 0.8561\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3925 - acc: 0.8408\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3869 - acc: 0.8402\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3708 - acc: 0.8479\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3772 - acc: 0.8436\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4027 - acc: 0.8286\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3814 - acc: 0.8493\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3752 - acc: 0.8488\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3563 - acc: 0.8533\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3823 - acc: 0.8386\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3759 - acc: 0.8436\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3740 - acc: 0.8438\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3724 - acc: 0.8504\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3772 - acc: 0.8562\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3654 - acc: 0.8568\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3777 - acc: 0.8428\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3599 - acc: 0.8612\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3540 - acc: 0.8595\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3142 - acc: 0.8672\n",
            "processing fold # 4\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 61ms/step - loss: 1.4827 - acc: 0.5308\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.0971 - acc: 0.5513\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.8788 - acc: 0.5722\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.7687 - acc: 0.5772\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6956 - acc: 0.6519\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.7120 - acc: 0.6872\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6410 - acc: 0.7075\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6096 - acc: 0.7199\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6083 - acc: 0.7438\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6079 - acc: 0.7259\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5837 - acc: 0.7430\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5671 - acc: 0.7605\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5944 - acc: 0.7332\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5712 - acc: 0.7503\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5663 - acc: 0.7383\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5758 - acc: 0.7496\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5610 - acc: 0.7546\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5758 - acc: 0.7362\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5575 - acc: 0.7641\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5523 - acc: 0.7469\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5359 - acc: 0.7657\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5555 - acc: 0.7520\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5440 - acc: 0.7435\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5583 - acc: 0.7535\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5199 - acc: 0.7636\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5469 - acc: 0.7559\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5143 - acc: 0.7755\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5134 - acc: 0.7860\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5040 - acc: 0.7970\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5211 - acc: 0.7920\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5649 - acc: 0.7754\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5135 - acc: 0.7920\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4781 - acc: 0.8016\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5086 - acc: 0.7816\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5017 - acc: 0.7822\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5160 - acc: 0.7780\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4999 - acc: 0.7855\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4858 - acc: 0.7917\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4963 - acc: 0.7874\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5005 - acc: 0.7947\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5265 - acc: 0.7607\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4688 - acc: 0.8080\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4840 - acc: 0.8014\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4735 - acc: 0.7988\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5111 - acc: 0.7908\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4669 - acc: 0.8039\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4998 - acc: 0.7758\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4424 - acc: 0.8305\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4812 - acc: 0.7981\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4508 - acc: 0.8205\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4689 - acc: 0.8089\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4662 - acc: 0.8118\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4597 - acc: 0.8145\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4370 - acc: 0.8340\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4451 - acc: 0.8218\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4472 - acc: 0.8147\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4404 - acc: 0.8137\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4552 - acc: 0.8008\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4507 - acc: 0.8211\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4606 - acc: 0.8021\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4466 - acc: 0.8150\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4177 - acc: 0.8446\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4425 - acc: 0.8263\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4366 - acc: 0.8180\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4381 - acc: 0.8230\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4332 - acc: 0.8202\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4305 - acc: 0.8245\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4642 - acc: 0.8108\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4471 - acc: 0.8188\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4360 - acc: 0.8230\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4076 - acc: 0.8346\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4340 - acc: 0.8318\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4049 - acc: 0.8339\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4357 - acc: 0.8381\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4310 - acc: 0.8270\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4274 - acc: 0.8321\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4233 - acc: 0.8330\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4235 - acc: 0.8249\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4092 - acc: 0.8455\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4229 - acc: 0.8230\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4346 - acc: 0.8172\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4062 - acc: 0.8369\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3932 - acc: 0.8539\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4069 - acc: 0.8376\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4069 - acc: 0.8349\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4211 - acc: 0.8381\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4010 - acc: 0.8428\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4081 - acc: 0.8316\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4137 - acc: 0.8238\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4029 - acc: 0.8314\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4119 - acc: 0.8487\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3922 - acc: 0.8407\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4075 - acc: 0.8398\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3959 - acc: 0.8450\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3730 - acc: 0.8503\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4079 - acc: 0.8419\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3763 - acc: 0.8510\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4012 - acc: 0.8357\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4199 - acc: 0.8355\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4007 - acc: 0.8473\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3580 - acc: 0.8945\n",
            "-----------------------------------------------------\n",
            "batch_size: \t 32\n",
            "num_epochs: \t 100\n",
            "units_per_layer: [32  64  128  256]\n",
            "optimizer: \t RMSprop\n",
            "learning_rate: \t 0.0001\n",
            "num_folds CV: \t 5\n",
            "-----------------------------------------------------\n",
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 61ms/step - loss: 1.4881 - acc: 0.5119\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.1008 - acc: 0.5157\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.8740 - acc: 0.5548\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.7562 - acc: 0.5997\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.7049 - acc: 0.6367\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6657 - acc: 0.6875\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6340 - acc: 0.6964\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6139 - acc: 0.7237\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5937 - acc: 0.7497\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6029 - acc: 0.7294\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5833 - acc: 0.7446\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5754 - acc: 0.7503\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5778 - acc: 0.7535\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5590 - acc: 0.7426\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5515 - acc: 0.7626\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5758 - acc: 0.7372\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5605 - acc: 0.7541\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5411 - acc: 0.7610\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5616 - acc: 0.7441\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5293 - acc: 0.7730\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5456 - acc: 0.7668\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5611 - acc: 0.7667\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5433 - acc: 0.7582\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5537 - acc: 0.7488\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5346 - acc: 0.7583\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5520 - acc: 0.7681\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5117 - acc: 0.7627\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5174 - acc: 0.7652\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5349 - acc: 0.7692\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5158 - acc: 0.7677\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5114 - acc: 0.7749\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4926 - acc: 0.7787\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5223 - acc: 0.7795\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5025 - acc: 0.7690\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5060 - acc: 0.7858\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4777 - acc: 0.7904\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5006 - acc: 0.7720\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4921 - acc: 0.7872\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5189 - acc: 0.7753\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5050 - acc: 0.7866\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4881 - acc: 0.7746\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5055 - acc: 0.7898\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4667 - acc: 0.8032\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4971 - acc: 0.7845\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4398 - acc: 0.8167\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4764 - acc: 0.7964\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4525 - acc: 0.8117\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4951 - acc: 0.7836\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4511 - acc: 0.8083\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4708 - acc: 0.8082\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4420 - acc: 0.8045\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4637 - acc: 0.8126\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4468 - acc: 0.8009\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4716 - acc: 0.7915\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4632 - acc: 0.8046\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4441 - acc: 0.8129\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4527 - acc: 0.8061\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4783 - acc: 0.8042\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4673 - acc: 0.8035\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4452 - acc: 0.8178\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4814 - acc: 0.8163\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4261 - acc: 0.8322\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4643 - acc: 0.8085\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4264 - acc: 0.8353\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4393 - acc: 0.8239\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4232 - acc: 0.8280\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4537 - acc: 0.8259\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4482 - acc: 0.8141\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4208 - acc: 0.8254\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4409 - acc: 0.8108\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4354 - acc: 0.8139\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4228 - acc: 0.8308\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4260 - acc: 0.8272\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4367 - acc: 0.8130\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4114 - acc: 0.8268\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4135 - acc: 0.8244\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3988 - acc: 0.8325\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4233 - acc: 0.8266\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4006 - acc: 0.8340\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4079 - acc: 0.8273\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4033 - acc: 0.8318\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4436 - acc: 0.8175\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3978 - acc: 0.8332\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4139 - acc: 0.8381\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4185 - acc: 0.8283\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4288 - acc: 0.8289\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4140 - acc: 0.8334\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3827 - acc: 0.8306\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4042 - acc: 0.8484\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3978 - acc: 0.8409\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4242 - acc: 0.8284\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4174 - acc: 0.8136\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4019 - acc: 0.8351\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4070 - acc: 0.8401\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3743 - acc: 0.8494\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4113 - acc: 0.8386\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3747 - acc: 0.8444\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3897 - acc: 0.8440\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3660 - acc: 0.8590\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3787 - acc: 0.8399\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3250 - acc: 0.8672\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 61ms/step - loss: 1.4718 - acc: 0.5046\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.0804 - acc: 0.5577\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.8610 - acc: 0.5736\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.7575 - acc: 0.5886\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7016 - acc: 0.6709\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6497 - acc: 0.6989\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6421 - acc: 0.7101\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6325 - acc: 0.6994\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6140 - acc: 0.7269\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6022 - acc: 0.7212\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6071 - acc: 0.7467\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5770 - acc: 0.7398\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6000 - acc: 0.7217\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5731 - acc: 0.7488\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5694 - acc: 0.7394\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5560 - acc: 0.7587\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5510 - acc: 0.7657\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5576 - acc: 0.7470\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5697 - acc: 0.7444\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5363 - acc: 0.7726\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5606 - acc: 0.7432\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5554 - acc: 0.7561\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5324 - acc: 0.7510\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5118 - acc: 0.7813\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5137 - acc: 0.7938\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5172 - acc: 0.7746\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5110 - acc: 0.7838\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5105 - acc: 0.7867\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5341 - acc: 0.7606\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5193 - acc: 0.7739\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5203 - acc: 0.7621\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5072 - acc: 0.7774\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4918 - acc: 0.7911\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5143 - acc: 0.7692\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5009 - acc: 0.7660\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4773 - acc: 0.8012\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5025 - acc: 0.7736\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4806 - acc: 0.8013\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4921 - acc: 0.7871\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4838 - acc: 0.8029\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4879 - acc: 0.7961\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4707 - acc: 0.7994\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4540 - acc: 0.8047\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4751 - acc: 0.7870\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4675 - acc: 0.7975\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4732 - acc: 0.8031\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4637 - acc: 0.8028\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4351 - acc: 0.8111\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4487 - acc: 0.8135\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4327 - acc: 0.8174\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4471 - acc: 0.8186\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4285 - acc: 0.8214\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4727 - acc: 0.8002\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4290 - acc: 0.8268\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4689 - acc: 0.7966\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4473 - acc: 0.8180\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4028 - acc: 0.8448\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4264 - acc: 0.8254\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4137 - acc: 0.8334\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4180 - acc: 0.8279\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4174 - acc: 0.8343\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4332 - acc: 0.8146\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4361 - acc: 0.8190\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4296 - acc: 0.8250\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4324 - acc: 0.8266\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4168 - acc: 0.8340\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4258 - acc: 0.8332\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3869 - acc: 0.8489\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3746 - acc: 0.8440\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4342 - acc: 0.8220\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4274 - acc: 0.8411\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4133 - acc: 0.8276\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3989 - acc: 0.8434\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4038 - acc: 0.8381\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4052 - acc: 0.8357\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3969 - acc: 0.8465\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3902 - acc: 0.8553\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4034 - acc: 0.8309\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4043 - acc: 0.8284\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4273 - acc: 0.8216\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4136 - acc: 0.8166\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4015 - acc: 0.8423\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3960 - acc: 0.8386\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3887 - acc: 0.8401\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3866 - acc: 0.8371\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3920 - acc: 0.8451\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3814 - acc: 0.8500\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3676 - acc: 0.8316\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3849 - acc: 0.8411\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3669 - acc: 0.8603\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3798 - acc: 0.8446\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3885 - acc: 0.8408\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3938 - acc: 0.8412\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4018 - acc: 0.8249\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3786 - acc: 0.8553\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3787 - acc: 0.8504\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3641 - acc: 0.8537\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3820 - acc: 0.8312\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3727 - acc: 0.8582\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3808 - acc: 0.8465\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3834 - acc: 0.8340\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 61ms/step - loss: 1.4831 - acc: 0.5437\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 1.0988 - acc: 0.5503\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.8659 - acc: 0.5922\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.7485 - acc: 0.6427\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.6758 - acc: 0.7098\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6529 - acc: 0.7179\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6221 - acc: 0.7406\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6044 - acc: 0.7364\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5935 - acc: 0.7569\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5910 - acc: 0.7538\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5821 - acc: 0.7471\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5856 - acc: 0.7428\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5576 - acc: 0.7662\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5613 - acc: 0.7598\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5288 - acc: 0.7802\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5614 - acc: 0.7644\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5308 - acc: 0.7693\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5401 - acc: 0.7652\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5459 - acc: 0.7654\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5471 - acc: 0.7493\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5422 - acc: 0.7646\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5251 - acc: 0.7857\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5132 - acc: 0.7833\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5025 - acc: 0.7703\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5028 - acc: 0.7885\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.5062 - acc: 0.7908\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4921 - acc: 0.7905\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4924 - acc: 0.8022\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4777 - acc: 0.7970\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5027 - acc: 0.8058\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4725 - acc: 0.8045\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4929 - acc: 0.7818\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4722 - acc: 0.7998\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4872 - acc: 0.8164\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4455 - acc: 0.8262\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5047 - acc: 0.7867\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4721 - acc: 0.8182\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4676 - acc: 0.7951\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4842 - acc: 0.8001\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4596 - acc: 0.8063\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4659 - acc: 0.7934\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4671 - acc: 0.7978\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4592 - acc: 0.8124\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4387 - acc: 0.8172\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4663 - acc: 0.8021\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4658 - acc: 0.8046\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4303 - acc: 0.8222\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 66ms/step - loss: 0.4565 - acc: 0.8147\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 65ms/step - loss: 0.4507 - acc: 0.8168\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 66ms/step - loss: 0.4228 - acc: 0.8362\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4417 - acc: 0.8192\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 65ms/step - loss: 0.4532 - acc: 0.8173\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 66ms/step - loss: 0.4349 - acc: 0.8309\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 65ms/step - loss: 0.4352 - acc: 0.8265\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 67ms/step - loss: 0.4394 - acc: 0.8244\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 66ms/step - loss: 0.4395 - acc: 0.8182\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 65ms/step - loss: 0.4357 - acc: 0.8231\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 66ms/step - loss: 0.4027 - acc: 0.8379\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4214 - acc: 0.8267\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4249 - acc: 0.8363\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4267 - acc: 0.8293\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4349 - acc: 0.8148\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4448 - acc: 0.8118\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4134 - acc: 0.8355\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3903 - acc: 0.8403\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4219 - acc: 0.8296\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3992 - acc: 0.8431\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4225 - acc: 0.8275\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4316 - acc: 0.8266\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3895 - acc: 0.8319\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4036 - acc: 0.8293\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4265 - acc: 0.8319\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4301 - acc: 0.8162\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4159 - acc: 0.8328\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3880 - acc: 0.8365\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3961 - acc: 0.8469\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.3752 - acc: 0.8549\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3900 - acc: 0.8421\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3803 - acc: 0.8475\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3942 - acc: 0.8429\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4099 - acc: 0.8227\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3900 - acc: 0.8347\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3990 - acc: 0.8380\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3834 - acc: 0.8570\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3860 - acc: 0.8543\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3768 - acc: 0.8513\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3990 - acc: 0.8378\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3707 - acc: 0.8642\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.4015 - acc: 0.8246\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.3786 - acc: 0.8489\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 66ms/step - loss: 0.3919 - acc: 0.8320\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 65ms/step - loss: 0.3916 - acc: 0.8275\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 66ms/step - loss: 0.3997 - acc: 0.8319\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.3623 - acc: 0.8557\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4129 - acc: 0.8336\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3632 - acc: 0.8524\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3940 - acc: 0.8345\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 66ms/step - loss: 0.3626 - acc: 0.8573\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 65ms/step - loss: 0.3618 - acc: 0.8681\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 65ms/step - loss: 0.3603 - acc: 0.8605\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3478 - acc: 0.8672\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 63ms/step - loss: 1.4692 - acc: 0.5133\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 1.0756 - acc: 0.5577\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.8562 - acc: 0.5905\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.7437 - acc: 0.6659\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6884 - acc: 0.6759\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.6207 - acc: 0.7329\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6143 - acc: 0.7337\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6119 - acc: 0.7395\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5760 - acc: 0.7543\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5965 - acc: 0.7567\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5647 - acc: 0.7596\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5844 - acc: 0.7521\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5463 - acc: 0.7781\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5805 - acc: 0.7391\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5666 - acc: 0.7464\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5632 - acc: 0.7592\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5777 - acc: 0.7490\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5747 - acc: 0.7383\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5472 - acc: 0.7608\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5442 - acc: 0.7514\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5455 - acc: 0.7604\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5540 - acc: 0.7447\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5646 - acc: 0.7452\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5324 - acc: 0.7670\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5220 - acc: 0.7860\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5302 - acc: 0.7685\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5387 - acc: 0.7698\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5253 - acc: 0.7698\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5265 - acc: 0.7754\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4878 - acc: 0.7913\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4998 - acc: 0.8034\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4894 - acc: 0.7927\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5148 - acc: 0.7837\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4987 - acc: 0.7807\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4661 - acc: 0.8123\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4490 - acc: 0.8209\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4700 - acc: 0.8069\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5119 - acc: 0.7798\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4624 - acc: 0.8119\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4300 - acc: 0.8259\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4726 - acc: 0.8086\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4510 - acc: 0.8319\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4735 - acc: 0.8109\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4593 - acc: 0.8078\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4726 - acc: 0.8137\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4556 - acc: 0.8193\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4490 - acc: 0.8252\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4429 - acc: 0.8208\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4371 - acc: 0.8229\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4601 - acc: 0.8185\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4424 - acc: 0.8116\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4515 - acc: 0.8290\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4445 - acc: 0.8170\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4340 - acc: 0.8177\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4477 - acc: 0.8148\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4215 - acc: 0.8245\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4373 - acc: 0.8183\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4296 - acc: 0.8199\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4408 - acc: 0.8167\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4038 - acc: 0.8480\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4292 - acc: 0.8225\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4260 - acc: 0.8361\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4035 - acc: 0.8427\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4183 - acc: 0.8284\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3918 - acc: 0.8375\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4109 - acc: 0.8381\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4232 - acc: 0.8334\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4180 - acc: 0.8278\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3769 - acc: 0.8482\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4137 - acc: 0.8283\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4032 - acc: 0.8318\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4252 - acc: 0.8238\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4261 - acc: 0.8242\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4079 - acc: 0.8373\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4120 - acc: 0.8506\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4001 - acc: 0.8581\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3835 - acc: 0.8503\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4102 - acc: 0.8186\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3948 - acc: 0.8316\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3812 - acc: 0.8365\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3997 - acc: 0.8385\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3806 - acc: 0.8508\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3847 - acc: 0.8553\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3690 - acc: 0.8630\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3959 - acc: 0.8467\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3727 - acc: 0.8516\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3844 - acc: 0.8592\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3792 - acc: 0.8535\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3660 - acc: 0.8658\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3744 - acc: 0.8472\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3708 - acc: 0.8630\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3682 - acc: 0.8493\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3548 - acc: 0.8516\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3903 - acc: 0.8402\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3575 - acc: 0.8589\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3555 - acc: 0.8631\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3411 - acc: 0.8707\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3475 - acc: 0.8707\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3832 - acc: 0.8525\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3267 - acc: 0.8812\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4044 - acc: 0.8164\n",
            "processing fold # 4\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 62ms/step - loss: 1.4731 - acc: 0.5558\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 1.0862 - acc: 0.5507\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8701 - acc: 0.5554\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.7620 - acc: 0.5950\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7055 - acc: 0.6499\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6423 - acc: 0.7226\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6345 - acc: 0.7299\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6225 - acc: 0.7114\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6041 - acc: 0.7326\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5816 - acc: 0.7422\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5791 - acc: 0.7556\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5861 - acc: 0.7515\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5752 - acc: 0.7411\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5700 - acc: 0.7498\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5699 - acc: 0.7292\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5699 - acc: 0.7486\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5590 - acc: 0.7665\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5732 - acc: 0.7415\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5778 - acc: 0.7461\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5685 - acc: 0.7538\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5225 - acc: 0.7793\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5398 - acc: 0.7698\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5185 - acc: 0.7837\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5272 - acc: 0.7639\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5557 - acc: 0.7535\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5221 - acc: 0.7676\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5050 - acc: 0.7899\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4944 - acc: 0.7915\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4999 - acc: 0.7841\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4998 - acc: 0.7832\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5168 - acc: 0.7606\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5207 - acc: 0.7989\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5123 - acc: 0.7857\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4996 - acc: 0.7818\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4985 - acc: 0.7948\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4900 - acc: 0.7787\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4988 - acc: 0.7761\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4823 - acc: 0.7874\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4953 - acc: 0.7902\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4993 - acc: 0.7885\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4721 - acc: 0.8180\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4762 - acc: 0.7975\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4710 - acc: 0.7993\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4966 - acc: 0.7814\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4617 - acc: 0.8064\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4672 - acc: 0.8041\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4769 - acc: 0.8033\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4437 - acc: 0.8080\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4583 - acc: 0.8123\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4433 - acc: 0.8037\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4523 - acc: 0.8072\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4588 - acc: 0.8202\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4500 - acc: 0.8025\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4637 - acc: 0.8023\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4476 - acc: 0.8204\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4537 - acc: 0.8088\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4392 - acc: 0.8235\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4506 - acc: 0.8144\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4480 - acc: 0.8205\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4301 - acc: 0.8258\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4782 - acc: 0.7879\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4251 - acc: 0.8176\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4629 - acc: 0.8108\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4110 - acc: 0.8514\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4431 - acc: 0.8283\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4223 - acc: 0.8415\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4161 - acc: 0.8272\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4316 - acc: 0.8284\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4075 - acc: 0.8385\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4370 - acc: 0.8274\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4253 - acc: 0.8306\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4301 - acc: 0.8243\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4217 - acc: 0.8218\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4181 - acc: 0.8272\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4227 - acc: 0.8207\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4514 - acc: 0.8157\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4201 - acc: 0.8135\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3904 - acc: 0.8438\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4034 - acc: 0.8482\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4163 - acc: 0.8415\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3654 - acc: 0.8626\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3993 - acc: 0.8322\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4068 - acc: 0.8430\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4006 - acc: 0.8466\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4001 - acc: 0.8366\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4100 - acc: 0.8383\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4040 - acc: 0.8451\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3895 - acc: 0.8449\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3785 - acc: 0.8533\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3874 - acc: 0.8543\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4096 - acc: 0.8298\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4035 - acc: 0.8285\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4011 - acc: 0.8376\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3863 - acc: 0.8481\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3855 - acc: 0.8532\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4064 - acc: 0.8342\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3859 - acc: 0.8471\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3697 - acc: 0.8493\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4034 - acc: 0.8317\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3947 - acc: 0.8580\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2942 - acc: 0.8965\n",
            "-----------------------------------------------------\n",
            "batch_size: \t 32\n",
            "num_epochs: \t 100\n",
            "units_per_layer: [32  64  128  128]\n",
            "optimizer: \t Adam\n",
            "learning_rate: \t 0.0001\n",
            "num_folds CV: \t 5\n",
            "-----------------------------------------------------\n",
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 62ms/step - loss: 1.4732 - acc: 0.5186\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 1.0849 - acc: 0.5453\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8763 - acc: 0.5552\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7621 - acc: 0.5930\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7028 - acc: 0.6261\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6756 - acc: 0.6880\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6477 - acc: 0.6851\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6180 - acc: 0.7236\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6110 - acc: 0.7194\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6023 - acc: 0.7418\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6108 - acc: 0.7261\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5636 - acc: 0.7505\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5716 - acc: 0.7439\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5446 - acc: 0.7505\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5858 - acc: 0.7358\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5576 - acc: 0.7544\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5446 - acc: 0.7610\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5500 - acc: 0.7467\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5398 - acc: 0.7659\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5399 - acc: 0.7689\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5275 - acc: 0.7717\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5400 - acc: 0.7677\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5219 - acc: 0.7736\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5231 - acc: 0.7758\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5140 - acc: 0.7775\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5317 - acc: 0.7600\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5414 - acc: 0.7696\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5229 - acc: 0.7774\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5037 - acc: 0.7909\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4814 - acc: 0.8021\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5074 - acc: 0.7789\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5030 - acc: 0.7836\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4767 - acc: 0.7945\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5032 - acc: 0.7990\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4827 - acc: 0.7884\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4901 - acc: 0.8035\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4923 - acc: 0.7859\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4993 - acc: 0.7894\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4863 - acc: 0.7887\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4836 - acc: 0.7985\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4856 - acc: 0.7907\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4849 - acc: 0.7918\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4739 - acc: 0.8031\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4781 - acc: 0.7953\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4601 - acc: 0.8051\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4551 - acc: 0.8092\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4681 - acc: 0.7939\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4491 - acc: 0.8101\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4625 - acc: 0.8084\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4446 - acc: 0.8231\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4466 - acc: 0.8212\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4360 - acc: 0.8196\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4589 - acc: 0.8233\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4672 - acc: 0.7911\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4065 - acc: 0.8293\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4369 - acc: 0.8080\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4382 - acc: 0.8111\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4243 - acc: 0.8208\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4346 - acc: 0.8205\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4358 - acc: 0.8253\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4256 - acc: 0.8221\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4375 - acc: 0.8303\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4083 - acc: 0.8411\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4040 - acc: 0.8455\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4520 - acc: 0.8192\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3941 - acc: 0.8304\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3940 - acc: 0.8383\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4261 - acc: 0.8335\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4441 - acc: 0.8215\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4081 - acc: 0.8424\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4132 - acc: 0.8264\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4190 - acc: 0.8372\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4237 - acc: 0.8254\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4150 - acc: 0.8314\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4133 - acc: 0.8336\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3983 - acc: 0.8300\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4373 - acc: 0.8212\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4133 - acc: 0.8310\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4101 - acc: 0.8320\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4153 - acc: 0.8305\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4210 - acc: 0.8412\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4328 - acc: 0.8235\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4004 - acc: 0.8463\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3965 - acc: 0.8429\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3826 - acc: 0.8454\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3969 - acc: 0.8533\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3857 - acc: 0.8400\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4069 - acc: 0.8396\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3856 - acc: 0.8390\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3876 - acc: 0.8481\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4016 - acc: 0.8467\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4114 - acc: 0.8214\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3632 - acc: 0.8579\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3942 - acc: 0.8476\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3883 - acc: 0.8483\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4046 - acc: 0.8351\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3934 - acc: 0.8384\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3986 - acc: 0.8322\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4130 - acc: 0.8205\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4165 - acc: 0.8304\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2947 - acc: 0.8926\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 61ms/step - loss: 1.4756 - acc: 0.5319\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.0909 - acc: 0.5422\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8740 - acc: 0.5823\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7676 - acc: 0.6068\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7119 - acc: 0.6494\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6785 - acc: 0.6773\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6582 - acc: 0.6921\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6378 - acc: 0.7111\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6471 - acc: 0.6922\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6331 - acc: 0.7135\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6135 - acc: 0.7412\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6055 - acc: 0.7444\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6177 - acc: 0.7191\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5787 - acc: 0.7346\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5767 - acc: 0.7524\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6091 - acc: 0.7406\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5837 - acc: 0.7342\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5691 - acc: 0.7535\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5445 - acc: 0.7560\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5488 - acc: 0.7573\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5528 - acc: 0.7451\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5526 - acc: 0.7603\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5359 - acc: 0.7648\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5391 - acc: 0.7687\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5258 - acc: 0.7697\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5212 - acc: 0.7747\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5418 - acc: 0.7495\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5396 - acc: 0.7706\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5657 - acc: 0.7474\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5192 - acc: 0.7652\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5416 - acc: 0.7692\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5741 - acc: 0.7517\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5087 - acc: 0.7851\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4951 - acc: 0.7800\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5072 - acc: 0.8011\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5217 - acc: 0.7914\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4812 - acc: 0.7943\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5355 - acc: 0.7598\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4961 - acc: 0.7796\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4994 - acc: 0.7936\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5072 - acc: 0.7731\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4787 - acc: 0.7918\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4974 - acc: 0.7937\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4806 - acc: 0.7869\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5115 - acc: 0.7827\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5003 - acc: 0.7879\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4948 - acc: 0.7935\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4816 - acc: 0.7943\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4671 - acc: 0.8138\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4691 - acc: 0.8048\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5010 - acc: 0.7979\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4672 - acc: 0.7961\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4728 - acc: 0.7993\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4538 - acc: 0.8071\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4643 - acc: 0.8155\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4604 - acc: 0.8165\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4607 - acc: 0.8135\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4644 - acc: 0.8031\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4518 - acc: 0.8176\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4803 - acc: 0.8082\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4568 - acc: 0.8213\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4818 - acc: 0.7913\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4739 - acc: 0.8095\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4628 - acc: 0.8094\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4445 - acc: 0.8143\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4697 - acc: 0.8218\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4377 - acc: 0.8218\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4370 - acc: 0.8252\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4347 - acc: 0.8208\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4138 - acc: 0.8216\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4741 - acc: 0.8040\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4497 - acc: 0.8239\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4430 - acc: 0.8120\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4387 - acc: 0.8249\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4279 - acc: 0.8321\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4129 - acc: 0.8375\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4177 - acc: 0.8311\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4187 - acc: 0.8370\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4440 - acc: 0.8145\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4502 - acc: 0.8167\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4242 - acc: 0.8228\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4450 - acc: 0.8087\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4134 - acc: 0.8419\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4286 - acc: 0.8188\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4035 - acc: 0.8391\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4214 - acc: 0.8267\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4220 - acc: 0.8209\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4158 - acc: 0.8299\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4113 - acc: 0.8312\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4116 - acc: 0.8305\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4164 - acc: 0.8186\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4224 - acc: 0.8475\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4286 - acc: 0.8224\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4251 - acc: 0.8293\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4131 - acc: 0.8317\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4265 - acc: 0.8349\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3960 - acc: 0.8420\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4045 - acc: 0.8236\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4325 - acc: 0.8237\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4159 - acc: 0.8335\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3239 - acc: 0.8691\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 60ms/step - loss: 1.4710 - acc: 0.5376\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 1.0779 - acc: 0.5527\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8548 - acc: 0.6059\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.7407 - acc: 0.6514\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6694 - acc: 0.6950\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6364 - acc: 0.7329\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6317 - acc: 0.7181\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5974 - acc: 0.7430\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5865 - acc: 0.7589\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5914 - acc: 0.7312\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5695 - acc: 0.7609\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6011 - acc: 0.7289\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5781 - acc: 0.7534\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5849 - acc: 0.7482\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5878 - acc: 0.7500\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5706 - acc: 0.7546\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5662 - acc: 0.7623\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5471 - acc: 0.7590\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5374 - acc: 0.7638\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5310 - acc: 0.7740\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5115 - acc: 0.7903\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5190 - acc: 0.7679\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5090 - acc: 0.7932\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5356 - acc: 0.7699\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5301 - acc: 0.7670\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4875 - acc: 0.8059\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5036 - acc: 0.7888\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4984 - acc: 0.7900\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5008 - acc: 0.7900\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5067 - acc: 0.7802\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5075 - acc: 0.7820\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4976 - acc: 0.8004\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5024 - acc: 0.7817\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4625 - acc: 0.7974\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4735 - acc: 0.7967\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4512 - acc: 0.8095\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4601 - acc: 0.8040\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4791 - acc: 0.7925\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4530 - acc: 0.8141\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4605 - acc: 0.8046\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4449 - acc: 0.8204\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4761 - acc: 0.7959\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4476 - acc: 0.8099\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4485 - acc: 0.8151\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4519 - acc: 0.8145\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4577 - acc: 0.8178\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4601 - acc: 0.8029\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4243 - acc: 0.8290\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4292 - acc: 0.8276\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4395 - acc: 0.8336\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4221 - acc: 0.8289\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4427 - acc: 0.8231\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4574 - acc: 0.8096\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4348 - acc: 0.8145\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4153 - acc: 0.8335\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4013 - acc: 0.8380\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4261 - acc: 0.8289\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4349 - acc: 0.8190\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4330 - acc: 0.8307\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4189 - acc: 0.8178\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3986 - acc: 0.8507\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4055 - acc: 0.8314\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4281 - acc: 0.8226\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3934 - acc: 0.8472\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4073 - acc: 0.8420\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4134 - acc: 0.8291\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3917 - acc: 0.8471\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3980 - acc: 0.8367\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3972 - acc: 0.8344\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3830 - acc: 0.8390\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4199 - acc: 0.8218\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4013 - acc: 0.8481\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3976 - acc: 0.8229\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4140 - acc: 0.8267\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4021 - acc: 0.8293\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4119 - acc: 0.8324\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3877 - acc: 0.8390\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3708 - acc: 0.8570\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3995 - acc: 0.8473\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4099 - acc: 0.8324\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4023 - acc: 0.8435\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4163 - acc: 0.8277\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3960 - acc: 0.8347\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3905 - acc: 0.8554\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3940 - acc: 0.8362\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3671 - acc: 0.8491\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3514 - acc: 0.8526\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3845 - acc: 0.8427\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3869 - acc: 0.8463\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3778 - acc: 0.8346\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3464 - acc: 0.8635\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4020 - acc: 0.8307\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3548 - acc: 0.8595\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3692 - acc: 0.8443\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3822 - acc: 0.8517\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3700 - acc: 0.8611\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3721 - acc: 0.8427\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3923 - acc: 0.8389\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3746 - acc: 0.8505\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3742 - acc: 0.8463\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3186 - acc: 0.8691\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 61ms/step - loss: 1.4864 - acc: 0.5106\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 1.0979 - acc: 0.5542\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.8682 - acc: 0.5869\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7646 - acc: 0.6182\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6936 - acc: 0.6810\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6623 - acc: 0.6913\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6449 - acc: 0.7205\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6073 - acc: 0.7388\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5943 - acc: 0.7363\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5710 - acc: 0.7658\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5737 - acc: 0.7444\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5873 - acc: 0.7455\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5694 - acc: 0.7570\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5707 - acc: 0.7428\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5884 - acc: 0.7381\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5655 - acc: 0.7495\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6001 - acc: 0.7269\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5536 - acc: 0.7582\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5292 - acc: 0.7740\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.5715 - acc: 0.7512\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5460 - acc: 0.7646\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5208 - acc: 0.7710\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5420 - acc: 0.7584\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5397 - acc: 0.7577\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5456 - acc: 0.7616\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5501 - acc: 0.7526\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5140 - acc: 0.7834\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5146 - acc: 0.7807\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5309 - acc: 0.7580\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5266 - acc: 0.7606\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5098 - acc: 0.7839\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4903 - acc: 0.7810\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5032 - acc: 0.7877\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4951 - acc: 0.7849\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5018 - acc: 0.7748\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4962 - acc: 0.7879\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4848 - acc: 0.8002\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4842 - acc: 0.7964\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4912 - acc: 0.7871\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4697 - acc: 0.8164\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4775 - acc: 0.7953\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4777 - acc: 0.7967\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4563 - acc: 0.8110\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4608 - acc: 0.8021\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4661 - acc: 0.8149\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4930 - acc: 0.7891\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4551 - acc: 0.8010\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4550 - acc: 0.8176\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4824 - acc: 0.7848\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4643 - acc: 0.8074\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4226 - acc: 0.8283\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4772 - acc: 0.8051\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4340 - acc: 0.8134\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4499 - acc: 0.8098\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4640 - acc: 0.8044\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4407 - acc: 0.8181\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4252 - acc: 0.8356\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4220 - acc: 0.8381\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4273 - acc: 0.8254\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4317 - acc: 0.8292\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4291 - acc: 0.8266\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4194 - acc: 0.8360\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4079 - acc: 0.8413\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4198 - acc: 0.8471\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4472 - acc: 0.8262\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4222 - acc: 0.8120\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4161 - acc: 0.8247\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4040 - acc: 0.8221\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4296 - acc: 0.8208\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4163 - acc: 0.8351\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4031 - acc: 0.8298\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4154 - acc: 0.8327\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4169 - acc: 0.8311\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4154 - acc: 0.8291\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3940 - acc: 0.8401\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3998 - acc: 0.8416\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3986 - acc: 0.8309\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4326 - acc: 0.8280\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4138 - acc: 0.8280\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3890 - acc: 0.8417\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4003 - acc: 0.8235\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4398 - acc: 0.8146\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4192 - acc: 0.8332\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3838 - acc: 0.8393\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4049 - acc: 0.8373\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3662 - acc: 0.8547\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3922 - acc: 0.8453\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4000 - acc: 0.8414\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3934 - acc: 0.8463\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3881 - acc: 0.8582\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3768 - acc: 0.8524\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3839 - acc: 0.8516\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3835 - acc: 0.8545\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3906 - acc: 0.8519\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3924 - acc: 0.8380\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3719 - acc: 0.8551\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3810 - acc: 0.8448\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3588 - acc: 0.8551\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3603 - acc: 0.8512\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4134 - acc: 0.8231\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3221 - acc: 0.8672\n",
            "processing fold # 4\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 60ms/step - loss: 1.4751 - acc: 0.5393\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 1.0807 - acc: 0.5529\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8596 - acc: 0.5681\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.7457 - acc: 0.6066\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6859 - acc: 0.6469\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6568 - acc: 0.6954\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6359 - acc: 0.6957\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6140 - acc: 0.7243\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5775 - acc: 0.7527\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5839 - acc: 0.7273\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5861 - acc: 0.7382\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5950 - acc: 0.7181\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5690 - acc: 0.7592\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5475 - acc: 0.7647\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5625 - acc: 0.7609\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5800 - acc: 0.7378\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5496 - acc: 0.7571\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5599 - acc: 0.7424\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5416 - acc: 0.7606\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5502 - acc: 0.7497\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5531 - acc: 0.7495\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5668 - acc: 0.7317\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5249 - acc: 0.7848\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5511 - acc: 0.7623\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5093 - acc: 0.7864\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5267 - acc: 0.7719\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5504 - acc: 0.7402\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5041 - acc: 0.7874\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5136 - acc: 0.7776\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5250 - acc: 0.7672\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5112 - acc: 0.7676\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5110 - acc: 0.7781\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5185 - acc: 0.7719\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5033 - acc: 0.7828\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5246 - acc: 0.7720\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5078 - acc: 0.7591\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5080 - acc: 0.7895\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5067 - acc: 0.7722\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4776 - acc: 0.8000\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5094 - acc: 0.7695\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4894 - acc: 0.7942\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4835 - acc: 0.8017\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4859 - acc: 0.7853\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4931 - acc: 0.7788\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4879 - acc: 0.7901\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5083 - acc: 0.7730\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4764 - acc: 0.7857\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4706 - acc: 0.7988\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4780 - acc: 0.7976\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4819 - acc: 0.7965\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4700 - acc: 0.8124\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4629 - acc: 0.8064\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4356 - acc: 0.8251\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4894 - acc: 0.7895\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4490 - acc: 0.8114\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4505 - acc: 0.8322\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4652 - acc: 0.7982\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4502 - acc: 0.8113\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4625 - acc: 0.8056\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4518 - acc: 0.8139\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4839 - acc: 0.8024\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4514 - acc: 0.8092\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4624 - acc: 0.8082\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4386 - acc: 0.8315\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4462 - acc: 0.8154\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4541 - acc: 0.8079\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4447 - acc: 0.8181\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4694 - acc: 0.7933\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4379 - acc: 0.8100\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4607 - acc: 0.7949\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4515 - acc: 0.8090\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4149 - acc: 0.8328\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4324 - acc: 0.8169\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4178 - acc: 0.8322\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4615 - acc: 0.8163\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4232 - acc: 0.8202\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4421 - acc: 0.8154\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4373 - acc: 0.8165\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4265 - acc: 0.8252\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4332 - acc: 0.8241\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3885 - acc: 0.8363\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4278 - acc: 0.8171\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4057 - acc: 0.8343\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4165 - acc: 0.8312\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4161 - acc: 0.8290\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4122 - acc: 0.8330\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4088 - acc: 0.8303\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4137 - acc: 0.8158\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4055 - acc: 0.8385\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4238 - acc: 0.8247\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4166 - acc: 0.8245\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4107 - acc: 0.8335\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4205 - acc: 0.8347\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4040 - acc: 0.8265\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4033 - acc: 0.8386\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4049 - acc: 0.8366\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3981 - acc: 0.8334\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3999 - acc: 0.8361\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4022 - acc: 0.8315\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4473 - acc: 0.8086\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.2796 - acc: 0.8867\n",
            "-----------------------------------------------------\n",
            "batch_size: \t 32\n",
            "num_epochs: \t 100\n",
            "units_per_layer: [32  64  128  256]\n",
            "optimizer: \t Adam\n",
            "learning_rate: \t 0.0001\n",
            "num_folds CV: \t 5\n",
            "-----------------------------------------------------\n",
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 61ms/step - loss: 1.4657 - acc: 0.5570\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.0772 - acc: 0.5533\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.8571 - acc: 0.5650\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7547 - acc: 0.5996\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6948 - acc: 0.6563\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6656 - acc: 0.7106\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6292 - acc: 0.7330\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6070 - acc: 0.7315\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.6082 - acc: 0.7447\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5943 - acc: 0.7397\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6000 - acc: 0.7359\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5871 - acc: 0.7505\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5582 - acc: 0.7676\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5734 - acc: 0.7294\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5579 - acc: 0.7685\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5573 - acc: 0.7558\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5643 - acc: 0.7382\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5554 - acc: 0.7480\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5347 - acc: 0.7652\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5473 - acc: 0.7453\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5249 - acc: 0.7594\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5148 - acc: 0.7809\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5229 - acc: 0.7570\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5520 - acc: 0.7582\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5216 - acc: 0.7579\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5265 - acc: 0.7826\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5115 - acc: 0.7799\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4925 - acc: 0.8014\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4938 - acc: 0.7938\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4862 - acc: 0.7855\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5106 - acc: 0.7850\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4826 - acc: 0.7966\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5043 - acc: 0.8048\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4922 - acc: 0.7863\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4828 - acc: 0.7837\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4760 - acc: 0.7988\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4684 - acc: 0.8056\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4969 - acc: 0.7737\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5059 - acc: 0.7651\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4810 - acc: 0.7959\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4836 - acc: 0.7920\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4692 - acc: 0.8086\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4669 - acc: 0.7930\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4627 - acc: 0.8023\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4438 - acc: 0.8211\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4476 - acc: 0.8284\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4433 - acc: 0.8285\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4611 - acc: 0.8100\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4601 - acc: 0.8154\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4399 - acc: 0.8174\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4469 - acc: 0.8235\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4606 - acc: 0.8071\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4416 - acc: 0.8163\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4420 - acc: 0.8220\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4675 - acc: 0.8167\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4489 - acc: 0.8219\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4545 - acc: 0.8065\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4291 - acc: 0.8319\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4402 - acc: 0.8291\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4457 - acc: 0.8228\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4553 - acc: 0.8114\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4223 - acc: 0.8283\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4004 - acc: 0.8505\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4188 - acc: 0.8366\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4259 - acc: 0.8217\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4425 - acc: 0.8232\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4041 - acc: 0.8309\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4431 - acc: 0.8149\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4333 - acc: 0.8260\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4220 - acc: 0.8279\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4273 - acc: 0.8298\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4070 - acc: 0.8445\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4111 - acc: 0.8256\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4323 - acc: 0.8251\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4171 - acc: 0.8271\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3938 - acc: 0.8452\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4013 - acc: 0.8401\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4149 - acc: 0.8439\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4211 - acc: 0.8247\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4176 - acc: 0.8198\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4352 - acc: 0.8154\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4037 - acc: 0.8302\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4058 - acc: 0.8346\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3967 - acc: 0.8331\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4136 - acc: 0.8296\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3757 - acc: 0.8493\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4202 - acc: 0.8208\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3783 - acc: 0.8549\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3765 - acc: 0.8604\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3968 - acc: 0.8337\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3844 - acc: 0.8429\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3953 - acc: 0.8519\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4178 - acc: 0.8242\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3770 - acc: 0.8568\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3701 - acc: 0.8606\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3935 - acc: 0.8533\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4024 - acc: 0.8343\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3635 - acc: 0.8565\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4266 - acc: 0.8291\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3990 - acc: 0.8455\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3075 - acc: 0.8965\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 62ms/step - loss: 1.4732 - acc: 0.5445\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.0882 - acc: 0.5411\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8681 - acc: 0.5729\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7528 - acc: 0.6090\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7014 - acc: 0.6554\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6616 - acc: 0.6927\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6302 - acc: 0.7214\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6151 - acc: 0.7318\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6019 - acc: 0.7250\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6041 - acc: 0.7187\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5798 - acc: 0.7430\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5727 - acc: 0.7565\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5738 - acc: 0.7461\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5635 - acc: 0.7428\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5528 - acc: 0.7538\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5470 - acc: 0.7625\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5504 - acc: 0.7598\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5684 - acc: 0.7616\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5362 - acc: 0.7667\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5501 - acc: 0.7628\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5215 - acc: 0.7487\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5097 - acc: 0.7780\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5358 - acc: 0.7554\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5392 - acc: 0.7594\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5200 - acc: 0.7658\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5103 - acc: 0.7739\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5180 - acc: 0.7773\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4993 - acc: 0.7755\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4895 - acc: 0.7763\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5089 - acc: 0.7844\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5020 - acc: 0.7777\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4962 - acc: 0.7843\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5080 - acc: 0.7842\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4950 - acc: 0.7877\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4730 - acc: 0.8150\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5027 - acc: 0.7764\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5013 - acc: 0.7959\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4688 - acc: 0.7998\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4281 - acc: 0.8213\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4865 - acc: 0.7766\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4621 - acc: 0.8130\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5066 - acc: 0.7766\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4723 - acc: 0.7985\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4554 - acc: 0.8155\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4881 - acc: 0.7961\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4689 - acc: 0.7983\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4640 - acc: 0.8035\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4696 - acc: 0.8027\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4554 - acc: 0.8132\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4936 - acc: 0.7808\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4636 - acc: 0.7943\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4734 - acc: 0.7988\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4364 - acc: 0.8069\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4439 - acc: 0.8326\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4478 - acc: 0.8161\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4387 - acc: 0.8074\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4476 - acc: 0.8316\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4692 - acc: 0.7997\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4392 - acc: 0.8154\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4617 - acc: 0.8100\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4255 - acc: 0.8297\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4294 - acc: 0.8342\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4588 - acc: 0.8098\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4305 - acc: 0.8309\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4392 - acc: 0.8108\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4367 - acc: 0.8144\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4360 - acc: 0.8312\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4359 - acc: 0.8229\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4243 - acc: 0.8231\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4287 - acc: 0.8214\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4259 - acc: 0.8270\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4374 - acc: 0.8156\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4233 - acc: 0.8324\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4218 - acc: 0.8141\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4341 - acc: 0.8217\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4235 - acc: 0.8318\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3990 - acc: 0.8397\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4531 - acc: 0.8009\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3721 - acc: 0.8600\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3923 - acc: 0.8471\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4209 - acc: 0.8221\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3935 - acc: 0.8460\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4159 - acc: 0.8239\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4039 - acc: 0.8458\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4031 - acc: 0.8395\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3932 - acc: 0.8408\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3829 - acc: 0.8448\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3918 - acc: 0.8569\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3836 - acc: 0.8348\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4132 - acc: 0.8220\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4046 - acc: 0.8326\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3835 - acc: 0.8589\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3822 - acc: 0.8420\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3989 - acc: 0.8357\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3994 - acc: 0.8283\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3842 - acc: 0.8507\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3810 - acc: 0.8572\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4180 - acc: 0.8248\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3883 - acc: 0.8457\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3899 - acc: 0.8438\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.3222 - acc: 0.8711\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 61ms/step - loss: 1.4694 - acc: 0.5284\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 1.0798 - acc: 0.5590\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8580 - acc: 0.5862\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.7509 - acc: 0.6243\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7047 - acc: 0.6462\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6496 - acc: 0.7150\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6336 - acc: 0.7285\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6118 - acc: 0.7301\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5990 - acc: 0.7381\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5842 - acc: 0.7431\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5855 - acc: 0.7461\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5761 - acc: 0.7644\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5721 - acc: 0.7370\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5783 - acc: 0.7444\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5439 - acc: 0.7663\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5598 - acc: 0.7381\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5439 - acc: 0.7796\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5325 - acc: 0.7794\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5480 - acc: 0.7689\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5549 - acc: 0.7566\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5298 - acc: 0.7627\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5223 - acc: 0.7801\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5207 - acc: 0.7789\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5103 - acc: 0.7852\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5415 - acc: 0.7630\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5062 - acc: 0.7916\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5147 - acc: 0.7744\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5242 - acc: 0.7740\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5171 - acc: 0.7869\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5287 - acc: 0.7856\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4932 - acc: 0.7772\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5018 - acc: 0.7780\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5008 - acc: 0.7924\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4570 - acc: 0.8091\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4928 - acc: 0.7849\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4709 - acc: 0.8011\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5276 - acc: 0.7843\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4615 - acc: 0.8103\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4586 - acc: 0.8126\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4857 - acc: 0.7924\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4815 - acc: 0.7947\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4735 - acc: 0.7967\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4796 - acc: 0.7907\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4570 - acc: 0.8190\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4655 - acc: 0.8113\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4408 - acc: 0.8138\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4661 - acc: 0.8080\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4559 - acc: 0.8076\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4600 - acc: 0.8243\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4463 - acc: 0.8042\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4763 - acc: 0.8015\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4490 - acc: 0.8152\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4382 - acc: 0.8234\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4329 - acc: 0.8162\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4437 - acc: 0.8274\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4248 - acc: 0.8238\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4246 - acc: 0.8249\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4676 - acc: 0.8082\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4244 - acc: 0.8284\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4160 - acc: 0.8301\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4345 - acc: 0.8060\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4703 - acc: 0.7981\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4231 - acc: 0.8216\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3982 - acc: 0.8477\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4363 - acc: 0.8121\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4345 - acc: 0.8181\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4201 - acc: 0.8382\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4360 - acc: 0.8199\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4165 - acc: 0.8324\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4301 - acc: 0.8119\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.4201 - acc: 0.8395\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4213 - acc: 0.8216\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.4274 - acc: 0.8304\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.3845 - acc: 0.8370\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4083 - acc: 0.8343\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3909 - acc: 0.8427\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4261 - acc: 0.8158\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3905 - acc: 0.8387\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.4042 - acc: 0.8350\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4194 - acc: 0.8385\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.3801 - acc: 0.8543\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 64ms/step - loss: 0.3872 - acc: 0.8453\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 63ms/step - loss: 0.4170 - acc: 0.8176\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4093 - acc: 0.8355\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4000 - acc: 0.8385\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3962 - acc: 0.8458\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3871 - acc: 0.8632\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3792 - acc: 0.8589\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4098 - acc: 0.8326\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3797 - acc: 0.8528\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4098 - acc: 0.8394\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4007 - acc: 0.8328\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3956 - acc: 0.8397\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4080 - acc: 0.8315\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3834 - acc: 0.8382\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4019 - acc: 0.8395\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3785 - acc: 0.8575\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3771 - acc: 0.8472\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3821 - acc: 0.8492\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3944 - acc: 0.8453\n",
            "16/16 [==============================] - 0s 10ms/step - loss: 0.3617 - acc: 0.8535\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 62ms/step - loss: 1.4713 - acc: 0.5544\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.0818 - acc: 0.5504\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8603 - acc: 0.5800\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7531 - acc: 0.6331\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.6792 - acc: 0.7102\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6438 - acc: 0.7280\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6377 - acc: 0.7187\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6432 - acc: 0.7298\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6117 - acc: 0.7294\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5825 - acc: 0.7444\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5727 - acc: 0.7520\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6070 - acc: 0.7388\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6010 - acc: 0.7395\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5934 - acc: 0.7459\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5597 - acc: 0.7576\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5621 - acc: 0.7477\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5515 - acc: 0.7693\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5685 - acc: 0.7516\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5161 - acc: 0.7864\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5633 - acc: 0.7548\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5664 - acc: 0.7560\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5331 - acc: 0.7650\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5349 - acc: 0.7590\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5296 - acc: 0.7629\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5229 - acc: 0.7705\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5207 - acc: 0.7883\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5031 - acc: 0.7825\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5066 - acc: 0.7889\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4858 - acc: 0.8068\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5395 - acc: 0.7586\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4995 - acc: 0.7843\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4891 - acc: 0.8052\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5176 - acc: 0.7727\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5161 - acc: 0.7909\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4758 - acc: 0.7965\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4775 - acc: 0.8089\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4957 - acc: 0.7972\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4900 - acc: 0.7982\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4684 - acc: 0.8090\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4703 - acc: 0.8025\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4762 - acc: 0.8084\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4824 - acc: 0.7979\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4798 - acc: 0.7919\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4599 - acc: 0.8133\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4356 - acc: 0.8304\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4512 - acc: 0.8154\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4783 - acc: 0.8110\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4774 - acc: 0.7943\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4268 - acc: 0.8242\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4314 - acc: 0.8256\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4595 - acc: 0.8071\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4426 - acc: 0.8154\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4814 - acc: 0.8102\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4614 - acc: 0.8072\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4402 - acc: 0.8146\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4354 - acc: 0.8285\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4365 - acc: 0.8270\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4016 - acc: 0.8459\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4598 - acc: 0.8150\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4283 - acc: 0.8306\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4174 - acc: 0.8311\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4225 - acc: 0.8260\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4105 - acc: 0.8398\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4410 - acc: 0.8113\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4528 - acc: 0.8155\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4053 - acc: 0.8415\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4266 - acc: 0.8203\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4233 - acc: 0.8221\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4083 - acc: 0.8383\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3998 - acc: 0.8388\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3858 - acc: 0.8378\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3967 - acc: 0.8378\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4006 - acc: 0.8475\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3913 - acc: 0.8412\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4425 - acc: 0.8040\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3858 - acc: 0.8474\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4068 - acc: 0.8369\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4147 - acc: 0.8226\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3850 - acc: 0.8417\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3848 - acc: 0.8499\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3988 - acc: 0.8414\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3848 - acc: 0.8453\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3851 - acc: 0.8463\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3867 - acc: 0.8489\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3744 - acc: 0.8455\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3880 - acc: 0.8364\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3954 - acc: 0.8539\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3942 - acc: 0.8339\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3857 - acc: 0.8560\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3821 - acc: 0.8591\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3955 - acc: 0.8503\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3834 - acc: 0.8496\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3878 - acc: 0.8500\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3756 - acc: 0.8562\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.3709 - acc: 0.8473\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3547 - acc: 0.8593\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3722 - acc: 0.8623\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3718 - acc: 0.8565\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3488 - acc: 0.8661\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3712 - acc: 0.8411\n",
            "16/16 [==============================] - 0s 9ms/step - loss: 0.4241 - acc: 0.8027\n",
            "processing fold # 4\n",
            "Epoch 1/100\n",
            "66/66 [==============================] - 5s 62ms/step - loss: 1.4728 - acc: 0.5414\n",
            "Epoch 2/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 1.0878 - acc: 0.5639\n",
            "Epoch 3/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.8802 - acc: 0.5732\n",
            "Epoch 4/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7740 - acc: 0.6015\n",
            "Epoch 5/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.7163 - acc: 0.6547\n",
            "Epoch 6/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.6707 - acc: 0.6854\n",
            "Epoch 7/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6508 - acc: 0.6989\n",
            "Epoch 8/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6142 - acc: 0.7192\n",
            "Epoch 9/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.6115 - acc: 0.7390\n",
            "Epoch 10/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5939 - acc: 0.7465\n",
            "Epoch 11/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5935 - acc: 0.7380\n",
            "Epoch 12/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5849 - acc: 0.7353\n",
            "Epoch 13/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5843 - acc: 0.7582\n",
            "Epoch 14/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5872 - acc: 0.7350\n",
            "Epoch 15/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5734 - acc: 0.7342\n",
            "Epoch 16/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5552 - acc: 0.7675\n",
            "Epoch 17/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5479 - acc: 0.7534\n",
            "Epoch 18/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5604 - acc: 0.7542\n",
            "Epoch 19/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5460 - acc: 0.7639\n",
            "Epoch 20/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5492 - acc: 0.7649\n",
            "Epoch 21/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5380 - acc: 0.7636\n",
            "Epoch 22/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5367 - acc: 0.7533\n",
            "Epoch 23/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5319 - acc: 0.7808\n",
            "Epoch 24/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5212 - acc: 0.7655\n",
            "Epoch 25/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5262 - acc: 0.7681\n",
            "Epoch 26/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5111 - acc: 0.7755\n",
            "Epoch 27/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.5437 - acc: 0.7569\n",
            "Epoch 28/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5251 - acc: 0.7703\n",
            "Epoch 29/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5186 - acc: 0.7762\n",
            "Epoch 30/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5265 - acc: 0.7695\n",
            "Epoch 31/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4924 - acc: 0.7994\n",
            "Epoch 32/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4919 - acc: 0.7978\n",
            "Epoch 33/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4816 - acc: 0.7840\n",
            "Epoch 34/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4933 - acc: 0.7858\n",
            "Epoch 35/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5049 - acc: 0.8081\n",
            "Epoch 36/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.5180 - acc: 0.7698\n",
            "Epoch 37/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4965 - acc: 0.7915\n",
            "Epoch 38/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.5007 - acc: 0.7904\n",
            "Epoch 39/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4793 - acc: 0.7968\n",
            "Epoch 40/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4681 - acc: 0.7995\n",
            "Epoch 41/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4937 - acc: 0.7924\n",
            "Epoch 42/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4764 - acc: 0.7931\n",
            "Epoch 43/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4781 - acc: 0.8008\n",
            "Epoch 44/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4607 - acc: 0.8022\n",
            "Epoch 45/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4908 - acc: 0.7832\n",
            "Epoch 46/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4782 - acc: 0.8025\n",
            "Epoch 47/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4463 - acc: 0.8165\n",
            "Epoch 48/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4488 - acc: 0.8165\n",
            "Epoch 49/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4773 - acc: 0.7969\n",
            "Epoch 50/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4698 - acc: 0.8139\n",
            "Epoch 51/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4444 - acc: 0.8246\n",
            "Epoch 52/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4531 - acc: 0.8152\n",
            "Epoch 53/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4644 - acc: 0.8006\n",
            "Epoch 54/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4520 - acc: 0.8075\n",
            "Epoch 55/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4454 - acc: 0.8264\n",
            "Epoch 56/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4466 - acc: 0.8235\n",
            "Epoch 57/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4277 - acc: 0.8152\n",
            "Epoch 58/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4334 - acc: 0.8260\n",
            "Epoch 59/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4578 - acc: 0.8086\n",
            "Epoch 60/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4333 - acc: 0.8269\n",
            "Epoch 61/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4487 - acc: 0.8083\n",
            "Epoch 62/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4524 - acc: 0.8085\n",
            "Epoch 63/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4365 - acc: 0.8242\n",
            "Epoch 64/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4564 - acc: 0.8151\n",
            "Epoch 65/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4129 - acc: 0.8418\n",
            "Epoch 66/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4424 - acc: 0.8163\n",
            "Epoch 67/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4402 - acc: 0.8285\n",
            "Epoch 68/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4137 - acc: 0.8343\n",
            "Epoch 69/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4406 - acc: 0.8230\n",
            "Epoch 70/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4216 - acc: 0.8324\n",
            "Epoch 71/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4249 - acc: 0.8299\n",
            "Epoch 72/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4332 - acc: 0.8079\n",
            "Epoch 73/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3993 - acc: 0.8416\n",
            "Epoch 74/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4161 - acc: 0.8245\n",
            "Epoch 75/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4117 - acc: 0.8396\n",
            "Epoch 76/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3895 - acc: 0.8385\n",
            "Epoch 77/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4099 - acc: 0.8396\n",
            "Epoch 78/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4087 - acc: 0.8360\n",
            "Epoch 79/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4158 - acc: 0.8171\n",
            "Epoch 80/100\n",
            "66/66 [==============================] - 4s 60ms/step - loss: 0.4030 - acc: 0.8474\n",
            "Epoch 81/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3868 - acc: 0.8490\n",
            "Epoch 82/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3934 - acc: 0.8299\n",
            "Epoch 83/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4039 - acc: 0.8283\n",
            "Epoch 84/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3881 - acc: 0.8409\n",
            "Epoch 85/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4002 - acc: 0.8350\n",
            "Epoch 86/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4149 - acc: 0.8221\n",
            "Epoch 87/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4151 - acc: 0.8344\n",
            "Epoch 88/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4105 - acc: 0.8278\n",
            "Epoch 89/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3883 - acc: 0.8390\n",
            "Epoch 90/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4017 - acc: 0.8458\n",
            "Epoch 91/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3989 - acc: 0.8288\n",
            "Epoch 92/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3718 - acc: 0.8462\n",
            "Epoch 93/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4016 - acc: 0.8437\n",
            "Epoch 94/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4012 - acc: 0.8394\n",
            "Epoch 95/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4027 - acc: 0.8287\n",
            "Epoch 96/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.3897 - acc: 0.8433\n",
            "Epoch 97/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3836 - acc: 0.8480\n",
            "Epoch 98/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.3754 - acc: 0.8507\n",
            "Epoch 99/100\n",
            "66/66 [==============================] - 4s 62ms/step - loss: 0.4050 - acc: 0.8292\n",
            "Epoch 100/100\n",
            "66/66 [==============================] - 4s 61ms/step - loss: 0.4004 - acc: 0.8360\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}