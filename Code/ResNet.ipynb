{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarshaGomez/CNN-Medical-Imaging-Analysis/blob/main/Code/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJV7CmDCfRY8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6f2cf7-5ae4-46c0-fe69-3cf9cf4cbcdc"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsZLDE21fjTX"
      },
      "source": [
        "#0.1 Load Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXkpDAfSfiol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da70f183-2212-46d4-c1a1-7c5bdeab8491"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "import seaborn as sns # Grouped bar plot\r\n",
        "import itertools\r\n",
        "import numpy as np\r\n",
        "import pandas as pd \r\n",
        "import ast #Abstract Syntax Trees\r\n",
        "import os \r\n",
        "import gc # Garbage Collector\r\n",
        "\r\n",
        "from tensorflow.keras import backend as K # Useful to free GPU and memory\r\n",
        "from sklearn.metrics import confusion_matrix, classification_report\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.preprocessing import image\r\n",
        "from tensorflow.keras.models import load_model\r\n",
        "from keras import layers, optimizers, models, regularizers, metrics\r\n",
        "from keras.models import load_model\r\n",
        "from sklearn.metrics import roc_curve\r\n",
        "from sklearn.metrics import auc\r\n",
        "from keras.models import Model\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "import scipy\r\n",
        "import scipy.misc\r\n",
        "from PIL import Image\r\n",
        "BATCH_SIZE = 20\r\n",
        "EPOCHS = 50\r\n",
        "\r\n",
        "base_path = \"/content/gdrive/My Drive/Colab Notebooks/CIDL/DL Project\"\r\n",
        "train_img_path = os.path.join(base_path, \"numpy data/train_tensor.npy\")\r\n",
        "train_label_path = os.path.join(base_path, \"numpy data/train_labels.npy\")\r\n",
        "test_img_path = os.path.join(base_path, \"numpy data/public_test_tensor.npy\")\r\n",
        "test_label_path = os.path.join(base_path, \"numpy data/public_test_labels.npy\")\r\n",
        "\r\n",
        "MODEL_PATH = os.path.join(base_path, \"models/PreTrained-Masses-Calcifications/ResNet\")\r\n",
        "PLOTS_PATH = os.path.join(base_path, \"plots/Masses-Calcifications\")\r\n",
        "\r\n",
        "\r\n",
        "# to produce final model report histogram \r\n",
        "AUC_values = []\r\n",
        "TPR_values = []\r\n",
        "FPR_values = []\r\n",
        "PRECISION_values = []\r\n",
        "SPECIFICITY_values = []\r\n",
        "\r\n",
        "# Load Arrays from Numpy Files\r\n",
        "def load_training():\r\n",
        "  train_images = np.load(train_img_path)\r\n",
        "  train_labels = np.load(train_label_path)\r\n",
        "  test_images = np.load(test_img_path)\r\n",
        "  test_labels = np.load(test_label_path)\r\n",
        "\r\n",
        "  return train_images, train_labels, test_images, test_labels\r\n",
        "\r\n",
        "def get_model_predictions(model, dataset, labels, sample_count): \r\n",
        "  predictions = np.zeros((sample_count,))   \r\n",
        "\r\n",
        "  BATCH_SIZE = 1\r\n",
        "  i = 0\r\n",
        "  for batch, labels_batch in test_datagen.flow(dataset, labels, batch_size=BATCH_SIZE, shuffle=False):\r\n",
        "    predictions[i * BATCH_SIZE : (i + 1) * BATCH_SIZE] = model.predict(batch)\r\n",
        "    i += 1\r\n",
        "\r\n",
        "    if i * BATCH_SIZE  >= sample_count:\r\n",
        "      break\r\n",
        "\r\n",
        "    #np.where(predictions < 0.5, 0, 1)\r\n",
        "    #predictions = np.where(predictions < 0.5, 0, 1)\r\n",
        "\r\n",
        "  return predictions\r\n",
        "\r\n",
        "\r\n",
        "# Remove baseline samples\r\n",
        "def remove_baseline(tensor): \r\n",
        "  max_ind = int(len(tensor)/2)\r\n",
        "  indexes = [2*i + 1 for i in range(0, max_ind)]\r\n",
        "\r\n",
        "  return tensor[indexes]\r\n",
        "\r\n",
        "# Interchange the dataset index\r\n",
        "def shuffle_dataset(x, y):\r\n",
        "  indices = tf.range(start=0, limit=tf.shape(x)[0], dtype=tf.int32)\r\n",
        "  shuffled_indices = tf.random.shuffle(indices)\r\n",
        "\r\n",
        "  x = tf.gather(x, shuffled_indices)\r\n",
        "  y = tf.gather(y, shuffled_indices)\r\n",
        "\r\n",
        "  x = x.numpy()\r\n",
        "  y = y.numpy()\r\n",
        "\r\n",
        "  return x, y\r\n",
        "\r\n",
        "# split dataset into training and validation set 70-30\r\n",
        "def split_train_val(dataset, labels):\r\n",
        "  train_data_split = dataset[:int(0.7*len(dataset))]\r\n",
        "  valid_data_split = dataset[int(0.7*len(dataset)):]\r\n",
        "  train_labels_split = labels[:int(0.7*len(labels))]\r\n",
        "  valid_labels_split = labels[int(0.7*len(labels)):]\r\n",
        "\r\n",
        "  print(train_data_split.shape)\r\n",
        "  print(valid_data_split.shape)\r\n",
        "  print(train_labels_split.shape)\r\n",
        "  print(valid_labels_split.shape)      \r\n",
        "\r\n",
        "  return train_data_split, valid_data_split, train_labels_split, valid_labels_split\r\n",
        "\r\n",
        "# Unify masses and calcifications \r\n",
        "def labels_mapping(labels):\r\n",
        "  labels_local = np.zeros(shape=labels.shape, dtype=\"float32\")\r\n",
        "  idx = 0\r\n",
        "  for label in labels:\r\n",
        "    # Masses\r\n",
        "    if label == 1 or label == 2:\r\n",
        "      labels_local[idx] = 0\r\n",
        "    # Calcifications\r\n",
        "    else:\r\n",
        "      labels_local[idx] = 1\r\n",
        "    idx += 1\r\n",
        "\r\n",
        "  return labels_local\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def cross_validate(k, batch_size, num_epochs, dataset, targets, verbosity, model_path):\r\n",
        "  #10-Fold-Cross-Validation\r\n",
        "  num_val_samples = len(dataset) // k \r\n",
        "  validation_accuracies = []\r\n",
        "  validation_losses = []\r\n",
        "  validation_precisions = []\r\n",
        "  validation_recalls = []\r\n",
        "  validation_aucs = []\r\n",
        "  model = models.load_model(os.path.join(MODEL_PATH, model_path))\r\n",
        "  for i in range(k):\r\n",
        "    # rigen augmented data \r\n",
        "    \r\n",
        "    print(\"processing fold #\", i)\r\n",
        "    validation_data = dataset[i * num_val_samples : (i + 1) * num_val_samples]\r\n",
        "    validation_labels = targets[i * num_val_samples : (i + 1) * num_val_samples]\r\n",
        "\r\n",
        "    partial_train_data = np.concatenate(\r\n",
        "        [dataset[:i * num_val_samples],\r\n",
        "        dataset[(i + 1) * num_val_samples:]], \r\n",
        "        axis=0)\r\n",
        "\r\n",
        "    partial_train_targets = np.concatenate(\r\n",
        "        [targets[:i * num_val_samples],\r\n",
        "        targets[(i + 1) * num_val_samples:]], \r\n",
        "        axis=0)\r\n",
        "\r\n",
        "    \r\n",
        "    \r\n",
        "    history = model.fit(train_datagen.flow(partial_train_data, \r\n",
        "                                          partial_train_targets,\r\n",
        "                                          batch_size=batch_size,\r\n",
        "                                          shuffle=False),\r\n",
        "                        epochs=num_epochs,\r\n",
        "                        steps_per_epoch=len(partial_train_data) // batch_size,\r\n",
        "                        verbose=verbosity,\r\n",
        "                        callbacks=[GarbageCollectorCallback()])\r\n",
        "    \r\n",
        "    val_loss, val_acc, val_prec, val_rec, val_auc= model.evaluate(valid_datagen.flow(validation_data,\r\n",
        "                                                          validation_labels,\r\n",
        "                                                          batch_size=batch_size,\r\n",
        "                                                          shuffle=False),\r\n",
        "                                       steps=len(validation_data) // batch_size,\r\n",
        "                                       callbacks=[GarbageCollectorCallback()])\r\n",
        "    \r\n",
        "    validation_accuracies.append(val_acc)\r\n",
        "    validation_losses.append(val_loss)\r\n",
        "    validation_precisions.append(val_prec)\r\n",
        "    validation_recalls.append(val_rec)\r\n",
        "    validation_aucs.append(val_auc)\r\n",
        "\r\n",
        "    ## ADDED TO TRY AND REDUCE RAM USAGE DURING CROSS VALIDATE\r\n",
        "    del partial_train_targets\r\n",
        "    del partial_train_data\r\n",
        "    del validation_data\r\n",
        "    del validation_labels\r\n",
        "    del history\r\n",
        "    \r\n",
        "  return validation_accuracies, validation_losses, validation_precisions, validation_recalls, validation_aucs\r\n",
        "\r\n",
        "\r\n",
        "def global_contrast_normalization(X):\r\n",
        "    X_average = np.mean(X)\r\n",
        "    #print('Mean: ', X_average)\r\n",
        "    X = X - X_average\r\n",
        "    return X\r\n",
        "\r\n",
        "# Visualization Confusion Matrix\r\n",
        "def plot_confusion_matrix(model,\r\n",
        "                          classes,\r\n",
        "                          dataset, \r\n",
        "                          labels,\r\n",
        "                          title='Confusion matrix',\r\n",
        "                          cmap=plt.cm.Blues):\r\n",
        "    \"\"\"\r\n",
        "    This function prints and plots the confusion matrix.\r\n",
        "    Normalization can be applied by setting `normalize=True`.\r\n",
        "    \"\"\"\r\n",
        "    Y_pred = model.predict(test_datagen.flow(dataset,\r\n",
        "                                            labels,\r\n",
        "                                            batch_size=21,\r\n",
        "                                            shuffle=False),\r\n",
        "                          steps=len(dataset) // BATCH_SIZE)\r\n",
        "\r\n",
        "    np.where(Y_pred < 0.5, 0, 1)\r\n",
        "    y_pred = np.where(Y_pred < 0.5, 0, 1)\r\n",
        "\r\n",
        "    print('Confusion Matrix')\r\n",
        "    cm = confusion_matrix(labels, y_pred)\r\n",
        "\r\n",
        "    #print(cm)\r\n",
        "    #print('Classification Report')\r\n",
        "    print(classification_report(labels, y_pred))\r\n",
        "\r\n",
        "\r\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\r\n",
        "    plt.title(title)\r\n",
        "    plt.colorbar()\r\n",
        "    tick_marks = np.arange(len(classes))\r\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\r\n",
        "    plt.yticks(tick_marks, classes)\r\n",
        "\r\n",
        "    #print(cm)\r\n",
        "\r\n",
        "    thresh = cm.max() / 2.\r\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\r\n",
        "        plt.text(j, i, cm[i, j],\r\n",
        "            horizontalalignment=\"center\",\r\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\r\n",
        "\r\n",
        "    plt.tight_layout()\r\n",
        "    plt.ylabel('True label')\r\n",
        "    plt.xlabel('Predicted label')\r\n",
        "\r\n",
        "    return plt\r\n",
        "\r\n",
        "\r\n",
        "def plot_loss(history):\r\n",
        "  acc = history.history['acc']\r\n",
        "  val_acc = history.history['val_acc']\r\n",
        "  loss = history.history['loss']\r\n",
        "  val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "  epochs = range(len(acc))\r\n",
        "\r\n",
        "  plt.figure()\r\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "  plt.title('Training and validation loss')\r\n",
        "  plt.legend()\r\n",
        "\r\n",
        "  return plt\r\n",
        "\r\n",
        "# Visualization Data Histogram\r\n",
        "def plot_acc(history):\r\n",
        "  acc = history.history['acc']\r\n",
        "  val_acc = history.history['val_acc']\r\n",
        "  loss = history.history['loss']\r\n",
        "  val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "  epochs = range(len(acc))\r\n",
        "\r\n",
        "  plt.figure()\r\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\r\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "  plt.title('Training and validation accuracy')\r\n",
        "  plt.legend()\r\n",
        "\r\n",
        "  return plt\r\n",
        "\r\n",
        "# Visualization Data Histogram\r\n",
        "def plot(history):\r\n",
        "  acc = history.history['accuracy']\r\n",
        "  val_acc = history.history['val_accuracy']\r\n",
        "  loss = history.history['loss']\r\n",
        "  val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "  epochs = range(len(acc))\r\n",
        "\r\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\r\n",
        "  plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "  plt.title('Training and validation accuracy')\r\n",
        "  plt.legend()\r\n",
        "\r\n",
        "  plt.figure()\r\n",
        "\r\n",
        "  plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "  plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "  plt.title('Training and validation loss')\r\n",
        "  plt.legend()\r\n",
        "\r\n",
        "  return plt\r\n",
        "\r\n",
        "# Visualization Detail Metric\r\n",
        "def plot_metrics(history):\r\n",
        "  metrics = ['loss', 'auc', 'precision', 'recall']\r\n",
        "  plt.figure(figsize=(12,10))\r\n",
        "\r\n",
        "  for n, metric in enumerate(metrics):\r\n",
        "    name = metric.replace(\"_\",\" \").capitalize()\r\n",
        "    plt.subplot(2,2,n+1)\r\n",
        "    plt.plot(history.epoch, history.history[metric], label='Train')\r\n",
        "    plt.plot(history.epoch, history.history['val_'+metric],\r\n",
        "             linestyle=\"--\", label='Val')\r\n",
        "    plt.xlabel('Epoch')\r\n",
        "    plt.ylabel(name)\r\n",
        "\r\n",
        "    if metric == 'loss':\r\n",
        "      plt.ylim([0, plt.ylim()[1]])\r\n",
        "    elif metric == 'auc':\r\n",
        "      plt.ylim([0.8,1])\r\n",
        "    else:\r\n",
        "      plt.ylim([0,1])\r\n",
        "\r\n",
        "    plt.legend()\r\n",
        "\r\n",
        "  return plt\r\n",
        "\r\n",
        "\r\n",
        "def plot_AUC(model, dataset, labels):\r\n",
        "  y_pred_keras = get_model_predictions(model, dataset, labels, len(dataset))\r\n",
        "  fpr_keras, tpr_keras, thresholds_keras = roc_curve(labels, y_pred_keras)\r\n",
        "  #thresholds_keras = np.linspace(0,1,num=100)\r\n",
        "  auc_keras = auc(fpr_keras, tpr_keras)\r\n",
        "\r\n",
        "  plt.figure(1)\r\n",
        "  plt.plot([0, 1], [0, 1], 'k--')\r\n",
        "  plt.plot(fpr_keras, tpr_keras, label='CNN (area = {:.3f})'.format(auc_keras))\r\n",
        "  plt.xlabel('False positive rate')\r\n",
        "  plt.ylabel('True positive rate')\r\n",
        "  plt.title('ROC curve')\r\n",
        "  plt.legend(loc='best')\r\n",
        "  #plt.show()\r\n",
        "\r\n",
        "  return auc_keras, plt\r\n",
        "\r\n",
        "def plot_AUC2(model, dataset, labels):\r\n",
        "  y_pred_keras = get_model_predictions(model, dataset, labels, len(dataset))\r\n",
        "  fpr_keras, tpr_keras, thresholds_keras = roc_curve(labels, y_pred_keras)\r\n",
        "  #thresholds_keras = np.linspace(0,1,num=100)\r\n",
        "  auc_keras = auc(fpr_keras, tpr_keras)\r\n",
        "\r\n",
        "  plt.figure(1)\r\n",
        "  plt.plot([0, 1], [0, 1], 'k--')\r\n",
        "  plt.plot(fpr_keras, tpr_keras, label='CNN (area = {:.3f})'.format(auc_keras))\r\n",
        "  plt.xlabel('False positive rate')\r\n",
        "  plt.ylabel('True positive rate')\r\n",
        "  plt.title('ROC curve')\r\n",
        "  plt.legend(loc='best')\r\n",
        "  plt.show()\r\n",
        "\r\n",
        "\r\n",
        "# Custom Callback To Include in Callbacks List At Training Time\r\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\r\n",
        "    def on_epoch_end(self, epoch, logs=None):\r\n",
        "      gc.collect()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "print(\"Done\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyFjHdpenDwG"
      },
      "source": [
        "## Init Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsndEObFnCeD"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "#all-in-one data loading & preprocessing function \r\n",
        "def init_data(base_NN, GCN=True, augmentation=True):\r\n",
        "  # Get images and labels (test, train)\r\n",
        "  train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "  # Get abnormalities only \r\n",
        "  train_images = remove_baseline(train_images)\r\n",
        "  train_labels = remove_baseline(train_labels)\r\n",
        "  test_images = remove_baseline(test_images)\r\n",
        "  test_labels = remove_baseline(test_labels)\r\n",
        "\r\n",
        "  # Suffle index (Previous dataset is ordered)\r\n",
        "  train_images, train_labels = shuffle_dataset(train_images, train_labels)\r\n",
        "\r\n",
        "  #print(\"Train shape: \", train_images.shape)\r\n",
        "  #print(\"Test shape: \", test_images.shape)\r\n",
        "\r\n",
        "  #1: Mass, benign\r\n",
        "  #2: Mass, malignant\r\n",
        "  #3: Calcification, benign\r\n",
        "  #4: Calcification, malignant\r\n",
        "\r\n",
        "  #count #of masses and #of calcifications\r\n",
        "  #unique, counts = np.unique(train_labels, return_counts=True)\r\n",
        "  #print(unique, counts)\r\n",
        "\r\n",
        "  #print(\"Benign Masses samples: \\t\", counts[0])\r\n",
        "  #print(\"Malign Masses samples: \\t\", counts[1])\r\n",
        "  #print(\"Benign Calc samples: \\t\", counts[2])\r\n",
        "  #print(\"Malign Calc samples: \\t\", counts[3])\r\n",
        "\r\n",
        "  #labels remapping\r\n",
        "  train_labels = labels_mapping(train_labels)\r\n",
        "  test_labels = labels_mapping(test_labels)\r\n",
        "\r\n",
        "  #tensors reshaping for models training \r\n",
        "  train_images = train_images.reshape(train_images.shape + (1,)) #(2676, 150, 150, 1)\r\n",
        "  test_images = test_images.reshape(test_images.shape + (1,)) #(2676, 150, 150, 1)\r\n",
        "  #print(train_images.shape)\r\n",
        "  #print(test_images.shape)\r\n",
        "\r\n",
        "  # split dataset into training and validation set 70-30\r\n",
        "  train_images_split, valid_images_split, train_labels_split, valid_labels_split = split_train_val(train_images, train_labels)  \r\n",
        "\r\n",
        "  # All images will be rescaled by 1./65535\r\n",
        "  if  base_NN == \"VGG16\":\r\n",
        "    from tensorflow.keras.applications.vgg16 import preprocess_input\r\n",
        "  if base_NN == \"ResNet50\":\r\n",
        "    from tensorflow.keras.applications.resnet import preprocess_input\r\n",
        "  #if Inception no preprocess function \r\n",
        "  if base_NN == \"InceptionV3\":\r\n",
        "    train_datagen = ImageDataGenerator(rescale=1./65535)\r\n",
        "    valid_datagen = ImageDataGenerator(rescale=1./65535)\r\n",
        "    test_datagen = ImageDataGenerator(rescale=1./65535) \r\n",
        "\r\n",
        "  if \"InceptionV3\" not in base_NN:\r\n",
        "    train_datagen = ImageDataGenerator(rescale=1./65535, preprocessing_function=preprocess_input)\r\n",
        "    valid_datagen = ImageDataGenerator(rescale=1./65535, preprocessing_function=preprocess_input)\r\n",
        "    test_datagen = ImageDataGenerator(rescale=1./65535, preprocessing_function=preprocess_input) \r\n",
        "\r\n",
        "  if GCN:\r\n",
        "    train_images_split_gcn = np.zeros(train_images_split.shape)  \r\n",
        "    train_labels_split_gcn = np.zeros(train_labels_split.shape)\r\n",
        "    valid_images_split_gcn = np.zeros(valid_images_split.shape)\r\n",
        "    valid_labels_split_gcn = np.zeros(valid_labels_split.shape)\r\n",
        "    train_datagen = ImageDataGenerator()\r\n",
        "    valid_datagen = ImageDataGenerator()\r\n",
        "    #global contrast normalization \r\n",
        "    counter = 0\r\n",
        "    for image, label in train_datagen.flow(train_images_split, train_labels_split, batch_size=1, shuffle=False):\r\n",
        "      #nomalize image\r\n",
        "      norm_image = global_contrast_normalization(image)\r\n",
        "      train_images_split_gcn[counter] = norm_image\r\n",
        "      train_labels_split_gcn[counter] = label\r\n",
        "      \r\n",
        "      counter += 1\r\n",
        "      if counter == len(train_images_split):\r\n",
        "        break\r\n",
        "    \r\n",
        "    counter = 0\r\n",
        "    for image, label in valid_datagen.flow(valid_images_split, valid_labels_split, batch_size=1, shuffle=False):\r\n",
        "      #nomalize image\r\n",
        "      norm_image = global_contrast_normalization(image)\r\n",
        "      valid_images_split_gcn[counter] = norm_image\r\n",
        "      valid_labels_split_gcn[counter] = label\r\n",
        "      \r\n",
        "      counter += 1\r\n",
        "      if counter == len(valid_images_split):\r\n",
        "        break\r\n",
        "    if base_NN == \"InceptionV3\":  \r\n",
        "      train_datagen = ImageDataGenerator(rescale=1./np.max(train_images_split_gcn))\r\n",
        "      valid_datagen = ImageDataGenerator(rescale=1./np.max(valid_images_split_gcn))     \r\n",
        "    else:\r\n",
        "      train_datagen = ImageDataGenerator(rescale=1./np.max(train_images_split_gcn), preprocessing_function=preprocess_input)\r\n",
        "      valid_datagen = ImageDataGenerator(rescale=1./np.max(valid_images_split_gcn), preprocessing_function=preprocess_input)      \r\n",
        "\r\n",
        "  if GCN and augmentation:\r\n",
        "    if base_NN == \"InceptionV3\":\r\n",
        "      train_datagen = ImageDataGenerator(\r\n",
        "          rescale=1./np.max(train_images_split_gcn),\r\n",
        "          rotation_range=40,\r\n",
        "          width_shift_range=0.25,\r\n",
        "          height_shift_range=0.25,\r\n",
        "          shear_range=20,\r\n",
        "          zoom_range=(0.5,1.5),\r\n",
        "          horizontal_flip=True,\r\n",
        "          fill_mode='nearest')\r\n",
        "    else:\r\n",
        "      train_datagen = ImageDataGenerator(\r\n",
        "          rescale=1./np.max(train_images_split_gcn),\r\n",
        "          preprocessing_function=preprocess_input,\r\n",
        "          rotation_range=40,\r\n",
        "          width_shift_range=0.25,\r\n",
        "          height_shift_range=0.25,\r\n",
        "          shear_range=20,\r\n",
        "          zoom_range=(0.5,1.5),\r\n",
        "          horizontal_flip=True,\r\n",
        "          fill_mode='nearest')\r\n",
        "\r\n",
        "  if not GCN and augmentation:\r\n",
        "    if base_NN == \"InceptionV3\":\r\n",
        "      train_datagen = ImageDataGenerator(\r\n",
        "          rescale=1./65535,\r\n",
        "          rotation_range=40,\r\n",
        "          width_shift_range=0.25,\r\n",
        "          height_shift_range=0.25,\r\n",
        "          shear_range=20,\r\n",
        "          zoom_range=(0.5,1.5),\r\n",
        "          horizontal_flip=True,\r\n",
        "          fill_mode='nearest')\r\n",
        "    else:\r\n",
        "      train_datagen = ImageDataGenerator(\r\n",
        "          rescale=1./65535,\r\n",
        "          preprocessing_function=preprocess_input,\r\n",
        "          rotation_range=40,\r\n",
        "          width_shift_range=0.25,\r\n",
        "          height_shift_range=0.25,\r\n",
        "          shear_range=20,\r\n",
        "          zoom_range=(0.5,1.5),\r\n",
        "          horizontal_flip=True,\r\n",
        "          fill_mode='nearest')\r\n",
        "\r\n",
        "  print(\"Done\")\r\n",
        "  if GCN:\r\n",
        "    #reshape to expand grayscale to rgb\r\n",
        "    train_images_split_gcn = np.repeat(train_images_split, 3, axis = 3)\r\n",
        "    valid_images_split_gcn = np.repeat(valid_images_split, 3, axis = 3)\r\n",
        "    return train_images_split_gcn, valid_images_split_gcn, train_labels_split_gcn, valid_labels_split_gcn, train_datagen, valid_datagen, test_datagen\r\n",
        "  else:\r\n",
        "    #reshape to expand grayscale to rgb\r\n",
        "    train_images_split = np.repeat(train_images_split, 3, axis = 3)\r\n",
        "    valid_images_split = np.repeat(valid_images_split, 3, axis = 3)\r\n",
        "    return train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kz2-Tgv4Uao"
      },
      "source": [
        "# 0.2 Set Metrics and Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43tqiH0zi09-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea93b8b7-014e-446f-8e1c-3ce972f6f1f2"
      },
      "source": [
        "INPUT_SHAPE = (150, 150, 3)\r\n",
        "IMG_HEIGHT = 150\r\n",
        "IMG_WIDTH = 150\r\n",
        "BATCH_SIZE = 20\r\n",
        "\r\n",
        "\r\n",
        "METRICS = [\r\n",
        "      metrics.BinaryAccuracy(name='acc'),\r\n",
        "      #metrics.Precision(name='precision'),\r\n",
        "      #metrics.Recall(name='recall'),\r\n",
        "      #metrics.AUC(name='auc'),\r\n",
        "      # metrics.TruePositives(name='tp'),\r\n",
        "      # metrics.FalsePositives(name='fp'),\r\n",
        "      # metrics.TrueNegatives(name='tn'),\r\n",
        "      # metrics.FalseNegatives(name='fn'),     \r\n",
        "]\r\n",
        "\r\n",
        "es = tf.keras.callbacks.EarlyStopping(\r\n",
        "     monitor='val_loss', patience=20, verbose=0,\r\n",
        "     mode='auto', restore_best_weights=True\r\n",
        ")\r\n",
        "\r\n",
        "# Custom Callback To Include in Callbacks List At Training Time\r\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\r\n",
        "    def on_epoch_end(self, epoch, logs=None):\r\n",
        "      gc.collect()\r\n",
        "\r\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWftfVoEl2Gu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIYbDHGbx5Ba"
      },
      "source": [
        "# Architecture : Flatten/GlobalAveragePooling, Dense 256"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0W8TuHmlax5Z"
      },
      "source": [
        "## Flatten, all trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrO0p8BQZ-sP",
        "outputId": "77f0d499-89b0-42c8-ddba-2803ec892279"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50v2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 156, 156, 3)  0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 75, 75, 64)   9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 77, 77, 64)   0           conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 38, 38, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_bn (BatchNo (None, 38, 38, 64)   256         pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_preact_relu (Activ (None, 38, 38, 64)   0           conv2_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 38, 38, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 38, 38, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_pad (ZeroPadding (None, 40, 40, 64)   0           conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 38, 38, 64)   36864       conv2_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 38, 38, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Add)          (None, 38, 38, 256)  0           conv2_block1_0_conv[0][0]        \n",
            "                                                                 conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_bn (BatchNo (None, 38, 38, 256)  1024        conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_preact_relu (Activ (None, 38, 38, 256)  0           conv2_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 38, 38, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 38, 38, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_pad (ZeroPadding (None, 40, 40, 64)   0           conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 38, 38, 64)   36864       conv2_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 38, 38, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 38, 38, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Add)          (None, 38, 38, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_bn (BatchNo (None, 38, 38, 256)  1024        conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_preact_relu (Activ (None, 38, 38, 256)  0           conv2_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 38, 38, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 38, 38, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 38, 38, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_pad (ZeroPadding (None, 40, 40, 64)   0           conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 19, 19, 64)   36864       conv2_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 19, 19, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 19, 19, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, 19, 19, 256)  0           conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 19, 19, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Add)          (None, 19, 19, 256)  0           max_pooling2d_6[0][0]            \n",
            "                                                                 conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_bn (BatchNo (None, 19, 19, 256)  1024        conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_preact_relu (Activ (None, 19, 19, 256)  0           conv3_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 19, 19, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 19, 19, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 19, 19, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 19, 19, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Add)          (None, 19, 19, 512)  0           conv3_block1_0_conv[0][0]        \n",
            "                                                                 conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 19, 19, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 19, 19, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Add)          (None, 19, 19, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 19, 19, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 19, 19, 128)  147456      conv3_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 19, 19, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 19, 19, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Add)          (None, 19, 19, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_bn (BatchNo (None, 19, 19, 512)  2048        conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_preact_relu (Activ (None, 19, 19, 512)  0           conv3_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 19, 19, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 19, 19, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 19, 19, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_pad (ZeroPadding (None, 21, 21, 128)  0           conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 10, 10, 128)  147456      conv3_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 10, 10, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 10, 10, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, 10, 10, 512)  0           conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 10, 10, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Add)          (None, 10, 10, 512)  0           max_pooling2d_7[0][0]            \n",
            "                                                                 conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_bn (BatchNo (None, 10, 10, 512)  2048        conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_preact_relu (Activ (None, 10, 10, 512)  0           conv4_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 10, 10, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 10, 10, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 10, 10, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 10, 10, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Add)          (None, 10, 10, 1024) 0           conv4_block1_0_conv[0][0]        \n",
            "                                                                 conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 10, 10, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 10, 10, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Add)          (None, 10, 10, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 10, 10, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 10, 10, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Add)          (None, 10, 10, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 10, 10, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block4_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 10, 10, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Add)          (None, 10, 10, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 10, 10, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 10, 10, 256)  589824      conv4_block5_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 10, 10, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 10, 10, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Add)          (None, 10, 10, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_bn (BatchNo (None, 10, 10, 1024) 4096        conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_preact_relu (Activ (None, 10, 10, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 10, 10, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 10, 10, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 10, 10, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_pad (ZeroPadding (None, 12, 12, 256)  0           conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 5, 5, 256)    589824      conv4_block6_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 5, 5, 256)    1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 5, 5, 256)    0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, 5, 5, 1024)   0           conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 5, 5, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Add)          (None, 5, 5, 1024)   0           max_pooling2d_8[0][0]            \n",
            "                                                                 conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_bn (BatchNo (None, 5, 5, 1024)   4096        conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_preact_relu (Activ (None, 5, 5, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 5, 5, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 5, 5, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_pad (ZeroPadding (None, 7, 7, 512)    0           conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 5, 5, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 5, 5, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 5, 5, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Add)          (None, 5, 5, 2048)   0           conv5_block1_0_conv[0][0]        \n",
            "                                                                 conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_bn (BatchNo (None, 5, 5, 2048)   8192        conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_preact_relu (Activ (None, 5, 5, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 5, 5, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 5, 5, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_pad (ZeroPadding (None, 7, 7, 512)    0           conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 5, 5, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 5, 5, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Add)          (None, 5, 5, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_bn (BatchNo (None, 5, 5, 2048)   8192        conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_preact_relu (Activ (None, 5, 5, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 5, 5, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 5, 5, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_pad (ZeroPadding (None, 7, 7, 512)    0           conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 5, 5, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 5, 5, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 5, 5, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 5, 5, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Add)          (None, 5, 5, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "post_bn (BatchNormalization)    (None, 5, 5, 2048)   8192        conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "post_relu (Activation)          (None, 5, 5, 2048)   0           post_bn[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,564,800\n",
            "Trainable params: 23,519,360\n",
            "Non-trainable params: 45,440\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g1xBBqeCZ-oa",
        "outputId": "0a78ee33-f582-417b-e1e8-96cd2fe23f16"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1873, 150, 150, 1)\n",
            "(803, 150, 150, 1)\n",
            "(1873,)\n",
            "(803,)\n",
            "Done\n",
            "\n",
            "(1873, 150, 150, 3)\n",
            "(336, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTPM15r1Z-VQ",
        "outputId": "869fa525-a1a8-4920-8ed1-8f3df9e26ec8"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "#conv_base.trainable = True\r\n",
        "\r\n",
        "for layer in model.layers:\r\n",
        "  layer.trainable = True\r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-3\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50v2 (Functional)      (None, 5, 5, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 36,672,513\n",
            "Trainable params: 13,107,713\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "93/93 [==============================] - 15s 131ms/step - loss: 5.1333 - acc: 0.5486 - val_loss: 1.3054 - val_acc: 0.5350\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.30538, saving model to checkpoint.h5\n",
            "Epoch 2/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 4.4602 - acc: 0.5222 - val_loss: 0.8994 - val_acc: 0.5375\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.30538 to 0.89936, saving model to checkpoint.h5\n",
            "Epoch 3/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 1.1643 - acc: 0.5519 - val_loss: 0.8867 - val_acc: 0.5387\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.89936 to 0.88671, saving model to checkpoint.h5\n",
            "Epoch 4/15\n",
            "93/93 [==============================] - 11s 120ms/step - loss: 0.9079 - acc: 0.5419 - val_loss: 0.6893 - val_acc: 0.5400\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.88671 to 0.68931, saving model to checkpoint.h5\n",
            "Epoch 5/15\n",
            "93/93 [==============================] - 11s 119ms/step - loss: 0.6835 - acc: 0.5528 - val_loss: 0.6893 - val_acc: 0.5387\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.68931\n",
            "Epoch 6/15\n",
            "93/93 [==============================] - 11s 120ms/step - loss: 0.6841 - acc: 0.5688 - val_loss: 0.6891 - val_acc: 0.5375\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.68931 to 0.68914, saving model to checkpoint.h5\n",
            "Epoch 7/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.6860 - acc: 0.5404 - val_loss: 0.6903 - val_acc: 0.5362\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.68914\n",
            "Epoch 8/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.6848 - acc: 0.5542 - val_loss: 0.6914 - val_acc: 0.5350\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.68914\n",
            "Epoch 9/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.6858 - acc: 0.5368 - val_loss: 0.6924 - val_acc: 0.5362\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.68914\n",
            "Epoch 10/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.6851 - acc: 0.5547 - val_loss: 0.6909 - val_acc: 0.5350\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.68914\n",
            "Epoch 11/15\n",
            "93/93 [==============================] - 11s 120ms/step - loss: 0.6854 - acc: 0.5429 - val_loss: 0.6922 - val_acc: 0.5375\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.68914\n",
            "Epoch 12/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.6887 - acc: 0.5504 - val_loss: 0.6917 - val_acc: 0.5337\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.68914\n",
            "Epoch 13/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.6797 - acc: 0.5613 - val_loss: 0.6925 - val_acc: 0.5375\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.68914\n",
            "Epoch 14/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.7017 - acc: 0.5581 - val_loss: 0.6919 - val_acc: 0.5362\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.68914\n",
            "Epoch 15/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.6839 - acc: 0.5576 - val_loss: 0.6933 - val_acc: 0.5362\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.68914\n",
            "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6b8892dfd0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b8890fcc0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b888f4c18>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b8849fe80>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6b88449208>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88997d68>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b8846b6a0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b8842b9e8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b889bb438>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b8838cb70>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b881807b8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88180828>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b883a4080>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b903fc390>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88934cc0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b903fcfd0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b884124a8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b883ced30>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b883a3d30>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b8838cf60>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b880fd5c0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b88086a20>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b880fd780>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88090ba8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88096668>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b88096f28>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b8809e128>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b880a6780>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b880aa710>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b880aa898>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b880b7160>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b880b7c50>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b880b7e10>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b88048390>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88048dd8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b8804f898>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b880483c8>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6b880b36a0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88060470>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b88060588>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88058908>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b880647b8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88070780>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88058a20>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b8807b4a8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b8807bd68>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88075f28>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e0f84a8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e0fe940>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88070fd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0fe208>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b88075e80>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e10ae48>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e10cbe0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b8807bb70>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e118e10>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e11edd8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5e118390>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e10c5c0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e0f86d8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b88064320>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88048eb8>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b880b7668>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b880a6eb8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b9021fc18>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b8809e2e8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88090c88>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b880864e0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b88058f60>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b883a3400>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b880a7470>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b880a7f28>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0b4940>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5e0b9588>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e0c0518>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e0c0898>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0c8dd8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e0cfa58>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e0cf630>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5e0d5fd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0dcbe0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e0e36a0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e0dc438>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6b5e0c84a8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0f0278>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5e0f0e80>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e0e7ac8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e076710>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e084630>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e0e7630>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e0902b0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5e090f60>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0e71d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e09a400>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e0a1be0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e084d30>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e09a780>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5e0a8cf8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e0aec88>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e0ae358>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0a1208>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e09a5c0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e0e78d0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5e0a85c0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0d5b70>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e0b9f28>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b883a39b0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0b4080>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b88090198>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88086b70>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b880bda90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b880aaa20>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88060630>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e036f28>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5e03dd30>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0427b8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e049278>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e0498d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e053748>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5e057390>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e060320>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e057ac8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0692b0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e069e80>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e06ee48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6960b9aa20>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960ba34a8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960ba3f60>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960baaef0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960bb1438>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6960bb6080>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960bbf160>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960bb65c0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960bbffd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960bc6b70>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960bcbb38>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6960b58710>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b58eb8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b5ec18>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960b5e358>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b6b128>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6960b6bd30>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b6fcc0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960b6f550>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b58048>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960bcb6a0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960bcb1d0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6960ba3c18>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b9a978>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e06e780>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960bb15f8>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6960b61780>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e053208>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b880757f0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5e060b38>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e03d630>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0d5a90>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b9acc0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5e076550>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5e0e74e0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5e0e3fd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b79b70>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960b85a20>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b880bdd30>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b85198>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5e087630>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b8ef60>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960b92cc0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b8e860>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b1bf28>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960b24eb8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6960b8e400>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b34518>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b34fd0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960b38780>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b2a4e0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5e0b40f0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b34ac8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960b4afd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b38dd8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b34358>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960adac88>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6960b24e80>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b34f60>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b4acc0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960aef5c0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960aefcc0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6960ae52e8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960ada940>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6960b4a6a0>]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50v2 (Functional)      (None, 5, 5, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 36,672,513\n",
            "Trainable params: 36,627,073\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "93/93 [==============================] - 19s 156ms/step - loss: 0.6026 - acc: 0.6275 - val_loss: 0.6948 - val_acc: 0.5412\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.68914\n",
            "Epoch 2/50\n",
            "93/93 [==============================] - 14s 149ms/step - loss: 0.4818 - acc: 0.7833 - val_loss: 0.5524 - val_acc: 0.7775\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.68914 to 0.55241, saving model to checkpoint.h5\n",
            "Epoch 3/50\n",
            "93/93 [==============================] - 14s 149ms/step - loss: 0.4374 - acc: 0.8036 - val_loss: 0.5819 - val_acc: 0.6712\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.55241\n",
            "Epoch 4/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.4138 - acc: 0.8202 - val_loss: 0.4430 - val_acc: 0.8175\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.55241 to 0.44295, saving model to checkpoint.h5\n",
            "Epoch 5/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.4207 - acc: 0.7973 - val_loss: 0.4285 - val_acc: 0.7962\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.44295 to 0.42848, saving model to checkpoint.h5\n",
            "Epoch 6/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3353 - acc: 0.8582 - val_loss: 0.7962 - val_acc: 0.5850\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.42848\n",
            "Epoch 7/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.3834 - acc: 0.8222 - val_loss: 0.4096 - val_acc: 0.8025\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.42848 to 0.40964, saving model to checkpoint.h5\n",
            "Epoch 8/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.3769 - acc: 0.8290 - val_loss: 0.5639 - val_acc: 0.6400\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.40964\n",
            "Epoch 9/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.3737 - acc: 0.8317 - val_loss: 0.5452 - val_acc: 0.7625\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.40964\n",
            "Epoch 10/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.3498 - acc: 0.8436 - val_loss: 0.3474 - val_acc: 0.8825\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.40964 to 0.34741, saving model to checkpoint.h5\n",
            "Epoch 11/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3216 - acc: 0.8541 - val_loss: 0.5691 - val_acc: 0.6750\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.34741\n",
            "Epoch 12/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.3549 - acc: 0.8339 - val_loss: 0.5784 - val_acc: 0.7038\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.34741\n",
            "Epoch 13/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.3859 - acc: 0.8413 - val_loss: 0.4840 - val_acc: 0.7650\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.34741\n",
            "Epoch 14/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.3968 - acc: 0.8409 - val_loss: 1.1881 - val_acc: 0.7050\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.34741\n",
            "Epoch 15/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.3835 - acc: 0.8551 - val_loss: 0.3406 - val_acc: 0.8662\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.34741 to 0.34056, saving model to checkpoint.h5\n",
            "Epoch 16/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.4016 - acc: 0.8463 - val_loss: 0.6436 - val_acc: 0.6862\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.34056\n",
            "Epoch 17/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3608 - acc: 0.8338 - val_loss: 0.9339 - val_acc: 0.6625\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.34056\n",
            "Epoch 18/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.4375 - acc: 0.8217 - val_loss: 0.5172 - val_acc: 0.7088\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.34056\n",
            "Epoch 19/50\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.3377 - acc: 0.8655 - val_loss: 0.5599 - val_acc: 0.7725\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.34056\n",
            "Epoch 20/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3633 - acc: 0.8672 - val_loss: 1.1979 - val_acc: 0.5638\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.34056\n",
            "Epoch 21/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3437 - acc: 0.8527 - val_loss: 0.5220 - val_acc: 0.7812\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.34056\n",
            "Epoch 22/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3575 - acc: 0.8633 - val_loss: 0.4048 - val_acc: 0.8275\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.34056\n",
            "Epoch 23/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.3488 - acc: 0.8559 - val_loss: 0.2919 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00023: val_loss improved from 0.34056 to 0.29192, saving model to checkpoint.h5\n",
            "Epoch 24/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3517 - acc: 0.8648 - val_loss: 0.4645 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.29192\n",
            "Epoch 25/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3890 - acc: 0.8442 - val_loss: 0.3680 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.29192\n",
            "Epoch 26/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3483 - acc: 0.8710 - val_loss: 0.3611 - val_acc: 0.8800\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.29192\n",
            "Epoch 27/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.3325 - acc: 0.8765 - val_loss: 0.4297 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.29192\n",
            "Epoch 28/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.3484 - acc: 0.8660 - val_loss: 0.4258 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.29192\n",
            "Epoch 29/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2722 - acc: 0.8762 - val_loss: 0.2756 - val_acc: 0.8863\n",
            "\n",
            "Epoch 00029: val_loss improved from 0.29192 to 0.27557, saving model to checkpoint.h5\n",
            "Epoch 30/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2993 - acc: 0.8772 - val_loss: 0.3020 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.27557\n",
            "Epoch 31/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.3580 - acc: 0.8505 - val_loss: 0.3905 - val_acc: 0.8475\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.27557\n",
            "Epoch 32/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2920 - acc: 0.8834 - val_loss: 0.3196 - val_acc: 0.8700\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.27557\n",
            "Epoch 33/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3032 - acc: 0.8745 - val_loss: 0.2800 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.27557\n",
            "Epoch 34/50\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.2896 - acc: 0.8776 - val_loss: 0.2985 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.27557\n",
            "Epoch 35/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2935 - acc: 0.8896 - val_loss: 0.2485 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00035: val_loss improved from 0.27557 to 0.24847, saving model to checkpoint.h5\n",
            "Epoch 36/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2788 - acc: 0.8859 - val_loss: 0.2599 - val_acc: 0.9025\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.24847\n",
            "Epoch 37/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2922 - acc: 0.8792 - val_loss: 0.2931 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.24847\n",
            "Epoch 38/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2677 - acc: 0.8808 - val_loss: 0.2640 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.24847\n",
            "Epoch 39/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.3017 - acc: 0.8857 - val_loss: 0.2895 - val_acc: 0.8763\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.24847\n",
            "Epoch 40/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2696 - acc: 0.9058 - val_loss: 0.2365 - val_acc: 0.9137\n",
            "\n",
            "Epoch 00040: val_loss improved from 0.24847 to 0.23646, saving model to checkpoint.h5\n",
            "Epoch 41/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2737 - acc: 0.8947 - val_loss: 0.2484 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.23646\n",
            "Epoch 42/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2457 - acc: 0.8970 - val_loss: 0.3006 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.23646\n",
            "Epoch 43/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2987 - acc: 0.8981 - val_loss: 0.2421 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.23646\n",
            "Epoch 44/50\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.2814 - acc: 0.9058 - val_loss: 0.2323 - val_acc: 0.9125\n",
            "\n",
            "Epoch 00044: val_loss improved from 0.23646 to 0.23234, saving model to checkpoint.h5\n",
            "Epoch 45/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2324 - acc: 0.9112 - val_loss: 0.3229 - val_acc: 0.8625\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.23234\n",
            "Epoch 46/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2506 - acc: 0.9007 - val_loss: 0.3372 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.23234\n",
            "Epoch 47/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2790 - acc: 0.8876 - val_loss: 0.3162 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.23234\n",
            "Epoch 48/50\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.2628 - acc: 0.9012 - val_loss: 0.7425 - val_acc: 0.6612\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.23234\n",
            "Epoch 49/50\n",
            "93/93 [==============================] - 14s 155ms/step - loss: 0.2667 - acc: 0.8902 - val_loss: 0.2813 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.23234\n",
            "Epoch 50/50\n",
            "93/93 [==============================] - 14s 155ms/step - loss: 0.2621 - acc: 0.8954 - val_loss: 0.5383 - val_acc: 0.7225\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.23234\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "46wAVTAXa8Ei",
        "outputId": "90d0e10d-40c7-4404-9603-57447308ed66"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZgU1dm374dhGdZhE1GHVUFBcdiEKC4Yo0GTgBglIEYRVxJi1BiXaNSYkE9fjYa8URPUuBtEkxCTEH1NHIxKogybBhQFRBk22R1kZ873x6lianqquqt6qpdpnvu6+uqq6lpOVXf/6lfPOec5YoxBURRFKVwa5boAiqIoSmZRoVcURSlwVOgVRVEKHBV6RVGUAkeFXlEUpcBRoVcURSlwVOgPQkTk7yJySdzr5hIRWSkiX8nAfo2IHOVM/0ZEfhxm3TSOM15E/i/dcipKMkTb0TcMRGS7Z7YFsBvY78xfZYx5Nvulyh9EZCVwuTHmHzHv1wC9jDHL4lpXRLoDHwNNjDH74iinoiSjca4LoITDGNPKnU4maiLSWMVDyRf095gfaOimgSMiw0WkUkRuEpF1wOMi0k5E/ioiG0RkizNd6tlmtohc7kxPEJE3ReQ+Z92PReTsNNftISL/EpEqEfmHiDwoIs8ElDtMGX8qIm85+/s/Eeno+fzbIvKJiGwSkVuTXJ+hIrJORIo8y0aLyLvO9BAR+beIbBWRtSLyaxFpGrCvJ0TkZ575HzrbrBGRiQnrfk1EFojI5yKySkTu9Hz8L+d9q4hsF5ET3Wvr2f4kEZkrItuc95PCXpuI17m9iDzunMMWEZnp+WyUiCx0zmG5iIxwltcKk4nIne73LCLdnRDWZSLyKfCas/wF53vY5vxGjvVs31xEfuF8n9uc31hzEfmbiHwv4XzeFZHRfueqBKNCXxh0BtoD3YArsd/r4858V2An8Osk2w8FlgIdgf8BHhMRSWPd54B3gA7AncC3kxwzTBkvBC4FOgFNgRsARKQv8LCz/8Od45XigzHmbeAL4MsJ+33Omd4PXOecz4nAGcB3kpQbpwwjnPKcCfQCEusHvgAuBtoCXwMmici5zmenOu9tjTGtjDH/Tth3e+BvwK+cc7sf+JuIdEg4hzrXxodU1/lpbCjwWGdfDzhlGAI8BfzQOYdTgZVB18OH04A+wFed+b9jr1MnYD7gDTXeBwwCTsL+jm8EqoEngYvclUSkDDgCe22UKBhj9NXAXtg/3Fec6eHAHqA4yfr9gS2e+dnY0A/ABGCZ57MWgAE6R1kXKyL7gBaez58Bngl5Tn5lvM0z/x3gZWf6dmC657OWzjX4SsC+fwb8zplujRXhbgHrXgv8yTNvgKOc6SeAnznTvwPu9qzX27uuz35/CTzgTHd31m3s+XwC8KYz/W3gnYTt/w1MSHVtolxn4DCsoLbzWe+3bnmT/f6c+Tvd79lzbj2TlKGts04J9ka0EyjzWa8Y2IKt9wB7Q3go2/+3Qnipoy8MNhhjdrkzItJCRH7rPAp/jg0VtPWGLxJY504YY3Y4k60irns4sNmzDGBVUIFDlnGdZ3qHp0yHe/dtjPkC2BR0LKx7P09EmgHnAfONMZ845ejthDPWOeX4Odbdp6JWGYBPEs5vqIiUOyGTbcDVIffr7vuThGWfYN2sS9C1qUWK69wF+51t8dm0C7A8ZHn9OHBtRKRIRO52wj+fU/Nk0NF5Ffsdy/lNPw9cJCKNgHHYJxAlIir0hUFi06kfAEcDQ40xbagJFQSFY+JgLdBeRFp4lnVJsn59yrjWu2/nmB2CVjbGLMEK5dnUDtuADQF9gHWNbYAfpVMG7BONl+eAl4AuxpgS4Dee/aZq6rYGG2rx0hVYHaJciSS7zquw31lbn+1WAUcG7PML7NOcS2efdbzneCEwChveKsG6frcMG4FdSY71JDAeG1LbYRLCXEo4VOgLk9bYx+GtTrz3jkwf0HHIFcCdItJURE4EvpGhMr4IfF1ETnYqTu8i9W/5OeD7WKF7IaEcnwPbReQYYFLIMswAJohIX+dGk1j+1li3vMuJd1/o+WwDNmTSM2Dfs4DeInKhiDQWkW8BfYG/hixbYjl8r7MxZi02dv6QU2nbRETcG8FjwKUicoaINBKRI5zrA7AQGOusPxg4P0QZdmOfulpgn5rcMlRjw2D3i8jhjvs/0Xn6whH2auAXqJtPGxX6wuSXQHOsW/oP8HKWjjseW6G5CRsXfx77B/cj7TIaYxYD38WK91psHLcyxWa/x1YQvmaM2ehZfgNWhKuAR5wyhynD351zeA1Y5rx7+Q5wl4hUYesUZni23QFMAd4S29rnSwn73gR8HevGN2ErJ7+eUO6wpLrO3wb2Yp9qPsPWUWCMeQdb2fsAsA14nZqnjB9jHfgW4CfUfkLy4ynsE9VqYIlTDi83AO8Bc4HNwD3U1qangH7YOh8lDbTDlJIxROR54ANjTMafKJTCRUQuBq40xpyc67I0VNTRK7EhIieIyJHOo/4IbFx2ZqrtFCUIJyz2HWBarsvSkFGhV+KkM7bp33ZsG/BJxpgFOS2R0mARka9i6zPWkzo8pCRBQzeKoigFjjp6RVGUAifvkpp17NjRdO/ePdfFUBRFaVDMmzdvozHmEL/P8k7ou3fvTkVFRa6LoSiK0qAQkcTe1AfQ0I2iKEqBo0KvKIpS4KjQK4qiFDgq9IqiKAWOCr2iKEqBo0KvKIpS4KjQK4qiFDh5145eURQFYPduWLMGVq+2r8pKOPJIOPfc1NsqtVGhVxQlr5g8GWbMgA0b6n7WuDEsXgy9e9fvGJs2QUmJ3d/BgIZuFEXJGzZtgocfhj594K674LHH4OWX4b33YOlSKC6Gm2+u3zHefx+6dYN77omnzH48+yx07w6NGtn3Z5/N3LHCcJDczxRFaQj89a9QXQ333w+DBtX9/Kab4Mc/hjfegFNOib7/Xbtg3Dj44gt49VW49db6lzmRZ5+FK6+EHTvs/Cef2HmA8ePjP14Y1NEripI3/OlPUFoKAwf6f3799XD44fDDH0I6GdZvvhkWLbI3kbffhj176ldeP269tUbkXXbsyMxNJSwq9Iqi5AU7dsDf/w7btkFRkX/Io0UL+NnPrEi/8ILvbgKZNQumToXvfQ9+9CPr7ufPj634B/j002jLs0EooReRESKyVESWiUidCJmIdBORf4rIuyIyW0RKPZ9dIiIfOa9L4iy8oiiFw623WoddVWXduhvySBT7iy+Gfv2sO98dNPR8AmvXwoQJcPzxMGAAfP/7dvnZZ8cfP+/aNdryrGCMSfoCioDlQE+gKbAI6JuwzgvAJc70l4Gnnen2wArnvZ0z3S7Z8QYNGmQURck/3n3XmNGjjRkzxpg9e+Lff8uWxliJr/3q1q3uuq+8Yj+7//7U+92/35gzzzSmeXNj7rnHmBYtau+/RQtjnnnGvrp1M0bEvj/zTHrn8cwzwccwxpj1643ZsSO9fScDqDBBOh70wYEV4ETgFc/8LcAtCessBro40wJ87kyPA37rWe+3wLhkx1OhV5T84uOPjbn4YiuArVpZ1bjsMmOqq+M7xt69/iIP9rh+nHWWvTmUliYX53vvtfv5zW/sOn7H6NAh3htAsm169DDmttuiXqHU1Ffozwce9cx/G/h1wjrPAd93ps8DDNABuAG4zbPej4EbfI5xJVABVHTt2jX+K6AoSmTWrzfmmmuMadLEmOJiY374Q2M2bjTm1lutctxzT3zHKi8PFno/R2+MMT//ed11vc7ZGGMqKmz5zzvP3phEgo8T9QaQDk8/Xfu80t2PH9kQ+sOBPwILgKlAJdA2rNB7X+roFSX3PPCAde+NGhlz+eXGrFpV89n+/cZ861tWPV58MZ7jff/7VpCbNw8vqkHuvGtXY957z5grrjCmcWO7rLS0xmVHEfqoN59kPPNMtPOLSsZDNwnrtwIqnWkN3ShKjqmoMOaEE4z573/Drf/yy1YZzj7bmPff919n505jTjzROv233w7e1549xixYkDzMU11txfkb34gWJonqzlu0MGbSpLoOvajIOvco+woKJyUj6CaTzk3Dj/oKfWOnErWHpzL22IR1OgKNnOkpwF3OdHvgY6citp0z3T7Z8VToFSVeRoyw//R+/axAJ2PrVut++/RJve769TbefOihxqxcWfuzdeuMuesuYw4/3B774YeD9zN/vl3nscfCnY9LkHC2bh0s3O7Nw72ZtGhhTKdOwRWoYfcTJgwTdGNK56bhR72E3m7POcCHTuubW51ldwEjnenzgY+cdR4Fmnm2nQgsc16XpjqWCr2ixMeCBfZffs459n3y5OTrT5xowzWdO4cTsCVLjCkpMea44+xN4u23jbnoImOaNrXHKy6uEbOgFjK3326P+dln0c4tWeuWsKJ6//12+erV/sIddAy/J4NUYZi8dvTZfqnQK0p8jB1rHe6WLcZce639x7/0kv+6f/ub/dyNaycKWJCDvfnm2usXF9sWMa7Iu69GjYx56qm6xz3+eGNOOSX5eQQdO2h5WFGdO9cunzEj2rHTEe1nnjGmWbNo1zYKKvSKkmNefdWGAXr1Mub0063rvekmY371K2P++EfrhCsrjdm3L75jLltmxfXGG+38rl3G9O9vy7F6de11N2+2YZYmTfwFLKj1iZ+zbd48OOTRvn3t4y5fbpcnaw+fql16fbbZu9c20bzmmvDX1Zj0wzA33lizbteuyZ8aooq9Cr2i5JhzzjGmY0fb2WjYMOva/ES1USMruEOG2CaB//53+se86iobQlmzpmbZ++9bETnjDNt6xuXii22lZFDlY9ArnW2WLas5rhs6Wb48+DzSDXmEdclnnGHMgAHJ9xVXmV58sWZd93uJK6SjQl8gzJ9f+8+pNAw+/dQKeGInmf37bYXmvHk2nPLww3adCRNsT87Wre0NIh3WrLEif+WVdT975BH7z7/7bjv/5z/b+dtvj6/5YdBLxIZpnnqq5lhNmqTXuiauSsw77rDfz7Zt4bdJ14U//njN+osX22VxnZ8KfQGwZIn9tmbNynVJlKj85Cf2u1uxItp2119vxfrzz6Mf86abrHh99FHdz6qrjTn/fOvGO3WqEdsnnoje+iTI0QeFeq68suZ4YUUy05WYr75q9/fKK9G2Syeu/r//W1P+N9+0y7Lh6DV7ZQNhxQr7vnZtbsuhWMaOhcsvT73e/v128Iwzz4QePaId49xzbZKvl19Ova53oIuuXW2WxgsusFkeEwfAELHlqa6Gzz6z2+/dC9/5jp2eNs0OzCFi36dNs/tr0aL2MVu0sEnH/JZPneq/n9/8Bpo3t8fzkiyN75Qp/seYMiX1dQnD0KE2W+abb0bbbvx4WLnSXseVK8Plmq+qqpneutW+Z/r8AHX0DQX3cfuBB3JdEmXNmprH7Xnzkq/rJt96/vnox9m3z5hDDjHmwgtrloVtAgjWtQeFF9JtNRKl5UsQycI6UY8dF4MG2UryTPOjH9Wc79NP1yzXVjeKMcZ2PgFj7rwz1yVpuOzcmbwXZ1jcx++WLW3v0WRccIENY+zaFe0YXjEWiTes4gpKJuPeych0KCYdvv9921ooE1k5vXzvezXX/le/inffyYReQzcNBDdk8/nnuS1HQ2bqVDjxRFi9un77mTEDjjsObr/dDpTxxhv+623YADNn2vzpzZqF3787FN0nn9h5Y+Cqq2wOdb+RizZt8t/P/v3+yz/9NLc506dMseEbL7GHKiJyyimwcycsWJDZ42zfDoceaqe3bMnssbyo0DcQXKHfti235WjI/POfNp76n/+kv4/Vq20sd8wYmDwZOne2sWVj6q771FM2Fn3ZZcH78xtE2m8out27gwU9iKIi/+Vdu2YpLhzA+PHwyCN14/e5Gk8VYNgw+x41Th+Vqipo1w5atVKhV3xQRx8OP+EEK7hvvWWn33kn/f3/4Q9W1C+4wAqjO1D1//1f7fWMgUcftU8QCxf6l8nr3I2pGVHJdfJh6dAhWkXplClWVP0qS7MltulUZGaSzp3hqKOCn87iYvt2K/Lt2tVUxmaFoJhOrl4ao/ena1cb1zvrrFyXJLtEqaRK1rZ5zhw736iRMaedln55hg2zXfZddu82pnt3W5nnzdD45pv2eFdcEb1CNCi23qZN8L6efLImdYHb4zLq9TvYmTDBdmqLc0CVRIYNM+bLX7YJ5kaNinffaGVsw6a6uiZJ1Je+lP3j791rk2F9/HF2jxu1U0qySr7/9//s9Le+ZStR00k1sGqV3ccFF9QWT7dt+B/+ULPuhAm2w1OXLsFlSpZm168VTbI0vo8+ateZOTP6eSkW9xp+8EHmjlFWZszIkcaceqp9xYkKfQNn48aaP3ufPtk/vttZ68EHs3vcqK0zkrUkGTHCmL59a0b4effd6OV54AG7bWKyrubNbdqCPn3sDWTr1prOQcnKlOz8EgX9uOOMOeYY/3Lt2mVvKEOGZNaNFjoffGCv/6OPZu4YPXsaM368dfP9+sW772RCrzH6BoAbn2/VKjcx+s2b7XtWY4rY1iFRlge1GOnSBWbPttt9+9t22dSp0cszYwY0aQK7dtVevnOn7dj0/vs27v7739vK1MsvT966JVmFaGIM++qr4YMP7CuR3/4WVq2y24lEPy/F0rs3dOxov+fEyvC48MbotTJWqYUr9EcfXbfVTVDlY5y4rT2y+cOE6E0Ag4Rz8GArztu31yx/4olo12rVKvj3v+v26HTZuNFe/8sug0mT7A1h6dLUYh62QnTkSPv+5z/XXv7FF3Zfp58OZ5wR/nyUuojA9dfbivXjjoNXX029zaefwt/+Fv4YVVXQunX2hT7noZrEl4Zu6vLkk/aR8sIL7bsbX44rvWkqfvc7u+/LLot3v6lINz1tYgy7bdtoISA/3CyL7ohJia8OHTKba9wYYwYPNmbo0NrL3AGy58xJb59KXV5/3Zjeve11vfhiGzr1Ul1tzGuvGTN6tK3ch9oZOYPYu9eue+edNfmP4uyghcboGzZ3322/Kbd37JYtdnm2ehjed5/d7ze/Ge9+wxBP1/DgV1i+9CWbyjadIefi4mc/s/t0c8lv2WJvYl//enzHUCw7d9pMoo0b25Y4zz5rzPbtxvzmN7a+BGxu/a99zU7/5z+p97l1q133F7+wvWIh+qhayUgm9KFCNyIyQkSWisgyEbnZ5/OuIlIuIgtE5F0ROcdZ3l1EdorIQuf1m3ifRw4O1q61cb3DD7fzbpw+agw7XTIdukkWfqpve+v9+4Pj1m4PxVThr08+sZ2sxowJDre49RiJxPldnHuufX/pJft+33223uSnP43vGIqluNhe1/nz4cgj7ffeoYOtK2nc2Caqq6yEW26x64fpyOgmNHNj9JDF8E3QHcB9AUXYsWJ7UjM4eN+EdaYBk5zpvsBKZ7o78N9Ux/C+1NHXZcwYOzLRjBmmVouRbDl6t/lg1MEZwpBu+Cms06+osPt0m6d6X2PHhju++0ST7PE8G99FdbUxRx1lzFe/avPYt2xpm4sqmWXfPmN+/WvbJ+KNN2q3bHrvPfs9h0la9/77dt3nnjPmr38N/yQQFurp6IcAy4wxK4wxe4DpwKjE+wXQxpkuAdake+NR6rJ2re3OPnmynT/zTOs6s9WNPZOtbvy6+ydLWQvBPUr9Kldff92+/+IXtV14p062YjXZ8V2nf8MN0LRp8tQJ2fguRGD0aHjtNbj5ZlvBfNdd8e1f8aeoCL77XfvkdvLJtZ8QS0rsexRH71bGQn45+vOBRz3z3wZ+nbDOYcB7QCWwBRhkahz9F8AC4HXglFTHU0dfl0MPrdtbMu6KvmScfro9Ztu28e87nSyKUdzzyJHWBScybpwxpaXROi2lUxEcN2+9VVOeiRPj378SjW3b7Hdx772p133tNbtueXlN35Tf/z6+spCFdvTjgCeMMaXAOcDTItIIWAt0NcYMAK4HnhORNokbi8iVIlIhIhUbNmyIqUiFw2ef1c1E6LrObOQMcR39tm32OHGSThbFsHUT+/fDv/4Fw4fXXXfIEBtjdes9Eikqiv6kkY3vYuhQW7fQtKnNnqnkllatbN1OVEfftq2dzpajDyP0q4EunvlSZ5mXy4AZAMaYfwPFQEdjzG5jzCZn+TxsrL934gGMMdOMMYONMYMPOeSQ6GdRwFRVWf/mR9yVrkG4lbHGxJ89M52QR9ibw3vv2XDTaafVXXfoUPvuJidLPH6yFL+5pKjIVsI+9JANQSm5pVEjaNMm3P/C7ceRi8rYMEI/F+glIj1EpCkwFngpYZ1PgTMARKQPVug3iMghIlLkLO8J9AJWxFX4g4E1SWo7spE7HKzQd+xop+OO06eTRTHszcGNz/sJ/YABtvVEcbH/8YNENFvXPBkXXZQ89bGSXUpKojv64mL7yhuhN8bsAyYDrwDvAzOMMYtF5C4Rcfrr8QPgChFZBPwemODEjE4F3hWRhcCLwNXGmICGaIofbq/YxIEr0q3oi9qTdudO+zrySDufiR9m1JBH2JvD7NnQs6dNgZBIcTGUldmUxX7HnzKlbj73XA+OoeQnYYXe6+ghy71jg4L3uXppZWxtnnvOVtrcc09NJWTr1ulV9KXTlLGysnbFZKdODSPV7f79tkPLpZcGr/Od79hr6ZfJculSW6napo2m+FWSc8opxgwfnnq9O+6w/yH399a3b7ydENGkZg0X19FfcYV1m1272iZ26VT0pdOU8amnatYDWzHsNmWM+nSQjbw8LosX20pkv7CNy9Ch9nHaL1HYvffap6gPP8yfwTGU/KSkJFxIc/t2+1ToPim2bZtHoRslNZkUsLVrreC4tfQlJelnsEzWWiXoHPyyPO7YYccvDWrL7revKG3f42D2bPueTOiHDLHviSNOrV4NTz4JEyfW9J5VlCCixOhbt66Zz2bopnF2DlO4uALmOl5XwCAeB7h2LRx2WE0njbA1/H507eo/TF379sHnsH69/778xi91bwA7d9bdV/PmwU8TmXDKr79uY/fduwev07u3/ZO+/TZcemnN8gcesC7+hhviL5dSeESJ0bvxebBCv3hx5srlRR19PUknHBIFV+hd6uPog1qrQPA5tG8f7RibNvnvK2hg60w0VzTGtp9P5ubBPnEMGWKF3mXzZpvffexY6NEj/rIphUfbtlbog5pBu+TS0avQ15N0wiFRSBT6+jj6dBJyfeUrdZe3aGETPMVBJporvv8+bNjg31EqkSFDbHt79+b00EPWed10U/zlUgqTkhLb7yLVYCV+jn7btuA+G3GiQp9AVHEOEio3HBI2hh1EnI4e/JsSJuuA1LWrHUTDbVfeooW9OUyd6v90EHQD6NAhO3l5IFx83mXoUPtHmz/f/lGnToWvfQ369Yu/XEphEjbfjZ+jh+yMGqdC7yGdCsOo4ZBklZiJ7Nxpa/MTHX3cP4xkHZA2bbIJwFauhBNOgFNOsTeHoKeDoBvA1KnRO0aly+uvQ2lpuNCLWyH79ts29ezGjTZhmKKEJazQJzr6rKZBCGp3matXLtvRp5tq1i+ZVbJkWWGPsWKF/eyxx2qWuYNP7N4dvUzprD9qlDHHH2+nzzqr7ghHcRw7TqqrbVv/b387/DbdutnRgrp2NebkkzNWNKVAmTXL/idTjfJ1xBG1E9HNnGm3q6iIpxwkaUevrW48pDuQh+twvdx6q38LlyjHdtvQJzp6sK7eTUuQSDotgfzOAayjdytk27Wzzj4VQfvKBkuW2Lb+p58efpuhQ+GFF+wt96GHMlc2pTBJ19FnM9+Nhm48pJNJMYigcEhQDNvvGH5CH+ZHFWdLoE2basqczQ4e6VJebt+jCr0xdkDoc87JTLmUwiXMf9KY4Bi9Cn2WSZUsK0olatQYtl+lZCpHH0ScQwxu3lwj9O3a2TqDVM3Ickl5uf1ukrWfT+TUU+37rbcGDzuoKEGEEfqdO20DCD9Hn4kBfRLR0I0HN9xw/fX28b+0FO6+2y6PMxwCVlQ+/dQ6+SlT/NdzR5byZm4O86MK6hgV9cnEmLqhm7177TVo2TLavrJBdbVtcTMqcfyzFAweDMuX2wRoihIVt1I12X/STWjmdfTZrIxVR5/A+PFw1VV2ety4GgGOMxwSlK0x8YnhzTehc2c77xLG0cc1rN327bBvX+3QDeRv+Oa99+wTSJSwjYuKvJIuLVtaQ5ZM6L0Dg3u3a9xYhT5nuINcTZ1aU/kYZzjED7+mnW++aUcS8hLG0aeT490PtzerN3QD2XnUTId04vOKUl9EUndk9HP0ItnrHatC78PGjTaZVVFRjWOPs6LWD78nhupqWLeu9rIwjh7iGdbOFXpv6Aby19G/9hocdZQNuSlKNkmV78Y76IgXFfoMk6xidcMGm/Dq+uvhueegoiK+cEgQQU8GO3fWno8y6nx9cVMjJDr6fBR6d3xYdfNKLkiVqjhx0BEXt4FDpjkohT5VD9iNG20b9RtvtBWhN9wAF16Y2Z6dQU8GrrC7NGtmwznZ6DadGLpxY/T5GLpZsMDe/FTolVygjj4PSVWxumGDFfg2beDOO22X+r/8JZ5wSBB+TwwA551Xd1nYtKj1pSGFbtz4fJhEZooSN6n+k0GOPlt9U0IJvYiMEJGlIrJMROpkAhGRriJSLiILRORdETnH89ktznZLReSrcRY+XZJVrFZX1x4M+4or4OijrbvfuzdzZUqsQO3c2S4/99y662Yi340fbujGFXr36SJfhf7oo2v3OVCUbOGmKg4i7x29iBQBDwJnA32BcSLSN2G127CDhg8AxgIPOdv2deaPBUYADzn7yynJKla3brXxXrftepMmcM89sHQpPPpo9GNdcgn8+Mfh1vU+Mfz2t3aZn3Bl09G3aWOvAdjK6TZt8k/o9+6FN97QsI2SO9J19NnqhBjG0Q8BlhljVhhj9gDTgcQuKQZw2oNQAqxxpkcB040xu40xHwPLnP3llGQVq27TSm8npZEjbe/JO++M7qTfesu+ouLXK9YlW47e21nKJVuVR1GYN8/+kVTolVzhpg8PEuyqKmuYmjWrvbxdO2ssXcefKcII/RHAKs98pbPMy53ARSJSCcwCvhdhW0TkShGpEJGKDa7SZpBk7cw3brTreBOGicB999neshl2CewAACAASURBVP/zP9GOVVUVPLBHMtautcf1G7M0W47em/7AJZuj4oRF4/NKrnEHH/niC//PExOauWSrb0pclbHjgCeMMaXAOcDTIhJ638aYacaYwcaYwYd4rXQGCapY9XP0YHOxjx0L999f47bD8PnnwcPoJWPtWnuzccMmXnLp6PMxsVl5ORx7rM2bryi5wK2/ChLsxIRmLtnqbR5GjFcDXTzzpc4yL5cBMwCMMf8GioGOIbfNK/wcvct3v2vbtS9YEG5fe/bArl3pO/qgisVsxuj9HH0+hW727LGhMQ3bKLkkVf+WVI4+H4R+LtBLRHqISFNs5epLCet8CpwBICJ9sEK/wVlvrIg0E5EeQC/gnbgKnwlcR+8n9K7ohXXTbtxtxw4r+FFIJvSuo890BU5DCN288469vir0Si5JJfRBjj5vhN4Ysw+YDLwCvI9tXbNYRO4SkZHOaj8ArhCRRcDvgQnOoCeLsU5/CfAy8F1jTBaGwk2fjRttxaxfm/aw6QdcvOtFdfWpHH2YwYjrw/799sfnVxmbT0JfXm7rMsKMD6somSLfHX2oNMXGmFnYSlbvsts900uAYQHbTgEyMAR0ZnA7S/lRH6HftAkOPzzcdtXVsH59ckfv7j9T6YLdJl+Jjr5tW3uD2bOnbsK1XFBeDscfHzygi6Jkg1Spiquq/OuQGlplbN4SZbAQSC70rVpZ9xg2Pu5tMhXF0W/caNMDJ3P0kNk4fWKeG5d8ymC5axfMmaNhGyX3pOvoW7e22pTz0E1DJlVOGz/cPDd+uOlI03X0YUnWhh6iP1mkQ2L6A5d8SoPwn//A7t0q9EruSTdG36iR3VaFvh6kM1hIMkcP6Qt9FEfvCn1QqCeXjj6fBh8pL7d/FHcoQEXJFS1aJB98JMjRQ3bqvQpa6NMZLCSZo4eDz9Hnc+hm9mwYMKDm5qMouUIkOFXxvn02zOjn6EGFvt5EHSxk507bsy2Zo4/Shr2+jj6XMfqGELr5+GM47rhcl0JRLEHa4DeMoJds9E0paKGPOlhIss5SLlEcvfsFd+4c3dG3bQvFxcFlgMw6+s2bbVgk0S3nU+jm88/r5utXlFwRJPR+wwh6UUdfT9ycNkVOvsxUg4UEpT/wEjV007q13V9UR58s3a4r9Jl29O3a1R6YHPIndGOMvb7utVCUXJOuo89GWpGCFnqwol5cDAMHph4sJG5H7wpR+/bRHX0yoS8qsu3nMx2jTwzbgM2+17x5Zn6YQQmhgtY1JtglKUq2CcpJH9bRZ7Kne8ELfXW1FYVVq1KvG8bRu+lIw+AKfYcO8Tp6txyZbnUT1AkpE4+ac+fac/roo3Dru9+BOnolX0jl6JMJ/Z49dceHjpOCF3rXJW7YkDrfTNjQzRdf2Jr0VKTj6I2BNWtSC32mM1j6JTRzads2/tDN66/btAsffxxufffPo0Kv5AupYvTJKmMhs+Gbghd6b+/UNWuC1wMbuikqSt5czxWWMAMFuDF619GHeTTbutV2Asq1ow8K3UBmHP2iRfY9aosmFXolX3D/k9XVtZeHcfSQ2Xqvg0roU4VvNmywopxYAeklSouXqqoaR797d7gkZKmaVnrLka6j37cv9bbZDt0sXGjfo/ZRUKFX8oWSEmvmXAfvoo4+C3gvemVl8nVTdZaCmuZ8YQTJG6OHcHH6sEJfH0f/859Dnz51nYfLnj32JpWt0M3u3fDBB3ZahV5pqAT1b0nl6LPRZLnghd7r6FMJfar0BxCtaaM3Rg/h4vTZcPSvv27DWMuW+X/u3pCyFbpZsqSmziNq6EZb3Sj5QpDQu2bTL/U5qKOPhShCH8bRhw3deNt5R3H069bZ90w5emNqRsiaP99/naA8Ny7t2vnHItPFjc+DOnql4ZLM0bdqFRwSVqGPAVfomzULF6MP6+hTCZLbzjsdR9+iRWqn2qaNdQr7Iw7j8umnNT+oIKEPynPj0ratPbe4KoMXLbJt8zt3jp4CWoVeyReCctInS2jm3U4rY+uB+9h09NHJHf3+/dbJxuXovXG5qI6+c2ebJCkZrnsI0/rHi+vmW7RILfTJQjcQ3w9z0SLo18/uN4qjb9rU3sAVJR9I5uiTGbeiIqsrOXf0IjJCRJaKyDIRudnn8wdEZKHz+lBEtno+2+/5LHGs2YzjCuExxyQX+i1bbCgilaMPm1DMG1qI6uhThW3c/XqPE5YFC+wj5De/aYXer8lnmNANxPPDNMYKfVlZep3RFCVfSBajT+boIfNpEFIKvYgUAQ8CZwN9gXEi0te7jjHmOmNMf2NMf+B/gT96Pt7pfmaMGUmWcYW+Tx87PN/u3f7rheksBTb1gEhqQfIKfbNmdrsojj4V6WawXLDAPt2cfLL9Ya1cWXedVKGbOIW+stJel/797bWKUhmrFbFKPuH+JxOfdFM5esh8YrMwjn4IsMwYs8IYsweYDoxKsv447ADhecH27TZM0a2bnQ/qNBUmzw2EH2UqsbIwbO/YTDv6+fNtDveBA2vmE9m8GZo0CR6PNs6YolsRW1aWXh4hRckXmjeHxo3Tc/T5IPRHAN5qzEpnWR1EpBvQA3jNs7hYRCpE5D8icm7aJU0T925aWmrng8I3YR09pCf0YfLd7NxpxTNTjn7DBli92gr9ccfZH6Wf0LvpD4LqCeJ09K7QH398tJZEbmc0RckX3MFHosboIfM56RvHvL+xwIvGGG9bkG7GmNUi0hN4TUTeM8Ys924kIlcCVwJ0DRoVJE3cpk2u0Ae1vAnr6CGcIKXj6Nevt++ZcvRuRezAgTaj57HHJhf6IOIW+p497R8hqqMPc50UJZv4aUNDcfSrgS6e+VJnmR9jSQjbGGNWO+8rgNnAgMSNjDHTjDGDjTGDDwljqSMQ1dGHEfowgpTYGy6Mow/bWQqi9dB1cYW+f3/7PnAgzJtXt0J28+bgFjdgQzpFRfGFbsrK7HRJSfgmoxq6UfKR+jj6XAv9XKCXiPQQkaZYMa/TekZEjgHaAf/2LGsnIs2c6Y7AMGBJHAUPy/bt9iK3bm2/hCCh37jR3nWDRnXykqkYvdtZKkzoJp3BRxYssHUVrogPHGhvcIn1FqkcvUg8P8wvvrBpiV2hj5owToVeyTcSc9K7uW/CtLrZscOmH8kEKYXeGLMPmAy8ArwPzDDGLBaRu0TE24pmLDDdmFr+sA9QISKLgHLgbmNMVoXeDd2AdfXJHH3Yh4mwQu9t5x0mg2UUR9+ypW0mGdXRD/A8TwVVyKYSeohH6N97z14P9wkjSjhKW90o+Uiio9+xI9wAOZnuHRsqRm+MmQXMSlh2e8L8nT7bzQH61aN89aaqCo480k6XliaP0YcJ20C49t6JjrN9e5vPJVkl4rp1VrzD3HDc1j9hHf327dY9e0fYKiuzx5s3D77xjZrlqUI3EE+7X2+LGwhfwbx3rx1bQB29km+UlNQOaaYaRtDFK/SHHhp/uQq+Z6w3PtalS3yOPkxlrFeIXIecLHyzdi106lQzxm0qonQwWrTIOguvo2/Z0nYk8zr6HTusiIZx9PWN0S9aZM/BbfoatdexCr2SbyQ6+lTDCLpkOid9wQu9G6MH6+jXr/ePg0UV+h07ko8ylRhacB1ysgrZsJ2lvOUI6+jditgBCVXhAwfWFvpUnaVc4gjdLFpkm1W6zTjDVjBrQjMlXykpsUbETfiXjqPPBAUt9IkVIaWlNUP1JRIldBOm0jAxRBPW0UdpMhjF0S9YYM/viIQeEAMH2rb1btPOVCmKXeor9NXV8O67NWEbCF/BrEKv5Cvu4COuNoR19JnOSV/QQu9mkPSGbqBu+OaLL2xnpbCOPozz9IvRQ24d/YABdTtBuRWyruMP6+jdwUfSHbn+44/tn8BP6NXRKw2VxHqmVIOOuKijrweJd9OgtvRROktBOOcZNUZfXW1ddSYc/Z498N//1oi6F7fFixu+iRK62bs33PCIfrhDB7rHh+gJ47TVjZJvJP6GUw0j6KJCXw8S76ZBQh8l/QGEc56JQu9+kUGOftMmG/PPhKNfssSKcmJ8HuwP86ijaoQ+SugG0v9hLlpkW/wce2zNsrBNRrUyVslXEnPSh3X0TZvanFxaGZsGiRUhbdrYV2ITy3QdfRShb9LEzgc5+iht6F3COvqgilgXt4cspM5F71LfxGaLFtksms2b1yxLN2GcouQL6Tp6yGzv2INC6L13U79OU3E7eredd+JdvH37YEfvCn1UR79rV+redPPn2x/aUUf5fz5woE1XvHmzFfoWLVL3EI7D0Xvj8y5hm6666ypKPpGYqjhsqxtQoU8bvxpvP6GP6uhTxZKDQgsdOgQ7+rBjxXoJW3m5YEFN5yg/Bg2qWW/z5tTxeaif0G/dCp98Eiz0YR19mD+PomQTP0fftKl9pSKTg48UtNAHOfrE0M2GDTZlrxuOSEUqgQ1ynHE7+jCVl9XV1j0HhW2g5rP588OlP4D6Cf2779p3P6EPmxk02WDLipIr/FrdhG00UFYGMSfvPUDcaYrzCr/Hpi5drHveu9fGzcEKfceOqcdpdUk1ylSQ0Hfo4D+iE9gytW4dPNiHH2Ec/bJl1lUkE/oOHWzv1Pnzw6U/gPrF6P1a3Li0aVMTSgtCE5op+UpxsdUVr6MP++T5619nrlwF7YmCQjfG1DhoiNZZClJXGqbr6KPmVw/j6FNVxLq4PWTDOnr32Ok4+kWLbH2I39NLGEevg44o+Uri4CNRHH0mKWih93P0fgOQREl/4JJMkJI5encQ8kSidpby7j+Zo1+wwDoMbzNGPwYOhA8/tPUXYYS+qMheg3SFvqzM/wkqbIxehV7JV7zaEMXRZ5KCF/riYht/d/HrHRvV0UNyQQpqO9u+vRV5vxtEJh39scemrgxyO1Nt3x4udAM1vWOjsG+f7bzlF58HFXql4ePNSa+OPgv4XWS/TlPpOPp0QjfJesdmwtEbY4Xer0dsIt51wjh6SK852Icfwu7dwUJfUmLTUezdG7wPFXoln/GmKlZHnwW8mStd2rSxF94V+n37rFjF6eiTxeihbpz+iy/sTSluR79mjb2JpYrPg73JuMfPpNAn5qBPJGxntHxwSYrih8bos4zfRRax4Rs3Ru+O+pROjD6V0CfeyYMcfZQhBL00a2ZDMkHlCFsR6+K2p89k6Oadd2w47Zhj/D8PE47Sylgln9EYfZbxDiPoxdtpKmpnKZdkPThdx5nYzjvI0aeT/sAlWaXwggX2xhbknhNxwzeZdPTl5XDSScF1BmHCURq6UfKZBuvoRWSEiCwVkWUicrPP5w+IyELn9aGIbPV8domIfOS8Lomz8KkIusheoY+a/sAlVWWsnxDF7ehTlWPePOjVK7yjOOss69KDUiUkElXoN22yoZvTTw9eJ1UK6B07bIW2Cr2Sr7iDj7jpSfLB0afsMCUiRcCDwJlAJTBXRF7yDvJtjLnOs/73gAHOdHvgDmAwYIB5zrYZ6uhbm+3boUePustLS62L3revfkLvjjLVOOEqBsWQ27a1Djsbjn7zZnjlFZg4Mfy+hg2LJtzt2tWMXB+mi/frr9v3ZEKfKgW05rlR8h3XrLgDHDUURz8EWGaMWWGM2QNMB0YlWX8c8Htn+qvAq8aYzY64vwqMqE+BoxDk6Lt0sa5w7dr0Qzful+k3ylRQaKGoyIp9oqNfu9beLMKGTLwEOfonn7SO4qqrou8zLFF7x5aX24RpJ5wQvE7Y9BL58OdRFD/c/8Xq1fY9Hxx9GKE/AvBmh6l0ltVBRLoBPYDXomwrIleKSIWIVGxI1f89Asli9GDDN+7h0onRg7/zTBZD9usdu26dHfk9ndwtfo7eGPjNb2ws/Pjjo+8zLFHz3ZSXw8knJ3f/qSpj1dEr+Y77G3bDw/lgSuKujB0LvGiM2R9lI2PMNGPMYGPM4EOixlAC9+nfvBJq947duNGKRpjQg5dkzjOZ0PtlsEyns5S3HIllKC+37dUnTUpvn2GJIvSffQaLFycP20BqR6+Djij5TqLQNxRHvxro4pkvdZb5MZaasE3UbWNl504bngkK3UCNo0/n3pKu0Ac5+nQqYsHf0T/8sL2hnH9+evsMS5TQzezZ9j2V0LtJoaL2UVCUfKGhOvq5QC8R6SEiTbFi/lLiSiJyDNAO+Ldn8SvAWSLSTkTaAWc5yzJOsoT/JSU2S2RlZXrpDyC50Cdr550pR+8O0r12LcycCZdemnrwkPoSxdGXl9sfvNtWPwg3YZyGbpSGiiv0boy+QQi9MWYfMBkr0O8DM4wxi0XkLhEZ6Vl1LDDdGFdywBizGfgp9mYxF7jLWZZxko3VKFLTxDJdRx8US3bbeQd9uYmOfv9+W4b6OPr9+2sG6X7sMdsS6Mor09tfFKIK/Smn1G2h5Ec6vY4VJV/Ix9BNqHz0xphZwKyEZbcnzN8ZsO3vgN+lWb608UtR7MXtHbtxo39e9FQEOfpU7bw7dLChDrdZ5mef2fXr4+jdchQXw7RpcOaZtv18pgkbulmzBpYuhcsvD7ffMJlB88ElKYofDdLRN1RSjb7ujjQVd4w+leN0e8e64lifzlJQ+8li1ix7Tldfnd6+otKsmR3cO5WjDxufd0nVGa1JE3tsRclHiott4w63f0w+OPqCF/qgi1xaau+4u3enJ/QtW9rmkFGFPrF3bH06S3mP8/nnthL28MNh5Mjk28TJUUfBq6/W1BH4UV5u3X/YJ6dUeYTatAk/Gpii5IK2bW1IVcT2Hck1BSv0YUI3LulUxgZVGoZ19G6cPi5Hv3AhvPwyXHFFuDh4XPzgBzatwV/+ErxOeTmceqrtMBaGVJWxGp9X8h33f9mqVX6YkoIV+jChG5d0m+77hRhStfMOcvTpCr17nF/8wj5hhI2Dx8X48XDkkfCTn/i7+lWrYPny8GEbSF0Zq0Kv5Duu0OdDfB5U6IH0HD34C1KqysJER792rX3MS7cppPuD+vBD+MY3ap9XNmjcGG691Y43O2tW3c/Ly+17FKF3K2P9bhwq9EpDwOvo84GCEfpnn4Xu3a2r7d4d3nzTLk8Wo3eJ09FHjdGvW5d+fD7xONmqhE3koots8jg/V19ebs+5X7/w+2vTxo4wtXt33c900BGlIaCOPgM8+6xtN/7JJ1ZoPvkE/vxn2zqjSRP/bdq1q6kkSdfR+1UaphL6Nm3szcjr6OMQ+p49bbPKXNCkCfzoRzB3rq0n8FJeDqedFi2PT7J8NzroiNIQUEefAW69tabDkMu+fbbWOwi301STJukLRzqVsY0a2fCN19GnG58HW8F59tlwxx3pJUWLi4svhq5da7v6jz+2N90oYRtIP72EouQL6ugzwKef+i+vrk6+XWmpdfPp1ooHVcY2bZq8nbfbO9aY+jt6sLHxiy+u3z7qS9Om1tW//bZtbgnpxedBhV5p+KijzwBdu/ovDwrbuIwaBd/8ZvrHDYrRpxIiN99NVZVNvlYfR59PTJhgb56uqy8vh06doG/faPsJCt3s3Wuvlwq9ku+4vcbV0cfIlCl1OyW4lbLJuOYa+N//Tf+43lGmXMJUFrqOvr6dpfKNZs3glltgzhx47TUr9MOHR39iCnL0qVpSKUq+oI4+A4wfb3O8dOtmRaVbN9sKpGfPzB7Xb3zTKI6+vp2l8pGJE23v3EmTbM/jqGEbCHb0moteaShojD5DjB8PK1fauPzKlTZmnOm7qZ/zDCP0herowfYHuPlm+OgjO5+O0KebR0hR8gV19FkiaHSpOElX6Dt0sO7UrUQuJEcPNg3DYYfZV+/e0bdXoVcaOvnm6LOYFSW7BA0MHid+glRVBUcfnXw7t3fskiX2ycPN614oFBfDCy/Y+ot0WjQ1bWr3EbXpqqLkC27T7W7dcl0SS0EKvTHZEXq/WHJYRw92DNXOnfMj6VHcDBtWv+3T6XWsKPlC58524JGYhsCuNwUZutm1y3aWylWMPkyrG7COvpDi83HiN/iIDjqiNCQ6dcofExdK6EVkhIgsFZFlInJzwDpjRGSJiCwWkec8y/eLyELnVWes2UyQKkVxXCQKfdh23q6j37Gj8OLzcZFOZlBFUfxJGboRkSLgQeBMoBKYKyIvGWOWeNbpBdwCDDPGbBGRTp5d7DTGpDFYX/pkq711otCHFSLX0YM6+iCShW7ypSWDojQUwjj6IcAyY8wKY8weYDowKmGdK4AHjTFbAIwxn8VbzGhkS+jdUabcEENYoXcdPajQBxEUumnVKvwAJoqiWMII/RHAKs98pbPMS2+gt4i8JSL/EZERns+KRaTCWX6u3wFE5EpnnYoNGzZEOgE/3NBNpp2fO8qU6zTDVha2alUzCpSGbvxJN72Eoih1iasytjHQCxgOjAMeEREn2wPdjDGDgQuBX4rIkYkbG2OmGWMGG2MGHxJDNXU2u8qnI/QiNa5eHb0/QY5ehV5RohNG6FcDnhFWKXWWeakEXjLG7DXGfAx8iBV+jDGrnfcVwGxgQD3LnJJcC32Y47pxenX0/rjX1TuQiQ46oijpEUbo5wK9RKSHiDQFxgKJrWdmYt08ItIRG8pZISLtRKSZZ/kwYAkZxhX6bFTaeQcfidLOWx19ctq0seksvOMM6KAjipIeKYXeGLMPmAy8ArwPzDDGLBaRu0RkpLPaK8AmEVkClAM/NMZsAvoAFSKyyFl+t7e1TqbIVvNKqD34SBShdx19p07J1ztYSbczmqIodQnVM9YYMwuYlbDsds+0Aa53Xt515gARRguNh2yHbpYvr33cMGLUubN9NW2aubI1ZLxNVw8/vGZahV5RolOQPWPdUZ6yIaJ+MfowIaPbboOZMzNXroaOOnpFiY+CzHWzfXv2OtUkCn3r1uHGbu3Sxb4UfxI7oxmjlbGKki4F6+izJQglJbbCcO9eFaI4SRT6nTtt5aw6ekWJjgp9PXGFp6pKQwtxkhi60cyVipI+KvT1xOs8tflffCQ6ehV6RUmfghT6bMfowQqROvr4cK+jOnpFqT8FKfTZjtGDFSQV+vgoKrJJ49TRK0r9UaGvJ+roM4dfZzSt7FaU6BSs0OcqdKNCFB/e9BI66IiipE9BCv327dl39Bq6iZ90MoMqilKXghP63bttm/Zsx+jXrdN23nHjTVWsQq8o6VNwQp/NPDcALVrYnrCVlXZehSg+Eh19kybQrFluy6QoDZGCE/psjS7l4o4ypUIfP4mVsa1b2+utKEo0Ck7os+3oQYU+UyRWxuq1VZT0UKGPgZKSGqHXVjfx0aaN/T6rq7WiW1Hqgwp9DHhDDCpG8eFWdGseIUWpHwUn9NmO0UNtAVIxig/tjKYo8VBwQp8rR+83rdQP7aOgKPEQSuhFZISILBWRZSJyc8A6Y0RkiYgsFpHnPMsvEZGPnNclcRU8CBX6wsEN3WivY0WpHylHmBKRIuBB4EygEpgrIi95B/kWkV7ALcAwY8wWEenkLG8P3AEMBgwwz9l2S/ynYslF6MYVpKZNtZ13nGgKaEWJhzCOfgiwzBizwhizB5gOjEpY5wrgQVfAjTGfOcu/CrxqjNnsfPYqMCKeovtTVQWNG2dXcF0BUscZL+4NdNMmO4qXCr2ipEcYoT8CWOWZr3SWeekN9BaRt0TkPyIyIsK2iMiVIlIhIhUbNmwIX3of3MyV2exY4wqQClG8uNdz9era84qiRCOuytjGQC9gODAOeERE2obd2BgzzRgz2Bgz+JBDDqlXQbKZothFhT4zuNdz1ara84qiRCOM0K8GunjmS51lXiqBl4wxe40xHwMfYoU/zLaxks3RpVzcEIMKUby0amWfzLTXsaLUj5SVscBcoJeI9MCK9FjgwoR1ZmKd/OMi0hEbylkBLAd+LiLtnPXOwlbaZgx19IVDo0b2u3RDNwdjHcjevXuprKxk165duS6KkicUFxdTWlpKkyZNQm+TUuiNMftEZDLwClAE/M4Ys1hE7gIqjDEvOZ+dJSJLgP3AD40xmwBE5KfYmwXAXcaYzZHOKiIq9IVFScnBHbqprKykdevWdO/eHdGMbgc9xhg2bdpEZWUlPXr0CL1dGEePMWYWMCth2e2eaQNc77wSt/0d8LvQJaon27dD587ZOppFW91kjjZtYMmSmumDjV27dqnIKwcQETp06EDURisF2TNWY/SFQ5s2YEzN9MGIirziJZ3fQ0EKfbadtSv0bUO3M1LC4l5bOHiFXlHqiwp9DLRoAc8/DxMnZve4BwNecc/2k1pD5NlnoXt3W5Hdvbudrw+bNm2if//+9O/fn86dO3PEEUccmN+zZ0/SbSsqKrjmmmtSHuOkk06qXyGVlISK0TcU9uyxr1zEyseMyf4xDwZcR9+yJRQV5bYs+c6zz8KVV9pexACffGLnAcaPT2+fHTp0YOHChQDceeedtGrVihtuuOHA5/v27aNxY38ZGTx4MIMHD055jDlz5qRXuByyf/9+ihrQD7KgHH0u8twomUVbNIXn1ltrRN5lxw67PE4mTJjA1VdfzdChQ7nxxht55513OPHEExkwYAAnnXQSS5cuBWD27Nl8/etfB+xNYuLEiQwfPpyePXvyq1/96sD+Wjl/2NmzZzN8+HDOP/98jjnmGMaPH49xKmhmzZrFMcccw6BBg7jmmmsO7NfLypUrOeWUUxg4cCADBw6sdQO555576NevH2VlZdx8s83LuGzZMr7yla9QVlbGwIEDWb58ea0yA0yePJknnngCgO7du3PTTTcxcOBAXnjhBR555BFOOOEEysrK+OY3v8kO5+KvX7+e0aNHU1ZWRllZGXPmzOH222/nl7/85YH93nrrrUydOrXe30VYCsrR5yJzpZJZVOjD8+mn0ZbXh8rKSubMmUNRURGff/45b7zxBo0bN+Yf//gHP/rRj/jDH/5QZ5sPPviA8vJyqqqqOProo5k0aVKdtuALFixg8eLFHH744QwbNoy33nqLwYMHc9VVV/Gvf/2LHj16MG7cON8yderUiVdffZXi4mI++ugjxo0b1gqJbAAADVhJREFUR0VFBX//+9/585//zNtvv02LFi3YvNm28B4/fjw333wzo0ePZteuXVRXV7Nq1Srffbt06NCB+fPnAzasdcUVVwBw22238dhjj/G9732Pa665htNOO40//elP7N+/n+3bt3P44Ydz3nnnce2111JdXc306dN55513Il/3dFGhV/IabdEUnq5dbbjGb3ncXHDBBQdCF9u2beOSSy7ho48+QkTYu3ev7zZf+9rXaNasGc2aNaNTp06sX7+e0tLSWusMGTLkwLL+/fuzcuVKWrVqRc+ePQ+0Gx83bhzTpk2rs/+9e/cyefJkFi5cSFFRER9++CEA//jHP7j00ktp0aIFAO3bt6eqqorVq1czevRowHZCCsO3vvWtA9P//e9/ue2229i6dSvbt2/nq1/9KgCvvfYaTz31FABFRUWUlJRQUlJChw4dWLBgAevXr2fAgAF06NAh1DHjoKCEXkM3hYc6+vBMmVI7Rg+2ocCUKfEfq2XLlgemf/zjH3P66afzpz/9iZUrVzJ8+HDfbZp5UsoWFRWxb9++tNYJ4oEHHuDQQw9l0aJFVFdXhxZvL40bN6a6uvrAfGKPZO95T5gwgZkzZ1JWVsYTTzzB7Nmzk+778ssv54knnmDdunVMzHLLjYKK0aujLzxcR6/faWrGj4dp06BbN5sjqFs3O59uRWxYtm3bxhFH2KS0bjw7To4++mhWrFjBypUrAXj++ecDy3HYYYfRqFEjnn76afbv3w/AmWeeyeOPP34ghr5582Zat25NaWkpM2fOBGD37t3s2LGDbt26sWTJEnbv3s3WrVv55z//GViuqqoqDjvsMPbu3cuznuZNZ5xxBg8//DBgK223OQNKjx49mpdffpm5c+cecP/ZQoVeyWvU0Udj/HhYuRKqq+17pkUe4MYbb+SWW25hwIABkRx4WJo3b85DDz3EiBEjGDRoEK1bt6bE28HC4Tvf+Q5PPvkkZWVlfPDBBwfc94gRIxg5ciSDBw+mf//+3HfffQA8/fTT/OpXv+L444/npJNOYt26dXTp0oUxY8Zw3HHHMWbMGAYMGBBYrp/+9KcMHTqUYcOGccwxxxxYPnXqVMrLy+nXrx+DBg1iidO1u2nTppx++umMGTMm+y12jDF59Ro0aJBJlyefNAaMWb487V0oecbbb9vvdPLkXJckNyxZsiTXRcgLqqqqjDHGVFdXm0mTJpn7778/xyWKzv79+01ZWZn58MMP670vv98FNveYr64WpKPXGH3hoJWxCsAjjzxC//79OfbYY9m2bRtXXXVVrosUiSVLlnDUUUdxxhln0KtXr6wfv6AqYzV0U3ho6EYBuO6667juuutyXYy06du3LytWrMjZ8QvO0RcVQRqV7UqecuihcPXVcM45uS6JojRcCsrRb9+e/fFilczSqBE4DRgURUmTgnP0Gp9XFEWpTcEJvcbnFUVRahNK6EVkhIgsFZFlInKzz+cTRGSDiCx0Xpd7PtvvWf5SnIVPxA3dKIoSD6effjqvvPJKrWW//OUvmTRpUuA2w4cPp6KiAoBzzjmHrVu31lnnzjvvPNCePYiZM2ceaIMOcPvtt/OPf/wjSvEVh5RCLyJFwIPA2UBfYJyI9PVZ9XljTH/n9ahn+U7P8pHxFNsfDd0oSryMGzeO6dOn11o2ffr0wMRiicyaNYu2aY7Ikyj0d911F1/5ylfS2leucHvn5powjn4IsMwYs8IYsweYDozKbLHSQ0M3SiFz7bUwfHi8r2uvTX7M888/n7/97W8HBhlZuXIla9as4ZRTTmHSpEkMHjyYY489ljvuuMN3++7du7Nx40YApkyZQu/evTn55JMPpDIGfNP9zpkzh5deeokf/vCH9O/fn+XLlzNhwgRefPFFAP75z38yYMAA+vXrx8SJE9m9e/eB491xxx0MHDiQfv368cEHH9Qp08GYzjiM0B8BeHN3VjrLEvmmiLwrIi+KSBfP8mIRqRCR/4jIuX4HEJErnXUqog5660WFXlHipX379gwZMoS///3vgHXzY8aMQUSYMmUKFRUVvPvuu7z++uu8++67gfuZN28e06dPZ+HChcyaNYu5c+ce+Oy8885j7ty5LFq0iD59+vDYY49x0kknMXLkSO69914WLlzIkUceeWD9Xbt2MWHCBJ5//nnee+899u3bdyC3DEDHjh2ZP38+kyZN8g0PuemM58+fz/PPP39gFCxvOuNFixZx4403Ajad8Xe/+10WLVrEnDlzOOyww1JeNzed8dixY33PDziQznjRokXMnz+fY489lokTJx7IfOmmM77oootSHi8VcTWv/Avwe2PMbhG5CngS+LLzWTdjzGoR6Qm8JiLvGWOWezc2xkwDpgEMHjzYpFsIjdErhYzH6GUVN3wzatQopk+ffkCoZsyYwbRp09i3bx9r165lyZIlHH/88b77eOONNxg9evSBVMEjR9ZEcYPS/QaxdOlSevToQe/evQG45JJLePDBB7nWeTw577zzABg0aBB//OMf62x/MKYzDiP0qwGvQy91lh3AGLPJM/so8D+ez1Y77ytEZDYwAKgl9HGhMXpFiZ9Ro0Zx3XXXMX/+fHbs2MGgQYP4+OOPue+++5g7dy7t2rVjwoQJdVL6hiVqut9UuKmOg9IcH4zpjMOEbuYCvUSkh4g0BcYCtVrPiIj3WWYk8L6zvJ2INHOmOwLDgCVkgH37YNcudfSKEjetWrXi9NNPZ+LEiQcqYT///HNatmxJSUkJ69evPxDaCeLUU09l5syZ7Ny5k6qqKv7yl78c+Cwo3W/r1q2pcvOaeDj66KNZuXIly5YtA2wWytNOOy30+RyM6YxTCr0xZh8wGXgFK+AzjDGLReQuEXGfv64RkcUisgi4BpjgLO8DVDjLy4G7jTEZEXp30BEVekWJn3HjxrFo0aIDQl9WVsaAAQM45phjuPDCCxk2bFjS7QcOHMi3vvUtysrKOPvssznhhBMOfBaU7nfs2LHce++9DBgwgOXLa4IAxcXFPP7441xwwQX069ePRo0acfXVV4c+l4MxnbEYk3ZIPCMMHjzYuG1wo7Bli82JMnEiZDmnv6JkjPfff58+ffrkuhhKFqmurj7QYico06Xf70JE5hljBvutXzA9Y9u1g+efV5FXFKXhkql0xgWV1ExRFKUhk6l0xgXj6BWlUMm38KqSW9L5PajQK0oeU1xczKZNm1TsFcCK/KZNmyI3CdXQjaLkMaWlpVRWVlKfHuNKYVFcXExpaWmkbVToFSWPadKkCT169Mh1MZQGjoZuFEVRChwVekVRlAJHhV5RFKXAybuesSKyAfikHrvoCGyMqTgNCT3vgws974OLMOfdzRhziN8HeSf09UVEKoK6ARcyet4HF3reBxf1PW8N3SiKohQ4KvSKoigFTiEK/bRcFyBH6HkfXOh5H1zU67wLLkavKIqi1KYQHb2iKIriQYVeURSlwCkYoReRESKyVESWicjNuS5PJhGR34nIZyLyX8+y9iLyqoh85Ly3y2UZ40ZEuohIuYgscYat/L6zvNDPu1hE3hGRRc55/8RZ3kNE3nZ+78874zkXHCJSJCILROSvzvzBct4rReQ9EVkoIhXOsrR/6wUh9CJSBDwInA30BcaJSN/cliqjPAGMSFh2M/BPY0wv4J/OfCGxD/iBMaYv8CXgu853XOjnvRv4sjGmDOgPjBCRLwH3AA8YY44CtgCX5bCMmeT72LGqXQ6W8wY43RjT39N+Pu3fekEIPTAEWGaMWWGM2QNMB0bluEwZwxjzL2BzwuJRwJPO9JPAuVktVIYxxqw1xsx3pquwf/4jKPzzNsaY7c5sE+dlgC8DLzrLC+68AUSkFPga8KgzLxwE552EtH/rhSL0RwCrPPOVzrKDiUONMWud6XXAobksTCYRke7AAOBtDoLzdsIXC4HPgFeB5cBWY8w+Z5VC/b3/ErgRqHbmO3BwnDfYm/n/icg8EbnSWZb2b13z0RcgxhgjIgXZblZEWgF/AK41xnxuTZ6lUM/bGLMf6C8ibYE/AcfkuEgZR0S+DnxmjJknIsNzXZ4ccLIxZrWIdAJeFZEPvB9G/a0XiqNfDXTxzJc6yw4m1ovIYQDO+2c5Lk/siEgTrMg/a4z5o7O44M/bxRizFSgHTgTaiohr1Arx9z4MGCkiK7Gh2C8DUyn88wbAGLPaef8Me3MfQj1+64Ui9HOBXk6NfFNgLPBSjsuUbV4CLnGmLwH+nMOyxI4Tn30MeN8Yc7/no0I/70McJ4+INAfOxNZPlAPnO6sV3HkbY24xxpQaY7pj/8+vGWPGU+DnDSAiLUWktTsNnAX8l3r81gumZ6yInION6RUBvzPGTMlxkTKGiPweGI5NXboeuAOYCcwAumLTPI8xxiRW2DZYRORk4A3gPWpitj/CxukL+byPx1a8FWGN2QxjzF0i0hPrdNsDC4CLjDG7c1fSzOGEbm4wxnz9YDhv5xz/5Mw2Bp4zxkwRkQ6k+VsvGKFXFEVR/CmU0I2iKIoSgAq9oihKgaNCryiKUuCo0CuKohQ4KvSKoigFjgq9oihKgaNCryiKUuD8f8RgVsA8VuyKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "4-vhguAda77a",
        "outputId": "4a9b0aba-e298-4000-feba-13bde966ee72"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 35ms/step - loss: 0.2588 - acc: 0.8938\n",
            "\n",
            "---------------------------------\n",
            "Accuracy: 89.38 %\n",
            "---------------------------------\n",
            "\n",
            "Confusion Matrix\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.90      0.90       179\n",
            "         1.0       0.89      0.89      0.89       157\n",
            "\n",
            "    accuracy                           0.90       336\n",
            "   macro avg       0.90      0.90      0.90       336\n",
            "weighted avg       0.90      0.90      0.90       336\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "68sLpIuqbJPY",
        "outputId": "3bb4eb96-97ba-4974-ce36-75d975b319ab"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9M5ev-PyUmf"
      },
      "source": [
        "models.save_model(model, os.path.join(MODEL_PATH, 'ResNet_flatten_dense_256_all_trainable.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ps5j1n_8bJmw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "770dd968-36cf-42e1-ab4a-2687f17d9414"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint.h5'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-6f56e0441ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#free RAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mconv_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rm 'checkpoint.h5'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OagMj3EMVwQP"
      },
      "source": [
        "## GlobalAveragePooling, all Trainable\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-BkPgSQVznw"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdJbXkIFVznx",
        "outputId": "ed7cb67e-bcb5-416b-aa76-c7d9a03e3f58"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1873, 150, 150, 1)\n",
            "(803, 150, 150, 1)\n",
            "(1873,)\n",
            "(803,)\n",
            "Done\n",
            "\n",
            "(1873, 150, 150, 3)\n",
            "(336, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMBghhJCVznx",
        "outputId": "a78dcff5-0dbf-4c50-d07e-b6004347aec8"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.GlobalAveragePooling2D())\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "#conv_base.trainable = True\r\n",
        "\r\n",
        "for layer in model.layers:\r\n",
        "  layer.trainable = True\r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-3\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50v2 (Functional)      (None, 5, 5, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 24,089,601\n",
            "Trainable params: 524,801\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "93/93 [==============================] - 16s 132ms/step - loss: 0.6068 - acc: 0.7596 - val_loss: 0.4260 - val_acc: 0.8250\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.42597, saving model to checkpoint.h5\n",
            "Epoch 2/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.4806 - acc: 0.7812 - val_loss: 0.3544 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.42597 to 0.35439, saving model to checkpoint.h5\n",
            "Epoch 3/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.4157 - acc: 0.8090 - val_loss: 0.3754 - val_acc: 0.8313\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.35439\n",
            "Epoch 4/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.3900 - acc: 0.8360 - val_loss: 0.3567 - val_acc: 0.8413\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.35439\n",
            "Epoch 5/15\n",
            "93/93 [==============================] - 12s 124ms/step - loss: 0.4110 - acc: 0.8103 - val_loss: 0.3597 - val_acc: 0.8363\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.35439\n",
            "Epoch 6/15\n",
            "93/93 [==============================] - 12s 124ms/step - loss: 0.3995 - acc: 0.8319 - val_loss: 0.3383 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.35439 to 0.33834, saving model to checkpoint.h5\n",
            "Epoch 7/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.3957 - acc: 0.8241 - val_loss: 0.3545 - val_acc: 0.8413\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.33834\n",
            "Epoch 8/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.3952 - acc: 0.8171 - val_loss: 0.3422 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.33834\n",
            "Epoch 9/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.3557 - acc: 0.8375 - val_loss: 0.3464 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.33834\n",
            "Epoch 10/15\n",
            "93/93 [==============================] - 11s 123ms/step - loss: 0.3832 - acc: 0.8364 - val_loss: 0.3277 - val_acc: 0.8525\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.33834 to 0.32768, saving model to checkpoint.h5\n",
            "Epoch 11/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.3793 - acc: 0.8314 - val_loss: 0.3284 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.32768\n",
            "Epoch 12/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.3517 - acc: 0.8442 - val_loss: 0.3288 - val_acc: 0.8562\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.32768\n",
            "Epoch 13/15\n",
            "93/93 [==============================] - 11s 120ms/step - loss: 0.3350 - acc: 0.8564 - val_loss: 0.3215 - val_acc: 0.8550\n",
            "\n",
            "Epoch 00013: val_loss improved from 0.32768 to 0.32149, saving model to checkpoint.h5\n",
            "Epoch 14/15\n",
            "93/93 [==============================] - 11s 119ms/step - loss: 0.3819 - acc: 0.8215 - val_loss: 0.3351 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.32149\n",
            "Epoch 15/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.3585 - acc: 0.8338 - val_loss: 0.3120 - val_acc: 0.8612\n",
            "\n",
            "Epoch 00015: val_loss improved from 0.32149 to 0.31203, saving model to checkpoint.h5\n",
            "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f6b89e36358>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5f7f04a8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960aeff60>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b889ac588>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6960aef390>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960ae5400>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f4c3eb8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960b524e0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6960b6f470>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b88aaac18>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b89d629b0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f7e8c88>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f7f0208>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b80093cf8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6960adaa20>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f695ecb0cf8>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6960ada5f8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88bb47b8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f6dda58>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88600f28>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88bb42e8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b882ffda0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b80167128>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88bb4ac8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b882ffa90>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f7ceb38>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f6ddda0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b88630978>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b80051438>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b80088898>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b882ff128>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f789978>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f789898>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b80088f28>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f7f09b0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88582eb8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b88582a58>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6b8004f828>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f7896a0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b80088cc0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88582208>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b88bdc5c0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88582e10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f7ceef0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b885d2940>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b80088128>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b80072da0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88bb4080>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f789d68>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f6d34e0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b887c6668>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f7cee10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b80088a90>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b88583550>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f6dd4a8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b887c64a8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f4d1080>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b80088a58>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4d1208>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b885d7a20>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f48a048>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f6ddeb8>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f493940>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f493908>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f4d1ef0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88bad4a8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f446a90>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f446278>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b88bad8d0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4bc4e0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f453160>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f453748>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4aef60>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f493da0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f45cba8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f45c7f0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4aee48>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f45cf98>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f4746a0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b8003acc0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88aaa160>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f47bac8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f47b0f0>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f6b5f4aeef0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f474358>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f4535f8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f48ac18>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f48acf8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f446550>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f48a588>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b8003a5c0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5f45c400>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4467b8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b8003aef0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b88abc4e0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f474978>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f44ca20>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f7ce1d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b88bdca58>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f465630>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b8003ab38>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f4936a0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f424390>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5f48a518>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88bb4208>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f42bb38>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f42b438>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4934a8>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f446e80>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f42b4a8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f3c3128>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4530b8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f3c3908>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f3cb550>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b8832b908>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f42bac8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f419e80>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f3e1b00>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4d19b0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f4d19e8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f407cf8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f3ede48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4359b0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f3c3f98>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f3fd748>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b88bad0b8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f419f60>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f3f6f28>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d157a90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d157dd8>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f3fd978>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f3fde10>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f3e1dd8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d151f28>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d1578d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f3d4d68>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5f3c3dd8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f3e1a20>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f424d30>, <tensorflow.python.keras.layers.core.Activation object at 0x7f6b5f407ba8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f3d4e80>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f3ed978>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f3c39e8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d1729e8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f4d1eb8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f3fdc88>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d179f28>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f6b5f45c080>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b5f424b38>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f4bc780>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d112710>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f694d172c18>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d172400>, <tensorflow.python.keras.layers.merge.Add object at 0x7f6b5f4d1c88>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d181a90>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d121c50>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d10cef0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d172dd8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d1336a0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f694d160748>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d121d68>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f6b5f44c550>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d0c8da0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f6b88abc6a0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d112fd0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f694d112dd8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d133ef0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d0d8f28>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d13cd68>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d13cc18>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d0ece48>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f694d133470>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d13cfd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d0d87f0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d103630>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d103c18>, <tensorflow.python.keras.layers.merge.Add object at 0x7f694d0f2898>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d0ecbe0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d0e1198>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d0fb668>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d0cd198>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d133ac8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f694d13c978>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d0fbe10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d0c8748>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d1125f8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f694d103b70>, <tensorflow.python.keras.layers.merge.Add object at 0x7f694d0f29b0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f694d13ca90>, <tensorflow.python.keras.layers.core.Activation object at 0x7f694d179080>]\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50v2 (Functional)      (None, 5, 5, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 24,089,601\n",
            "Trainable params: 24,044,161\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            " 6/93 [>.............................] - ETA: 11s - loss: 1.0378 - acc: 0.8430WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0682s vs `on_train_batch_end` time: 0.0718s). Check your callbacks.\n",
            "93/93 [==============================] - 19s 161ms/step - loss: 0.5939 - acc: 0.8173 - val_loss: 0.5197 - val_acc: 0.8250\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.31203\n",
            "Epoch 2/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.3672 - acc: 0.8534 - val_loss: 0.5884 - val_acc: 0.8363\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.31203\n",
            "Epoch 3/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.3410 - acc: 0.8595 - val_loss: 0.4117 - val_acc: 0.8562\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.31203\n",
            "Epoch 4/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3078 - acc: 0.8733 - val_loss: 0.3634 - val_acc: 0.8363\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.31203\n",
            "Epoch 5/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3203 - acc: 0.8711 - val_loss: 0.4389 - val_acc: 0.8188\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.31203\n",
            "Epoch 6/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2859 - acc: 0.8798 - val_loss: 0.2803 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.31203 to 0.28030, saving model to checkpoint.h5\n",
            "Epoch 7/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2650 - acc: 0.8906 - val_loss: 0.3004 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.28030\n",
            "Epoch 8/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.3051 - acc: 0.8910 - val_loss: 0.3305 - val_acc: 0.8612\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.28030\n",
            "Epoch 9/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2536 - acc: 0.9002 - val_loss: 0.2386 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.28030 to 0.23858, saving model to checkpoint.h5\n",
            "Epoch 10/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2663 - acc: 0.8898 - val_loss: 0.8572 - val_acc: 0.6500\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.23858\n",
            "Epoch 11/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2683 - acc: 0.8896 - val_loss: 0.2391 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.23858\n",
            "Epoch 12/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2633 - acc: 0.8995 - val_loss: 0.2437 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.23858\n",
            "Epoch 13/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2413 - acc: 0.8908 - val_loss: 0.2632 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.23858\n",
            "Epoch 14/50\n",
            "93/93 [==============================] - 14s 154ms/step - loss: 0.2163 - acc: 0.9217 - val_loss: 0.3580 - val_acc: 0.8313\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.23858\n",
            "Epoch 15/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2376 - acc: 0.9034 - val_loss: 0.4571 - val_acc: 0.8225\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.23858\n",
            "Epoch 16/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2484 - acc: 0.9042 - val_loss: 0.2897 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.23858\n",
            "Epoch 17/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2306 - acc: 0.9080 - val_loss: 0.3391 - val_acc: 0.8813\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.23858\n",
            "Epoch 18/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2531 - acc: 0.8985 - val_loss: 0.3246 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.23858\n",
            "Epoch 19/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.2121 - acc: 0.9124 - val_loss: 0.5567 - val_acc: 0.6737\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.23858\n",
            "Epoch 20/50\n",
            "93/93 [==============================] - 14s 153ms/step - loss: 0.1825 - acc: 0.9312 - val_loss: 0.2372 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00020: val_loss improved from 0.23858 to 0.23720, saving model to checkpoint.h5\n",
            "Epoch 21/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2041 - acc: 0.9102 - val_loss: 0.2392 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.23720\n",
            "Epoch 22/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.2253 - acc: 0.9030 - val_loss: 0.2151 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00022: val_loss improved from 0.23720 to 0.21512, saving model to checkpoint.h5\n",
            "Epoch 23/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.2145 - acc: 0.9119 - val_loss: 0.2470 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.21512\n",
            "Epoch 24/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.1919 - acc: 0.9270 - val_loss: 0.2352 - val_acc: 0.9162\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.21512\n",
            "Epoch 25/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.2190 - acc: 0.9166 - val_loss: 0.4121 - val_acc: 0.7862\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.21512\n",
            "Epoch 26/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1898 - acc: 0.9182 - val_loss: 0.3466 - val_acc: 0.8325\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.21512\n",
            "Epoch 27/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1757 - acc: 0.9337 - val_loss: 0.2471 - val_acc: 0.9212\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.21512\n",
            "Epoch 28/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.2263 - acc: 0.9054 - val_loss: 0.2914 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.21512\n",
            "Epoch 29/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.2262 - acc: 0.9109 - val_loss: 0.4248 - val_acc: 0.8288\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.21512\n",
            "Epoch 30/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.2099 - acc: 0.9211 - val_loss: 0.5254 - val_acc: 0.7225\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.21512\n",
            "Epoch 31/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.2305 - acc: 0.9018 - val_loss: 0.8024 - val_acc: 0.7487\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.21512\n",
            "Epoch 32/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1762 - acc: 0.9292 - val_loss: 0.2739 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.21512\n",
            "Epoch 33/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1918 - acc: 0.9312 - val_loss: 0.6023 - val_acc: 0.8012\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.21512\n",
            "Epoch 34/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1759 - acc: 0.9310 - val_loss: 0.3434 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.21512\n",
            "Epoch 35/50\n",
            "93/93 [==============================] - 14s 151ms/step - loss: 0.1846 - acc: 0.9194 - val_loss: 0.3629 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.21512\n",
            "Epoch 36/50\n",
            "93/93 [==============================] - 14s 152ms/step - loss: 0.1496 - acc: 0.9478 - val_loss: 0.4043 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.21512\n",
            "Epoch 37/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1673 - acc: 0.9250 - val_loss: 0.3525 - val_acc: 0.8575\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.21512\n",
            "Epoch 38/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1532 - acc: 0.9382 - val_loss: 0.3884 - val_acc: 0.8200\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.21512\n",
            "Epoch 39/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1723 - acc: 0.9438 - val_loss: 0.3633 - val_acc: 0.8425\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.21512\n",
            "Epoch 40/50\n",
            "93/93 [==============================] - 14s 149ms/step - loss: 0.1570 - acc: 0.9319 - val_loss: 0.5781 - val_acc: 0.7775\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.21512\n",
            "Epoch 41/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1479 - acc: 0.9488 - val_loss: 0.3094 - val_acc: 0.8662\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.21512\n",
            "Epoch 42/50\n",
            "93/93 [==============================] - 14s 150ms/step - loss: 0.1666 - acc: 0.9266 - val_loss: 0.4466 - val_acc: 0.8025\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.21512\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kPGk3lGVzny"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKXFTHKtVzny"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keMpQRLoVzny"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LgXri0uVznz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "9fba2fe0-e445-4e24-dccb-8e545b1d1307"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint_2.h5'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e27933f1e170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mconv_base\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"rm 'checkpoint_2.h5'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jwxk0JAahmXq"
      },
      "source": [
        "## Flatten, Last 2 Blocks Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-7_64p2hz2B"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRXq_MGrhzuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40e844a2-98cd-411a-9e89-659089614128"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1873, 150, 150, 1)\n",
            "(803, 150, 150, 1)\n",
            "(1873,)\n",
            "(803,)\n",
            "Done\n",
            "\n",
            "(1873, 150, 150, 3)\n",
            "(336, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5CuH_gIhzsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4add663-701d-4b04-9c68-7897d3209214"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last 2 convolutional block\r\n",
        "conv_base.trainable = True\r\n",
        "set_trainable = False \r\n",
        "for layer in conv_base.layers:\r\n",
        "  if layer.name == \"conv5_block2_preact_bn\":\r\n",
        "    set_trainable = True\r\n",
        "  if set_trainable:\r\n",
        "    layer.trainable = True \r\n",
        "  else: \r\n",
        "    layer.trainable = False \r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-4\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50v2 (Functional)      (None, 5, 5, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 36,672,513\n",
            "Trainable params: 13,107,713\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "93/93 [==============================] - 15s 133ms/step - loss: 1.7999 - acc: 0.7806 - val_loss: 0.5066 - val_acc: 0.7425\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.50664, saving model to checkpoint.h5\n",
            "Epoch 2/15\n",
            "93/93 [==============================] - 11s 123ms/step - loss: 0.4324 - acc: 0.8171 - val_loss: 0.3558 - val_acc: 0.8425\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.50664 to 0.35578, saving model to checkpoint.h5\n",
            "Epoch 3/15\n",
            "93/93 [==============================] - 11s 123ms/step - loss: 0.4501 - acc: 0.7926 - val_loss: 0.3296 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.35578 to 0.32958, saving model to checkpoint.h5\n",
            "Epoch 4/15\n",
            "93/93 [==============================] - 11s 123ms/step - loss: 0.3969 - acc: 0.8222 - val_loss: 0.3498 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.32958\n",
            "Epoch 5/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.3964 - acc: 0.8268 - val_loss: 0.4214 - val_acc: 0.8300\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.32958\n",
            "Epoch 6/15\n",
            "93/93 [==============================] - 11s 124ms/step - loss: 0.3973 - acc: 0.8434 - val_loss: 0.3522 - val_acc: 0.8425\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.32958\n",
            "Epoch 7/15\n",
            "93/93 [==============================] - 11s 120ms/step - loss: 0.3752 - acc: 0.8412 - val_loss: 0.3249 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.32958 to 0.32492, saving model to checkpoint.h5\n",
            "Epoch 8/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.3552 - acc: 0.8477 - val_loss: 0.3270 - val_acc: 0.8587\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.32492\n",
            "Epoch 9/15\n",
            "93/93 [==============================] - 11s 124ms/step - loss: 0.3481 - acc: 0.8580 - val_loss: 0.3338 - val_acc: 0.8487\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.32492\n",
            "Epoch 10/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.3853 - acc: 0.8340 - val_loss: 0.3238 - val_acc: 0.8512\n",
            "\n",
            "Epoch 00010: val_loss improved from 0.32492 to 0.32376, saving model to checkpoint.h5\n",
            "Epoch 11/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.3418 - acc: 0.8574 - val_loss: 0.3308 - val_acc: 0.8450\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.32376\n",
            "Epoch 12/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.3253 - acc: 0.8678 - val_loss: 0.3057 - val_acc: 0.8687\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.32376 to 0.30568, saving model to checkpoint.h5\n",
            "Epoch 13/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.3357 - acc: 0.8548 - val_loss: 0.3197 - val_acc: 0.8612\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.30568\n",
            "Epoch 14/15\n",
            "93/93 [==============================] - 11s 120ms/step - loss: 0.3456 - acc: 0.8419 - val_loss: 0.3198 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.30568\n",
            "Epoch 15/15\n",
            "93/93 [==============================] - 11s 120ms/step - loss: 0.2970 - acc: 0.8772 - val_loss: 0.3213 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.30568\n",
            "[<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x7f5799e58208>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f5799e58a58>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c3eb1940>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f5799e6cb38>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f57c3e73c50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f5799e546d8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2c28588>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2bc25c0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f5799e54f98>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2bd3048>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2bd3d68>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2bd3390>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2bda3c8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2be4b70>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2bc2ba8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2c285f8>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2becc88>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2bf2c18>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2bf22e8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2bfacf8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b7f7b8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b87780>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2bfa438>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b92da0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b98860>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b98a58>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b9ed30>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2ba5978>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2baa908>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2baaa90>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2bbb208>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2bbbe48>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2bbb828>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2b4b588>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b4bfd0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b51a90>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b4b0b8>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f57c2bb3898>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b61668>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2b61940>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b57908>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b68b00>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b72a58>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b61780>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b51b38>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2ba54e0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b43e10>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b61ef0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b9e6a0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b78160>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b92eb8>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2bb3198>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b87710>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2bf2dd8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b43c18>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2be41d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2c28ef0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2be4048>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b782b0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b00828>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b00390>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b04208>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2b0d940>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b148d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b14a58>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b1a860>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b23470>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b23f28>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2b2afd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b30a58>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b36518>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b365c0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2abe9e8>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2ac6630>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2acd5c0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2acd828>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2ad4e80>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2adbb00>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2adb6d8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2aec048>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2aecc88>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2af0748>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2aec198>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f57c2ad4550>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a7e320>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2a7ef60>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2af9b00>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2af03c8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2ad41d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2af97b8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2abe3c8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2b235f8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2b2ab00>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2af0390>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2b1a128>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2ac66a0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c3eb1128>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2b1a278>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2bc2518>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2be42e8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2abe6d8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2b877f0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a867b8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2b92710>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a91f60>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a97a20>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a97710>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a9c358>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2aa9b38>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2aabac8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2aabc88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2ab4a58>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2abd668>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2abdf28>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2a4c208>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a4cc50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a50710>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a503c8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a5cbe0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2a60828>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a687b8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a68b70>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a6e748>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a76358>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a76d30>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c29feeb8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a06940>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a0c400>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a0cd30>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a76588>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2a6e860>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a4cb38>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a4cda0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a445f8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2aa96a0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2ab4550>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2a9c588>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a91710>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a86518>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2bec7b8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f5799e6c9b0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c2ae1320>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a13a90>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a13710>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a1f390>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a28160>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a1fbe0>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2a30710>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a30eb8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a37c18>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a1a668>, <tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x7f57c2a1aa20>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c29c67f0>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c29c61d0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a3bb38>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c29cbc88>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c29d3828>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a3b978>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c29e4828>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c29e5e48>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c29e50b8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c29d85c0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c29f1b38>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c29d82e8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c29e4e10>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c29812b0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2988240>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2988fd0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c29e40b8>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2991da0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2997d68>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2981b38>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2988a58>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c29918d0>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c29f96a0>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2991a90>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c29f9940>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c29f9ac8>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a377b8>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2991ef0>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2988f28>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c2a132e8>, <tensorflow.python.keras.layers.convolutional.ZeroPadding2D object at 0x7f57c2997d30>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c29f9358>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2bda978>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c29fe240>, <tensorflow.python.keras.layers.convolutional.Conv2D object at 0x7f57c2a30080>, <tensorflow.python.keras.layers.merge.Add object at 0x7f57c29d8c50>, <tensorflow.python.keras.layers.normalization_v2.BatchNormalization object at 0x7f57c2a1a240>, <tensorflow.python.keras.layers.core.Activation object at 0x7f57c29addd8>]\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50v2 (Functional)      (None, 5, 5, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               13107456  \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 36,672,513\n",
            "Trainable params: 22,041,089\n",
            "Non-trainable params: 14,631,424\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "93/93 [==============================] - 15s 132ms/step - loss: 0.9641 - acc: 0.8247 - val_loss: 0.3675 - val_acc: 0.8350\n",
            "\n",
            "Epoch 00001: val_loss did not improve from 0.30568\n",
            "Epoch 2/50\n",
            "93/93 [==============================] - 12s 124ms/step - loss: 0.3830 - acc: 0.8259 - val_loss: 0.3053 - val_acc: 0.8687\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.30568 to 0.30534, saving model to checkpoint.h5\n",
            "Epoch 3/50\n",
            "93/93 [==============================] - 12s 124ms/step - loss: 0.3532 - acc: 0.8466 - val_loss: 0.3684 - val_acc: 0.8537\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.30534\n",
            "Epoch 4/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.3630 - acc: 0.8335 - val_loss: 0.4058 - val_acc: 0.8425\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.30534\n",
            "Epoch 5/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.3392 - acc: 0.8490 - val_loss: 0.3073 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.30534\n",
            "Epoch 6/50\n",
            "93/93 [==============================] - 12s 124ms/step - loss: 0.3299 - acc: 0.8480 - val_loss: 0.3076 - val_acc: 0.8650\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.30534\n",
            "Epoch 7/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.3111 - acc: 0.8690 - val_loss: 0.2973 - val_acc: 0.8737\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.30534 to 0.29729, saving model to checkpoint.h5\n",
            "Epoch 8/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.3415 - acc: 0.8691 - val_loss: 0.3037 - val_acc: 0.8725\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.29729\n",
            "Epoch 9/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2919 - acc: 0.8833 - val_loss: 0.3117 - val_acc: 0.8750\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.29729\n",
            "Epoch 10/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.3104 - acc: 0.8630 - val_loss: 0.3574 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.29729\n",
            "Epoch 11/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.3266 - acc: 0.8582 - val_loss: 0.3311 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.29729\n",
            "Epoch 12/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2936 - acc: 0.8828 - val_loss: 0.2897 - val_acc: 0.8763\n",
            "\n",
            "Epoch 00012: val_loss improved from 0.29729 to 0.28974, saving model to checkpoint.h5\n",
            "Epoch 13/50\n",
            "93/93 [==============================] - 12s 124ms/step - loss: 0.3000 - acc: 0.8791 - val_loss: 0.2911 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.28974\n",
            "Epoch 14/50\n",
            "93/93 [==============================] - 12s 127ms/step - loss: 0.2795 - acc: 0.8789 - val_loss: 0.2696 - val_acc: 0.8925\n",
            "\n",
            "Epoch 00014: val_loss improved from 0.28974 to 0.26963, saving model to checkpoint.h5\n",
            "Epoch 15/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.3068 - acc: 0.8768 - val_loss: 0.3010 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.26963\n",
            "Epoch 16/50\n",
            "93/93 [==============================] - 12s 127ms/step - loss: 0.2904 - acc: 0.8819 - val_loss: 0.3312 - val_acc: 0.8625\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.26963\n",
            "Epoch 17/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2904 - acc: 0.8719 - val_loss: 0.3222 - val_acc: 0.8637\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.26963\n",
            "Epoch 18/50\n",
            "93/93 [==============================] - 12s 124ms/step - loss: 0.2843 - acc: 0.8809 - val_loss: 0.2908 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.26963\n",
            "Epoch 19/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2678 - acc: 0.8976 - val_loss: 0.2820 - val_acc: 0.8825\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.26963\n",
            "Epoch 20/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2806 - acc: 0.8850 - val_loss: 0.2929 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.26963\n",
            "Epoch 21/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2798 - acc: 0.8938 - val_loss: 0.2925 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.26963\n",
            "Epoch 22/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2975 - acc: 0.8757 - val_loss: 0.3120 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.26963\n",
            "Epoch 23/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2979 - acc: 0.8790 - val_loss: 0.2746 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.26963\n",
            "Epoch 24/50\n",
            "93/93 [==============================] - 12s 127ms/step - loss: 0.2940 - acc: 0.8793 - val_loss: 0.2577 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00024: val_loss improved from 0.26963 to 0.25773, saving model to checkpoint.h5\n",
            "Epoch 25/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2471 - acc: 0.9084 - val_loss: 0.2680 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.25773\n",
            "Epoch 26/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2737 - acc: 0.8917 - val_loss: 0.2422 - val_acc: 0.9013\n",
            "\n",
            "Epoch 00026: val_loss improved from 0.25773 to 0.24220, saving model to checkpoint.h5\n",
            "Epoch 27/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2681 - acc: 0.8913 - val_loss: 0.2502 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.24220\n",
            "Epoch 28/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2688 - acc: 0.8888 - val_loss: 0.2470 - val_acc: 0.8963\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.24220\n",
            "Epoch 29/50\n",
            "93/93 [==============================] - 12s 128ms/step - loss: 0.2605 - acc: 0.8912 - val_loss: 0.2618 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.24220\n",
            "Epoch 30/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2540 - acc: 0.8887 - val_loss: 0.2655 - val_acc: 0.8838\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.24220\n",
            "Epoch 31/50\n",
            "93/93 [==============================] - 12s 124ms/step - loss: 0.2696 - acc: 0.8910 - val_loss: 0.2771 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.24220\n",
            "Epoch 32/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2663 - acc: 0.8942 - val_loss: 0.2947 - val_acc: 0.8788\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.24220\n",
            "Epoch 33/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2703 - acc: 0.9009 - val_loss: 0.2579 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.24220\n",
            "Epoch 34/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2245 - acc: 0.9069 - val_loss: 0.2781 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.24220\n",
            "Epoch 35/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2484 - acc: 0.9014 - val_loss: 0.3185 - val_acc: 0.8675\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.24220\n",
            "Epoch 36/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2311 - acc: 0.9142 - val_loss: 0.2688 - val_acc: 0.8875\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.24220\n",
            "Epoch 37/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2409 - acc: 0.9024 - val_loss: 0.2684 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.24220\n",
            "Epoch 38/50\n",
            "93/93 [==============================] - 12s 124ms/step - loss: 0.2273 - acc: 0.9114 - val_loss: 0.3143 - val_acc: 0.8825\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.24220\n",
            "Epoch 39/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2436 - acc: 0.9022 - val_loss: 0.2782 - val_acc: 0.8888\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.24220\n",
            "Epoch 40/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2373 - acc: 0.9087 - val_loss: 0.2671 - val_acc: 0.8975\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.24220\n",
            "Epoch 41/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2449 - acc: 0.8910 - val_loss: 0.2730 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.24220\n",
            "Epoch 42/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2629 - acc: 0.8901 - val_loss: 0.2858 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.24220\n",
            "Epoch 43/50\n",
            "93/93 [==============================] - 12s 126ms/step - loss: 0.2279 - acc: 0.9127 - val_loss: 0.2917 - val_acc: 0.8988\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.24220\n",
            "Epoch 44/50\n",
            "93/93 [==============================] - 12s 127ms/step - loss: 0.2309 - acc: 0.9118 - val_loss: 0.3117 - val_acc: 0.8938\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.24220\n",
            "Epoch 45/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2473 - acc: 0.9122 - val_loss: 0.2758 - val_acc: 0.8913\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.24220\n",
            "Epoch 46/50\n",
            "93/93 [==============================] - 12s 125ms/step - loss: 0.2340 - acc: 0.9164 - val_loss: 0.3025 - val_acc: 0.8763\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.24220\n",
            "done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsGBlliIhzp6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "cdd6f772-8b67-4e72-bec4-10ccb541b11e"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeEGGbqfhznv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "outputId": "56a33ec6-7f92-4e24-b648-bdf0bbfc5d43"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 34ms/step - loss: 0.2587 - acc: 0.8938\n",
            "\n",
            "---------------------------------\n",
            "Accuracy: 89.38 %\n",
            "---------------------------------\n",
            "\n",
            "Confusion Matrix\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.87      0.90       179\n",
            "         1.0       0.86      0.92      0.89       157\n",
            "\n",
            "    accuracy                           0.89       336\n",
            "   macro avg       0.89      0.89      0.89       336\n",
            "weighted avg       0.89      0.89      0.89       336\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DgfrajxhzlT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "30979689-89fa-4e87-9c1b-a8d4a58a0cea"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgwLFWnutK3X"
      },
      "source": [
        "models.save_model(model, os.path.join(MODEL_PATH, 'resNet_dense_256x1_last_2_blocks_trainable.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkh-0_QxhzjE"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMWPlmck4aMu"
      },
      "source": [
        "## GlobalAveragePooling, Last 2 Blocks Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0QFAYq_4dex"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyNJoa8v4eCb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa4a4c09-bb87-4588-ed0c-957a35007587"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1873, 150, 150, 1)\n",
            "(803, 150, 150, 1)\n",
            "(1873,)\n",
            "(803,)\n",
            "Done\n",
            "\n",
            "(1873, 150, 150, 3)\n",
            "(336, 150, 150, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8aq3j5N4eAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58101e3b-9279-4601-9772-b39106905787"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.GlobalAveragePooling2D())\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "conv_base.trainable = True\r\n",
        "set_trainable = False \r\n",
        "for layer in conv_base.layers:\r\n",
        "  if layer.name == \"conv5_block2_preact_bn\":\r\n",
        "    set_trainable = True\r\n",
        "  if set_trainable:\r\n",
        "    layer.trainable = True \r\n",
        "  else: \r\n",
        "    layer.trainable = False \r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-4\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "resnet50v2 (Functional)      (None, 5, 5, 2048)        23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               524544    \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 24,089,601\n",
            "Trainable params: 524,801\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "93/93 [==============================] - 15s 138ms/step - loss: 0.5461 - acc: 0.7871 - val_loss: 0.4276 - val_acc: 0.8050\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.42763, saving model to checkpoint.h5\n",
            "Epoch 2/15\n",
            "93/93 [==============================] - 11s 122ms/step - loss: 0.4542 - acc: 0.7938 - val_loss: 0.3792 - val_acc: 0.8238\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.42763 to 0.37921, saving model to checkpoint.h5\n",
            "Epoch 3/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.3976 - acc: 0.8189 - val_loss: 0.3651 - val_acc: 0.8325\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.37921 to 0.36513, saving model to checkpoint.h5\n",
            "Epoch 4/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.3981 - acc: 0.8282 - val_loss: 0.3588 - val_acc: 0.8462\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.36513 to 0.35881, saving model to checkpoint.h5\n",
            "Epoch 5/15\n",
            "93/93 [==============================] - 11s 121ms/step - loss: 0.3874 - acc: 0.8377 - val_loss: 0.3833 - val_acc: 0.8300\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.35881\n",
            "Epoch 6/15\n",
            "16/93 [====>.........................] - ETA: 7s - loss: 0.4315 - acc: 0.8130"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpPr2ouS4d-S"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJvDl4rO4d8k"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2dQ1frL4d6O"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OC3pRDy4d4T"
      },
      "source": [
        "models.save_model(model, os.path.join(MODEL_PATH, 'vgg__globalAvgPool_dense_256x1_last_2_blocks_trainable.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_kg-orv4d2J"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnWr3aLsiFMA"
      },
      "source": [
        "## BEST - Flatten, Last 3 Blocks Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU-5qco0hzfL"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gd00cR6DsQ6-"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV__2_f-sQ43"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "conv_base.trainable = True\r\n",
        "set_trainable = False \r\n",
        "for layer in conv_base.layers:\r\n",
        "  if layer.name == \"block3_conv1\":\r\n",
        "    set_trainable = True\r\n",
        "  if set_trainable:\r\n",
        "    layer.trainable = True \r\n",
        "  else: \r\n",
        "    layer.trainable = False \r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-4\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjIqWnb0sQ2a"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONhAfPy1sQ0b"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWlwN_f9sQyv"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tVY6gFAy_10"
      },
      "source": [
        "models.save_model(model, os.path.join(MODEL_PATH, 'vgg_dense_256x1_last_3_blocks_trainable.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrgrucaPsQvp"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdcWShaL8nPy"
      },
      "source": [
        "## GlobalAveragePooling, Last 3 Blocks Trainable\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skyhE-SV8q8Q"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXlbFhaZ85lh"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeKrPVlS85ll"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.GlobalAveragePooling2D())\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "conv_base.trainable = True\r\n",
        "set_trainable = False \r\n",
        "for layer in conv_base.layers:\r\n",
        "  if layer.name == \"block3_conv1\":\r\n",
        "    set_trainable = True\r\n",
        "  if set_trainable:\r\n",
        "    layer.trainable = True \r\n",
        "  else: \r\n",
        "    layer.trainable = False \r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-4\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Lv1BomC85ll"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7l1E57D85lm"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNVBHcQH85lm"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLnn24sf85lm"
      },
      "source": [
        "models.save_model(model, os.path.join(MODEL_PATH, 'vgg__globalAvgPool_dense_256x1_last_3_blocks_trainable.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ly-A73Rq85lm"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npG7fjb4ufRn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBjD1oj5ufPa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4IQVSaFzue65"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ta2YKkEupYa"
      },
      "source": [
        "# Architecture : Flatten/GlobalAveragePooling, 3x [ DropOut(0.5 + Dense (256)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzlS1FAYupYg"
      },
      "source": [
        "## Flatten, all trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYjm5YmvupYg"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t0K15BkupYi"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTXBOzJdupYj"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint_2.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint_2.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "#conv_base.trainable = True\r\n",
        "\r\n",
        "for layer in model.layers:\r\n",
        "  layer.trainable = True\r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-3),  #lr=1e-3\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unQtsXDYupYj"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZD43-2zupYk"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6mJG3YKupYk"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh35I3K2upYl"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint_2.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecGuQcLzupYl"
      },
      "source": [
        "## GlobalAveragePooling, all Trainable\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PX31LuFMupYm"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aqCdsRlupYm"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4z2kXUqNupYm"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint_2.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.GlobalAveragePooling2D())\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint_2.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "#conv_base.trainable = True\r\n",
        "\r\n",
        "for layer in model.layers:\r\n",
        "  layer.trainable = True\r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-3),  #lr=1e-3\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint_2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_tr1WscupYn"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFLH8GnZupYn"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcfoWWWvupYn"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KrFOKSZupYo"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint_2.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VftaeiMPupYo"
      },
      "source": [
        "## Flatten, Last 2 Blocks Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDtOrjOhupYo"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vayEiTK0upYp"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v29KcdjCupYp"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "conv_base.trainable = True\r\n",
        "set_trainable = False \r\n",
        "for layer in conv_base.layers:\r\n",
        "  if layer.name == \"block4_conv1\":\r\n",
        "    set_trainable = True\r\n",
        "  if set_trainable:\r\n",
        "    layer.trainable = True \r\n",
        "  else: \r\n",
        "    layer.trainable = False \r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-4\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJ4JYQrRupYp"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-AimU1NupYp"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDMz8fn9upYq"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7Bh3osqupYq"
      },
      "source": [
        "models.save_model(model, os.path.join(MODEL_PATH, 'vgg_dense_256x1_last_2_blocks_trainable.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV4NDlKFupYq"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PzHNKNdupYq"
      },
      "source": [
        "## GlobalAveragePooling, Last 2 Blocks Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyhFc2p7upYr"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNBIknOaupYr"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-T5UoBYupYr"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.GlobalAveragePooling2D())\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "conv_base.trainable = True\r\n",
        "set_trainable = False \r\n",
        "for layer in conv_base.layers:\r\n",
        "  if layer.name == \"block4_conv1\":\r\n",
        "    set_trainable = True\r\n",
        "  if set_trainable:\r\n",
        "    layer.trainable = True \r\n",
        "  else: \r\n",
        "    layer.trainable = False \r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-4\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_HSt13QupYr"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x5SJhZ0upYr"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d9EWEa2upYs"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHCg1QPEupYs"
      },
      "source": [
        "models.save_model(model, os.path.join(MODEL_PATH, 'vgg__globalAvgPool_dense_256x1_last_2_blocks_trainable.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QdD_C3xupYs"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7DCU1ImupYs"
      },
      "source": [
        "## BEST - Flatten, Last 3 Blocks Trainable"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVBMykPRupYs"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RtlbPm9EupYt"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDyvFCAcupYt"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.Flatten())\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "conv_base.trainable = True\r\n",
        "set_trainable = False \r\n",
        "for layer in conv_base.layers:\r\n",
        "  if layer.name == \"block3_conv1\":\r\n",
        "    set_trainable = True\r\n",
        "  if set_trainable:\r\n",
        "    layer.trainable = True \r\n",
        "  else: \r\n",
        "    layer.trainable = False \r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-4\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3hIxBUIupYt"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4khCurTtupYt"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k96ksP36upYt"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-_88D9mupYu"
      },
      "source": [
        "models.save_model(model, os.path.join(MODEL_PATH, 'vgg_dense_256x1_last_3_blocks_trainable.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4dewqlupYu"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyhhanFrupYu"
      },
      "source": [
        "## GlobalAveragePooling, Last 3 Blocks Trainable\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U4QN-bfPupYu"
      },
      "source": [
        "from keras.applications import ResNet50V2\r\n",
        "from tensorflow.keras import models\r\n",
        "from tensorflow.keras import layers\r\n",
        "\r\n",
        "#load VGG16 as convolutional base\r\n",
        "conv_base = ResNet50V2(weights='imagenet',\r\n",
        "                     include_top=False,\r\n",
        "                     input_shape=(150, 150, 3))\r\n",
        "\r\n",
        "#conv_base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My467kgUupYu"
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "train_images_split, valid_images_split, train_labels_split, valid_labels_split, train_datagen, valid_datagen, test_datagen = init_data(base_NN=\"ResNet50\", GCN=False, augmentation=True)\r\n",
        "\r\n",
        "\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "test_images, test_labels = shuffle_dataset(test_images, test_labels)\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "#expand test images from grayscale to RGB \r\n",
        "if test_images.shape[3] == 1:\r\n",
        "  test_images = np.repeat(test_images, 3, axis = 3)\r\n",
        "\r\n",
        "print()\r\n",
        "print(train_images_split.shape)\r\n",
        "print(test_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfB4mB6zupYv"
      },
      "source": [
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath='checkpoint.h5',\r\n",
        "    save_weights_only=True,\r\n",
        "    monitor='val_loss',\r\n",
        "    mode='auto',\r\n",
        "    save_best_only=True,\r\n",
        "    verbose = 1)\r\n",
        "\r\n",
        "#add custom fully-connected network on top of the already-trained base network \r\n",
        "model = models.Sequential()\r\n",
        "model.add(conv_base)\r\n",
        "model.add(layers.GlobalAveragePooling2D())\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(256, activation=\"relu\"))\r\n",
        "model.add(layers.Dense(1, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "#freeze convolutional base \r\n",
        "conv_base.trainable = False\r\n",
        "model.summary()\r\n",
        "\r\n",
        "model.compile(loss=\"binary_crossentropy\",\r\n",
        "            optimizer=optimizers.Adam(lr=1e-3), # lr = 0.0001\r\n",
        "            metrics=METRICS) \r\n",
        "\r\n",
        "#train fully-connected added part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=15,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "\r\n",
        "model.load_weights('checkpoint.h5')\r\n",
        "\r\n",
        "#unfreeze last convolutional block\r\n",
        "conv_base.trainable = True\r\n",
        "set_trainable = False \r\n",
        "for layer in conv_base.layers:\r\n",
        "  if layer.name == \"block3_conv1\":\r\n",
        "    set_trainable = True\r\n",
        "  if set_trainable:\r\n",
        "    layer.trainable = True \r\n",
        "  else: \r\n",
        "    layer.trainable = False \r\n",
        "\r\n",
        "print(conv_base.layers)\r\n",
        "\r\n",
        "model.summary()\r\n",
        "model.compile(loss='binary_crossentropy',\r\n",
        "              optimizer=optimizers.Adam(lr=1e-4),  #lr=1e-4\r\n",
        "              metrics=METRICS)\r\n",
        "\r\n",
        "\r\n",
        "#jointly train both the unfreezed layers and the fully-connected part \r\n",
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=True),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[es, model_checkpoint_callback, GarbageCollectorCallback()])\r\n",
        "print('done')\r\n",
        "model.load_weights('checkpoint.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9W8S-ynupYv"
      },
      "source": [
        "plt_a = plot_acc(history)\r\n",
        "#save & show plot\r\n",
        "#plt_a.savefig(os.path.join(PLOTS_PATH, 'model_0_a.png'))\r\n",
        "plt_a.show()\r\n",
        "\r\n",
        "plt_b = plot_loss(history)\r\n",
        "#save & show plot\r\n",
        "#plt_b.savefig(os.path.join(PLOTS_PATH, 'model_0_b.png'))\r\n",
        "plt_b.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JISMpQFaupYv"
      },
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                            test_labels,\r\n",
        "                                                            batch_size=BATCH_SIZE,\r\n",
        "                                                            shuffle=False),\r\n",
        "                                            steps=len(test_images) // BATCH_SIZE,\r\n",
        "                                            callbacks=[GarbageCollectorCallback()]\r\n",
        ")\r\n",
        "\r\n",
        "print(\"\\n---------------------------------\")\r\n",
        "print(\"Accuracy:\", \"%0.2f\" % (test_accuracy*100), \"%\")\r\n",
        "#print(\"Precision:\", \"%0.2f\" % (test_precision*100), \"%\")\r\n",
        "#print(\"Recall:\", \"%0.2f\" % (test_recall*100), \"%\")\r\n",
        "#print(\"AUC:\", \"%0.2f\" % test_auc)\r\n",
        "print(\"---------------------------------\\n\")\r\n",
        "\r\n",
        "#print confusion matrix\r\n",
        "classes = [\"Masses\", \"Calcification\"]\r\n",
        "plt_0 = plot_confusion_matrix(model,\r\n",
        "                      classes,\r\n",
        "                      test_images,\r\n",
        "                      test_labels,\r\n",
        "                      title='Confusion matrix',\r\n",
        "                      cmap=plt.cm.Blues)  \r\n",
        "\r\n",
        "#save plot\r\n",
        "#plt_0.savefig(os.path.join(PLOTS_PATH, 'model_0_CM.png'))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InI7LuDOupYv"
      },
      "source": [
        "#ROC-AUC \r\n",
        "auc_1, plt_1 = plot_AUC(model, test_images, test_labels)\r\n",
        "AUC_values.append(auc_1)\r\n",
        "\r\n",
        "#save & show plot\r\n",
        "#plt_1.savefig(os.path.join(PLOTS_PATH, 'model_1_AUC.png'))\r\n",
        "plt_1.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E-BKjqeupYv"
      },
      "source": [
        "models.save_model(model, os.path.join(MODEL_PATH, 'vgg__globalAvgPool_dense_256x1_last_3_blocks_trainable.h5'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6M6TSrbLupYw"
      },
      "source": [
        "#free RAM \r\n",
        "del model\r\n",
        "del conv_base\r\n",
        "del history\r\n",
        "!rm 'checkpoint.h5'"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}