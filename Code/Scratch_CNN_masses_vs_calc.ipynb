{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scratch_CNN_masses_vs_calc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarshaGomez/CNN-Medical-Imaging-Analysis/blob/main/Code/Scratch_CNN_masses_vs_calc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPQ8gkXb0NY0"
      },
      "source": [
        "# **Scratch CNN**\r\n",
        "---\r\n",
        "Classification model for discriminating between 2 classes: **masses and calcification**. *Ad-hoc CNN architecture*.\r\n",
        "\r\n",
        "**Students:**   *A. Schiavo - M. GÃ³mez - M. Daole*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AB6hExesaEvW"
      },
      "source": [
        "## Data Loading\r\n",
        "This can be easily done with the Python data manipulation. Modern deep learning provides a very powerful framework for supervised learning, we introduce on this step the convolutional network for scaling to large images.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95hM4MvWjwfO",
        "outputId": "9a6c5626-f80f-4e61-936f-ace8a9bc3b91"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive', force_remount=True) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iduaD281krFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ed7102e-106b-454c-9f61-8a6ec2cb6a9b"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import pandas as pd \r\n",
        "import ast #Abstract Syntax Trees\r\n",
        "import os \r\n",
        "import gc # Garbage Collector\r\n",
        "\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from keras import layers\r\n",
        "from keras import optimizers \r\n",
        "from keras import models\r\n",
        "from keras import regularizers\r\n",
        "\r\n",
        "BATCH_SIZE = 20\r\n",
        "EPOCHS = 100\r\n",
        "\r\n",
        "base_path = \"/content/gdrive/My Drive/Colab_Notebooks/CIDL/DL Project/numpy data\"\r\n",
        "train_img_path = os.path.join(base_path, 'train_tensor.npy')\r\n",
        "train_label_path = os.path.join(base_path, 'train_labels.npy')\r\n",
        "test_img_path = os.path.join(base_path, 'public_test_tensor.npy')\r\n",
        "test_label_path = os.path.join(base_path, 'public_test_labels.npy')\r\n",
        "\r\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HEhhQy4Sr_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4867be9b-c5de-4928-bde8-168156cc7ecd"
      },
      "source": [
        "# Custom Callback To Include in Callbacks List At Training Time\r\n",
        "class GarbageCollectorCallback(tf.keras.callbacks.Callback):\r\n",
        "    def on_epoch_end(self, epoch, logs=None):\r\n",
        "      gc.collect()\r\n",
        "\r\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek9JMlmD6GsU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5acdf20c-8f5b-4899-fcaf-fa482d749def"
      },
      "source": [
        "# Load Arrays from Numpy Files\r\n",
        "def load_training():\r\n",
        "  train_images = np.load(train_img_path)\r\n",
        "  train_labels = np.load(train_label_path)\r\n",
        "  test_images = np.load(test_img_path)\r\n",
        "  test_labels = np.load(test_label_path)\r\n",
        "\r\n",
        "  return train_images, train_labels, test_images, test_labels\r\n",
        "\r\n",
        "# Remove baseline samples\r\n",
        "def remove_baseline(tensor): \r\n",
        "  max_ind = int(len(tensor)/2)\r\n",
        "  indexes = [2*i + 1 for i in range(0, max_ind)]\r\n",
        "\r\n",
        "  return tensor[indexes]\r\n",
        "\r\n",
        "# Interchange the dataset index\r\n",
        "def shuffle_dataset(x, y):\r\n",
        "  indices = tf.range(start=0, limit=tf.shape(x)[0], dtype=tf.int32)\r\n",
        "  shuffled_indices = tf.random.shuffle(indices)\r\n",
        "\r\n",
        "  x = tf.gather(x, shuffled_indices)\r\n",
        "  y = tf.gather(y, shuffled_indices)\r\n",
        "\r\n",
        "  x = x.numpy()\r\n",
        "  y = y.numpy()\r\n",
        "\r\n",
        "  return x, y\r\n",
        "\r\n",
        "# Unify masses and calcifications \r\n",
        "def labels_mapping(labels):\r\n",
        "  labels_local = np.zeros(shape=labels.shape, dtype=\"float32\")\r\n",
        "  idx = 0\r\n",
        "  for label in labels:\r\n",
        "    # Masses\r\n",
        "    if label == 1 or label == 2:\r\n",
        "      labels_local[idx] = 0\r\n",
        "    # Calcifications\r\n",
        "    else:\r\n",
        "      labels_local[idx] = 1\r\n",
        "    idx += 1\r\n",
        "\r\n",
        "  return labels_local\r\n",
        "\r\n",
        "print(\"Done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gowt9JUQ6sdj",
        "outputId": "4883707e-a399-4a98-94ee-26a20c9d82ad"
      },
      "source": [
        "# Get images and labels (test, train)\r\n",
        "train_images, train_labels, test_images, test_labels = load_training()\r\n",
        "\r\n",
        "# Get abnormalities only \r\n",
        "train_images = remove_baseline(train_images)\r\n",
        "train_labels = remove_baseline(train_labels)\r\n",
        "test_images = remove_baseline(test_images)\r\n",
        "test_labels = remove_baseline(test_labels)\r\n",
        "\r\n",
        "# Mapping labels with standard index\r\n",
        "train_labels = labels_mapping(train_labels)\r\n",
        "test_labels = labels_mapping(test_labels)\r\n",
        "\r\n",
        "# Suffle index (Previous dataset is ordered by index)\r\n",
        "train_images, train_labels = shuffle_dataset(train_images, train_labels)\r\n",
        "\r\n",
        "print(\"Train shape: \", train_images.shape)\r\n",
        "print(\"Test shape: \", test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape:  (2676, 150, 150)\n",
            "Test shape:  (336, 150, 150)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrrJFfg2e4fL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b75cf78-1ce0-43c3-85f0-35971ac8191b"
      },
      "source": [
        "# Prepare the data with the expected format\r\n",
        "train_images = train_images.reshape(train_images.shape + (1,))\r\n",
        "test_images = test_images.reshape(test_images.shape + (1,))\r\n",
        "\r\n",
        "print(\"Train shape: \", train_images.shape)\r\n",
        "print(\"Test shape: \", test_images.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train shape:  (2676, 150, 150, 1)\n",
            "Test shape:  (336, 150, 150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t4iLd0ExZho"
      },
      "source": [
        "## Data preprocessing\r\n",
        "\r\n",
        "Computer vision usually requires relatively little of this kind of preprocessing. The images should be standardized, formatting images to have the same scale is the only kind of preprocessing that is strictly necessary. As optional, we add dataset augmentation because is an excellent way to reduce the generalization error of most computer vision models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfMviUsBn-gX",
        "outputId": "b9318974-60b3-420e-e255-bfc3001a2ddf"
      },
      "source": [
        "# Split dataset into training and validation set 70-30\r\n",
        "train_images_split = train_images[:int(0.7*len(train_images))]\r\n",
        "valid_images_split = train_images[int(0.7*len(train_images)):]\r\n",
        "train_labels_split = train_labels[:int(0.7*len(train_labels))]\r\n",
        "valid_labels_split = train_labels[int(0.7*len(train_labels)):]\r\n",
        "\r\n",
        "print(train_images_split.shape)\r\n",
        "print(valid_images_split.shape)                                       "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1873, 150, 150, 1)\n",
            "(803, 150, 150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAimqVVOhaH7"
      },
      "source": [
        "# Verify values range: Getting max value \r\n",
        "print(max([np.max(image) for image in train_images])) # max is 65535 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hm9x-21nzEoE",
        "outputId": "977ce240-32cf-4ce5-a72a-c20de207d7a7"
      },
      "source": [
        "# All images will be rescaled by 1./65535 (max value range)\r\n",
        "train_datagen = ImageDataGenerator(rescale=1./65535)\r\n",
        "valid_datagen = ImageDataGenerator(rescale=1./65535)\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./65535) \r\n",
        "\r\n",
        "for batch, labels_batch in train_datagen.flow(train_images, train_labels, batch_size=BATCH_SIZE):\r\n",
        "  print(batch.shape)\r\n",
        "  print(labels_batch.shape)\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20, 150, 150, 1)\n",
            "(20,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi0ZJVf1vA31"
      },
      "source": [
        "### Defining CNN \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwQTeDPEvKql"
      },
      "source": [
        "\r\n",
        "\r\n",
        "def build_model(loss_function, eval_metric):\r\n",
        "  model = models.Sequential()\r\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Conv2D(128, (3, 3), activation='relu'))\r\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  #model.add(layers.Dense(512, activation='relu'))\r\n",
        "  #model.add(layers.Dropout(0.5))\r\n",
        "  model.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.001), activation=\"relu\"))\r\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "  model.compile(loss=loss_function,\r\n",
        "              optimizer=optimizers.RMSprop(lr=1e-4), # lr = 0.0001\r\n",
        "              metrics=[\"acc\"]) \r\n",
        "  \r\n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZIemXxawWLm"
      },
      "source": [
        "## CNN Compilation:\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iumGmf1whk1",
        "outputId": "3c147165-5a22-4334-ea1d-aec1c5ca9b9c"
      },
      "source": [
        "model = build_model(\"binary_crossentropy\", \"acc\")\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 148, 148, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,452,545\n",
            "Trainable params: 3,452,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-V8cw96y_3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e11a5afa-4fb8-45de-fe16-4c5480133932"
      },
      "source": [
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=50,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[GarbageCollectorCallback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "93/93 [==============================] - 10s 25ms/step - loss: 1.4390 - acc: 0.5212 - val_loss: 1.0513 - val_acc: 0.5462\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 2/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.9755 - acc: 0.5808 - val_loss: 0.8096 - val_acc: 0.5462\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 3/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.7742 - acc: 0.6212 - val_loss: 0.6801 - val_acc: 0.7538\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 4/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.6635 - acc: 0.7372 - val_loss: 0.6730 - val_acc: 0.6400\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 5/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.5706 - acc: 0.7962 - val_loss: 0.5423 - val_acc: 0.8238\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 6/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.5617 - acc: 0.7785 - val_loss: 0.5919 - val_acc: 0.7900\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 7/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.5146 - acc: 0.8233 - val_loss: 0.5699 - val_acc: 0.7862\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 8/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.5126 - acc: 0.8172 - val_loss: 0.5352 - val_acc: 0.8087\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 9/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4966 - acc: 0.8173 - val_loss: 0.5691 - val_acc: 0.7300\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 10/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4834 - acc: 0.8178 - val_loss: 0.5004 - val_acc: 0.8175\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 11/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4809 - acc: 0.8196 - val_loss: 0.4758 - val_acc: 0.8062\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 12/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4777 - acc: 0.8069 - val_loss: 0.4917 - val_acc: 0.8288\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 13/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4349 - acc: 0.8348 - val_loss: 0.6493 - val_acc: 0.6150\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 14/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4779 - acc: 0.8076 - val_loss: 0.5394 - val_acc: 0.7900\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 15/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4333 - acc: 0.8330 - val_loss: 0.5233 - val_acc: 0.7600\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 16/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4378 - acc: 0.8307 - val_loss: 0.4481 - val_acc: 0.8150\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 17/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4347 - acc: 0.8363 - val_loss: 0.4332 - val_acc: 0.8263\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 18/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4245 - acc: 0.8429 - val_loss: 0.4422 - val_acc: 0.8375\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 19/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4274 - acc: 0.8351 - val_loss: 0.4446 - val_acc: 0.8225\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 20/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.4255 - acc: 0.8438 - val_loss: 0.4570 - val_acc: 0.8338\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 21/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.4122 - acc: 0.8426 - val_loss: 0.4302 - val_acc: 0.8325\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 22/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3929 - acc: 0.8535 - val_loss: 0.4123 - val_acc: 0.8562\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 23/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.3907 - acc: 0.8529 - val_loss: 0.4247 - val_acc: 0.8250\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 24/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3785 - acc: 0.8554 - val_loss: 0.4306 - val_acc: 0.8400\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 25/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.3873 - acc: 0.8484 - val_loss: 0.4684 - val_acc: 0.8163\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 26/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3592 - acc: 0.8731 - val_loss: 0.4665 - val_acc: 0.8350\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 27/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3796 - acc: 0.8637 - val_loss: 0.4057 - val_acc: 0.8487\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 28/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3622 - acc: 0.8751 - val_loss: 0.3997 - val_acc: 0.8625\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 29/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3737 - acc: 0.8499 - val_loss: 0.3906 - val_acc: 0.8525\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 30/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.3591 - acc: 0.8629 - val_loss: 0.4492 - val_acc: 0.8375\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 31/50\n",
            "93/93 [==============================] - 2s 20ms/step - loss: 0.3431 - acc: 0.8688 - val_loss: 0.3939 - val_acc: 0.8475\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 32/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3659 - acc: 0.8697 - val_loss: 0.3925 - val_acc: 0.8587\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 33/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3447 - acc: 0.8725 - val_loss: 0.3893 - val_acc: 0.8525\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 34/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3505 - acc: 0.8729 - val_loss: 0.3806 - val_acc: 0.8562\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 35/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3344 - acc: 0.8795 - val_loss: 0.4129 - val_acc: 0.8300\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 36/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3222 - acc: 0.8745 - val_loss: 0.4496 - val_acc: 0.8138\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 37/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3414 - acc: 0.8727 - val_loss: 0.3721 - val_acc: 0.8650\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 38/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3247 - acc: 0.8815 - val_loss: 0.4274 - val_acc: 0.8313\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 39/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3298 - acc: 0.8589 - val_loss: 0.3801 - val_acc: 0.8575\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 40/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3108 - acc: 0.8833 - val_loss: 0.4549 - val_acc: 0.8350\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 41/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3303 - acc: 0.8814 - val_loss: 0.3747 - val_acc: 0.8650\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 42/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3200 - acc: 0.8777 - val_loss: 0.4517 - val_acc: 0.8288\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 43/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.3055 - acc: 0.8846 - val_loss: 0.4222 - val_acc: 0.8250\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 44/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.2760 - acc: 0.9104 - val_loss: 0.3830 - val_acc: 0.8600\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 45/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.2885 - acc: 0.8923 - val_loss: 0.3942 - val_acc: 0.8525\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 46/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.2868 - acc: 0.8986 - val_loss: 0.3991 - val_acc: 0.8400\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 47/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.2803 - acc: 0.8984 - val_loss: 0.3771 - val_acc: 0.8575\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 48/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.2796 - acc: 0.9040 - val_loss: 0.3834 - val_acc: 0.8587\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 49/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.2703 - acc: 0.9061 - val_loss: 0.4088 - val_acc: 0.8562\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n",
            "Epoch 50/50\n",
            "93/93 [==============================] - 2s 21ms/step - loss: 0.2670 - acc: 0.9073 - val_loss: 0.4580 - val_acc: 0.8363\n",
            "<__main__.GarbageCollectorCallback object at 0x7fd671f8f240>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QiPmyqK47aUq",
        "outputId": "b12c560d-f9e3-456b-decf-a6c5680b19ce"
      },
      "source": [
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=1,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[GarbageCollectorCallback()])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "93/93 [==============================] - 85s 914ms/step - loss: 0.5968 - acc: 0.7658 - val_loss: 0.5058 - val_acc: 0.7900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "nI8FjTjY4KIe",
        "outputId": "a62ad2a1-70bb-4a3f-db2b-c7d08704c0ac"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K17uwrHn_TY5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH89us9R_o_F",
        "outputId": "d2dd19c4-db2d-4686-9241-2da580546c09"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                       test_labels,\r\n",
        "                                                       batch_size=BATCH_SIZE,\r\n",
        "                                                       shuffle=False),\r\n",
        "                                     steps=len(test_images) // BATCH_SIZE\r\n",
        ")\r\n",
        "\r\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3748 - acc: 0.8438\n",
            "0.84375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2v_-h75Z3aZ"
      },
      "source": [
        "These plots are characteristic of **overfitting**. Training accuracy keeps increasing linearly while validation accuracy stalls around **82%**.\r\n",
        "\r\n",
        "### Fighting overfitting: 1. Data Augmentation:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ojvyPceIaunR",
        "outputId": "0ba144c9-332e-4bf4-804d-1eb6ecf08e25"
      },
      "source": [
        "from tensorflow.keras.preprocessing import image\r\n",
        "\r\n",
        "# train data augmentation \r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./65535,\r\n",
        "    rotation_range=40,\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        "    shear_range=20,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True,\r\n",
        "    fill_mode='nearest')\r\n",
        "\r\n",
        "valid_datagen = ImageDataGenerator(rescale=1./65535)\r\n",
        "test_datagen = ImageDataGenerator(rescale=1./65535) \r\n",
        "\r\n",
        "\"\"\"\r\n",
        "x = train_images[0].reshape((1,) + train_images[0].shape)\r\n",
        "\r\n",
        "i = 0\r\n",
        "for batch in train_datagen.flow(x, batch_size=1):\r\n",
        "  plt.figure(i)\r\n",
        "  imgplot = plt.imshow(image.array_to_img(batch[0]))\r\n",
        "  i += 1\r\n",
        "  if i % 4 == 0:\r\n",
        "    break\r\n",
        "\r\n",
        "plt.show()\r\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nx = train_images[0].reshape((1,) + train_images[0].shape)\\n\\ni = 0\\nfor batch in train_datagen.flow(x, batch_size=1):\\n  plt.figure(i)\\n  imgplot = plt.imshow(image.array_to_img(batch[0]))\\n  i += 1\\n  if i % 4 == 0:\\n    break\\n\\nplt.show()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ex5WyyOwir4",
        "outputId": "b67bf279-d807-4ec5-a8c4-178864966e96"
      },
      "source": [
        "model = build_model(\"binary_crossentropy\", \"acc\")\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_40 (Conv2D)           (None, 148, 148, 32)      320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_40 (MaxPooling (None, 74, 74, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_41 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_41 (MaxPooling (None, 36, 36, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_42 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_42 (MaxPooling (None, 17, 17, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_43 (Conv2D)           (None, 15, 15, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_43 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 3,452,545\n",
            "Trainable params: 3,452,545\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_LVsSUEj0Vx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "outputId": "22762288-6231-42bf-ae2d-76a86836a04a"
      },
      "source": [
        "history = model.fit(train_datagen.flow(train_images_split,\r\n",
        "                                       train_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    steps_per_epoch=len(train_images_split) // BATCH_SIZE, \r\n",
        "                    epochs=EPOCHS,\r\n",
        "                    validation_data=valid_datagen.flow(valid_images_split,\r\n",
        "                                       valid_labels_split,\r\n",
        "                                       batch_size=BATCH_SIZE,\r\n",
        "                                       shuffle=False),\r\n",
        "                    validation_steps=len(valid_labels_split) // BATCH_SIZE,\r\n",
        "                    callbacks=[GarbageCollectorCallback()])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-58915cb74fac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                                        \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                                        shuffle=False),\n\u001b[0;32m---> 11\u001b[0;31m                     validation_steps=len(valid_labels_split) // BATCH_SIZE)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:757 train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n\n    AttributeError: 'ListWrapper' object has no attribute 'minimize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "DNJBV5khoFEA",
        "outputId": "52ba77cc-c4fd-4cb2-bf69-8ba4fa9f6802"
      },
      "source": [
        "acc = history.history['acc']\r\n",
        "val_acc = history.history['val_acc']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'bo', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYDj_8GquRRh",
        "outputId": "42ce8ffd-7e3a-469d-9609-00a6f49bacd6"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                       test_labels,\r\n",
        "                                                       batch_size=BATCH_SIZE,\r\n",
        "                                                       shuffle=False),\r\n",
        "                                     steps=len(test_images) // BATCH_SIZE\r\n",
        ")\r\n",
        "\r\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 8ms/step - loss: 0.3545 - acc: 0.8500\n",
            "0.8500000238418579\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrLD4fBGtc6k"
      },
      "source": [
        "##K-fold cross validation.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuiUODCT97Bq",
        "outputId": "9244464c-0f58-42de-d668-c70e983704a9"
      },
      "source": [
        "print(train_images.shape)\r\n",
        "\r\n",
        "# train data augmentation for k-fold-cross-validation \r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./65535,\r\n",
        "    rotation_range=40,\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        "    shear_range=20,\r\n",
        "    zoom_range=0.2,\r\n",
        "    horizontal_flip=True,\r\n",
        "    fill_mode='nearest')\r\n",
        "\r\n",
        "valid_datagen = ImageDataGenerator(rescale=1./65535)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2676, 150, 150, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgdAZtZ1wMf3"
      },
      "source": [
        "def cross_validate(k, batch_size, num_epochs, dataset, targets, verbosity):\r\n",
        "  #10-Fold-Cross-Validation\r\n",
        "  num_val_samples = len(dataset) // k \r\n",
        "  validation_accuracies = []\r\n",
        "  validation_losses = []\r\n",
        "\r\n",
        "  for i in range(k):\r\n",
        "    # rigen augmented data \r\n",
        "    \r\n",
        "    print(\"processing fold #\", i)\r\n",
        "    validation_data = dataset[i * num_val_samples : (i + 1) * num_val_samples]\r\n",
        "    validation_labels = targets[i * num_val_samples : (i + 1) * num_val_samples]\r\n",
        "\r\n",
        "    partial_train_data = np.concatenate(\r\n",
        "        [dataset[:i * num_val_samples],\r\n",
        "        dataset[(i + 1) * num_val_samples:]], \r\n",
        "        axis=0)\r\n",
        "\r\n",
        "    partial_train_targets = np.concatenate(\r\n",
        "        [targets[:i * num_val_samples],\r\n",
        "        targets[(i + 1) * num_val_samples:]], \r\n",
        "        axis=0)\r\n",
        "\r\n",
        "    model = build_model(\"binary_crossentropy\", \"acc\")\r\n",
        "    \r\n",
        "    history = model.fit(train_datagen.flow(partial_train_data, \r\n",
        "                                          partial_train_targets,\r\n",
        "                                          batch_size=batch_size,\r\n",
        "                                          shuffle=False),\r\n",
        "                        epochs=num_epochs,\r\n",
        "                        steps_per_epoch=len(partial_train_data) // batch_size,\r\n",
        "                        verbose=verbosity,\r\n",
        "                        callbacks=[GarbageCollectorCallback()])\r\n",
        "    \r\n",
        "    val_loss, val_acc = model.evaluate(valid_datagen.flow(validation_data,\r\n",
        "                                                          validation_labels,\r\n",
        "                                                          batch_size=batch_size,\r\n",
        "                                                          shuffle=False),\r\n",
        "                                      steps=len(validation_data) // batch_size)\r\n",
        "    \r\n",
        "    validation_accuracies.append(val_acc)\r\n",
        "    validation_losses.append(val_loss)\r\n",
        "\r\n",
        "  return validation_accuracies, validation_losses \r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdmZ-0dKuKlG"
      },
      "source": [
        "acc, loss = cross_validate(k=10, batch_size=20, num_epochs=100, dataset=train_images, targets=train_labels, verbosity=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3hbM3c6RxTq"
      },
      "source": [
        "print(len(acc))\r\n",
        "print(len(loss))\r\n",
        "print()\r\n",
        "print(np.mean(acc))\r\n",
        "print(np.mean(loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqQKeyLVTVi7"
      },
      "source": [
        "##Hyperparameters Tuning:\r\n",
        "\r\n",
        "*   add Dropout or L2 Regularization\r\n",
        "*   varying of convolutional layers: [3, 5, 7]\r\n",
        "*   varying # of units per layer:\r\n",
        "\r\n",
        "| Layer  | Unit per Layer  |  \r\n",
        "|---|---|\r\n",
        "| 1  | [32,32,64,128]  |\r\n",
        "| 2  | [32,64,128,128]  |\r\n",
        "| 3  | [32,64,128,256]  |\r\n",
        "| 4  | [64,64,128,256]  |\r\n",
        "\r\n",
        "*   change Optimizer (try Adam)\r\n",
        "*   varying batch size: [20, 32, 64, 128]\r\n",
        "*   varying learning rate \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQgC-nrCTcn7"
      },
      "source": [
        "from keras import optimizers\r\n",
        "\r\n",
        "#Parameters Grid \r\n",
        "dropout_regularization = True                                               # grafico comparativo: sembra leggermente meglio con Dropout\r\n",
        "#batch_sizes = [20, 32, 64, 128]                                             # 4 \r\n",
        "batch_sizes = [20, 32]\r\n",
        "layers_number = 4                                                           # 1\r\n",
        "units_per_layer_dict = [[32,64,128,128], [32,64,128,256]]                   # 2\r\n",
        "learning_rates = [1e-2, 1e-3, 1e-4]                                         # 3\r\n",
        "opts = [optimizers.RMSprop(lr=1e-4), optimizers.Adam(learning_rate=0.01)]   # 2\r\n",
        "num_epochs = 100\r\n",
        "num_folds = 5\r\n",
        "\r\n",
        "def build_custom_model(layers_number, units_per_layer, batch_size, dropout, optimizer):\r\n",
        "  model = models.Sequential()\r\n",
        "\r\n",
        "  for i in range(layers_number):\r\n",
        "    if i == 0:  #first layer\r\n",
        "      model.add(layers.Conv2D(units_per_layer[i], (3, 3), activation='relu', input_shape=(150, 150, 1)))\r\n",
        "      model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "    else:\r\n",
        "      model.add(layers.Conv2D(units_per_layer[i], (3, 3), activation='relu'))\r\n",
        "      model.add(layers.MaxPooling2D((2, 2)))\r\n",
        "\r\n",
        "  model.add(layers.Flatten())\r\n",
        "  model.add(layers.Dense(512, activation='relu'))\r\n",
        "  \r\n",
        "  if dropout:\r\n",
        "    model.add(layers.Dropout(0.5))\r\n",
        "\r\n",
        "  model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "  #model.summary()\r\n",
        "  model.compile(loss=\"binary_crossentropy\",\r\n",
        "              optimizer=optimizer,\r\n",
        "              metrics=[\"acc\"]) \r\n",
        "  \r\n",
        "  return model \r\n",
        "\r\n",
        "def CNN_tuning(num_folds, batch_sizes, num_epochs, layers_number, units_per_layer_dict, learning_rates, dropout_reg, dataset, targets):\r\n",
        "  lr = learning_rates[2]  \r\n",
        "  opts = [optimizers.RMSprop(lr=lr), optimizers.Adam(learning_rate=lr)]\r\n",
        "\r\n",
        "  with open(file_path, 'w') as f:\r\n",
        "    header = \"batch_size,num_epochs,units_per_layer,optimizer,learning_rate,mean_val_acc,mean_val_loss,num_folds\\n\"\r\n",
        "    f.write(header)\r\n",
        "\r\n",
        "  for batch_size in batch_sizes:                # 4\r\n",
        "    for opt in opts:                            # 2\r\n",
        "      for values_set in units_per_layer_dict:   # 2\r\n",
        "        #build CNN model \r\n",
        "        model = build_custom_model(layers_number, values_set, batch_size, dropout_reg, opt)\r\n",
        "\r\n",
        "        if \"RMSprop\" in str(opt):\r\n",
        "          str_opt = \"RMSprop\"  \r\n",
        "        else:\r\n",
        "          str_opt = \"Adam\"\r\n",
        "\r\n",
        "        #print info \r\n",
        "        print(\"-----------------------------------------------------\")\r\n",
        "        print(\"batch_size: \\t\", batch_size)\r\n",
        "        print(\"num_epochs: \\t\", num_epochs)\r\n",
        "        print(\"units_per_layer:\", str(values_set).replace(\",\", \" \"))\r\n",
        "        print(\"optimizer: \\t\", str_opt)\r\n",
        "        print(\"learning_rate: \\t\", str(lr))\r\n",
        "        print(\"num_folds CV: \\t\", num_folds)\r\n",
        "        print(\"-----------------------------------------------------\")\r\n",
        "\r\n",
        "        #cross validate CNN model\r\n",
        "        val_acc, val_loss = cross_validate(num_folds, batch_size, num_epochs, dataset, targets, 1)\r\n",
        "\r\n",
        "        #save results on csv file \r\n",
        "        with open(file_path, 'a') as f:\r\n",
        "          row = str(batch_size) + \",\" \\\r\n",
        "              + str(num_epochs) + \",\" \\\r\n",
        "              + str(values_set).replace(\",\", \" \") + \",\" \\\r\n",
        "              + str_opt + \",\" \\\r\n",
        "              + str(lr) + \",\" \\\r\n",
        "              + \"%0.4f (+/- %0.4f)\" % (np.mean(val_acc), np.std(val_acc) * 2) + \",\" \\\r\n",
        "              + \"%0.4f (+/- %0.4f)\" % (np.mean(val_loss), np.std(val_loss) * 2) + \",\" \\\r\n",
        "              + str(num_folds) + \"\\n\"\r\n",
        "          f.write(row)\r\n",
        "          \r\n",
        "          del model \r\n",
        "          tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0fLlSfbPOWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3846b17-3b2e-44a1-a816-af592cc329ba"
      },
      "source": [
        "file_path = \"/content/gdrive/My Drive/Colab_Notebooks/CIDL/DL Project/tuning_results/results.csv\"\r\n",
        "\r\n",
        "CNN_tuning(num_folds, batch_sizes, num_epochs, layers_number, units_per_layer_dict, learning_rates, dropout_regularization, train_images, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------------------------\n",
            "batch_size: \t 20\n",
            "num_epochs: \t 100\n",
            "units_per_layer: [32  64  128  128]\n",
            "optimizer: \t RMSprop\n",
            "learning_rate: \t 0.0001\n",
            "num_folds CV: \t 5\n",
            "-----------------------------------------------------\n",
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 1.4135 - acc: 0.5450\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.9218 - acc: 0.5355\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.7536 - acc: 0.5882\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6886 - acc: 0.6575\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6463 - acc: 0.7126\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6395 - acc: 0.7110\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5837 - acc: 0.7378\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5857 - acc: 0.7282\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5883 - acc: 0.7367\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5837 - acc: 0.7524\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5839 - acc: 0.7287\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5854 - acc: 0.7282\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5780 - acc: 0.7336\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5371 - acc: 0.7533\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5714 - acc: 0.7536\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5527 - acc: 0.7455\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5225 - acc: 0.7747\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5435 - acc: 0.7569\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5169 - acc: 0.7818\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5354 - acc: 0.7589\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5578 - acc: 0.7534\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5333 - acc: 0.7706\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5664 - acc: 0.7656\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5164 - acc: 0.7783\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5110 - acc: 0.7903\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5209 - acc: 0.7688\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5098 - acc: 0.7826\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5225 - acc: 0.7741\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4917 - acc: 0.8048\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4732 - acc: 0.7989\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4733 - acc: 0.7916\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4803 - acc: 0.8093\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5360 - acc: 0.7699\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4867 - acc: 0.7971\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4622 - acc: 0.8080\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4646 - acc: 0.7958\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4592 - acc: 0.8152\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4765 - acc: 0.7883\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4353 - acc: 0.8156\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4362 - acc: 0.8231\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4558 - acc: 0.8248\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4654 - acc: 0.8161\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4600 - acc: 0.8092\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4720 - acc: 0.8153\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4218 - acc: 0.8394\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4725 - acc: 0.8090\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4758 - acc: 0.8043\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4256 - acc: 0.8238\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4319 - acc: 0.8249\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4166 - acc: 0.8189\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4783 - acc: 0.8033\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4442 - acc: 0.8135\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4465 - acc: 0.8335\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4285 - acc: 0.8299\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4373 - acc: 0.8302\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4507 - acc: 0.8123\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4237 - acc: 0.8362\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4113 - acc: 0.8538\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4255 - acc: 0.8206\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4295 - acc: 0.8281\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4084 - acc: 0.8353\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3910 - acc: 0.8459\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4295 - acc: 0.8207\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4139 - acc: 0.8369\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3972 - acc: 0.8441\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4164 - acc: 0.8389\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3910 - acc: 0.8369\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4088 - acc: 0.8336\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4047 - acc: 0.8434\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4024 - acc: 0.8379\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4315 - acc: 0.8284\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3852 - acc: 0.8480\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4206 - acc: 0.8358\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3814 - acc: 0.8438\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3984 - acc: 0.8446\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4116 - acc: 0.8335\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3948 - acc: 0.8376\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4033 - acc: 0.8395\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3939 - acc: 0.8442\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3956 - acc: 0.8371\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3660 - acc: 0.8573\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3932 - acc: 0.8463\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3735 - acc: 0.8485\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3883 - acc: 0.8457\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3748 - acc: 0.8645\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3994 - acc: 0.8417\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3722 - acc: 0.8511\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3618 - acc: 0.8487\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3824 - acc: 0.8454\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3502 - acc: 0.8703\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3752 - acc: 0.8547\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3706 - acc: 0.8422\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3943 - acc: 0.8417\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3770 - acc: 0.8476\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3555 - acc: 0.8615\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3715 - acc: 0.8500\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3708 - acc: 0.8616\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3593 - acc: 0.8612\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3675 - acc: 0.8508\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3750 - acc: 0.8544\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.3211 - acc: 0.8731\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 40ms/step - loss: 1.4207 - acc: 0.5390\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.9321 - acc: 0.5477\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.7533 - acc: 0.5791\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6961 - acc: 0.6347\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6421 - acc: 0.6921\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.6229 - acc: 0.7218\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.6017 - acc: 0.7267\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5641 - acc: 0.7562\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5823 - acc: 0.7369\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5551 - acc: 0.7523\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5430 - acc: 0.7661\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5376 - acc: 0.7722\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5187 - acc: 0.7829\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5594 - acc: 0.7406\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5731 - acc: 0.7399\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5203 - acc: 0.7616\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5001 - acc: 0.7822\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5071 - acc: 0.7722\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5171 - acc: 0.7660\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5226 - acc: 0.7864\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5216 - acc: 0.7854\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5094 - acc: 0.7715\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5197 - acc: 0.7741\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5061 - acc: 0.7695\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5327 - acc: 0.7717\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4923 - acc: 0.7810\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.5116 - acc: 0.7825\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4702 - acc: 0.7906\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4537 - acc: 0.8019\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4892 - acc: 0.7886\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4789 - acc: 0.7871\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4780 - acc: 0.7821\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4775 - acc: 0.8049\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4656 - acc: 0.7974\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4485 - acc: 0.8031\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4493 - acc: 0.8146\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4909 - acc: 0.7767\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4338 - acc: 0.8286\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4668 - acc: 0.8084\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4536 - acc: 0.8174\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4614 - acc: 0.8006\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4724 - acc: 0.8125\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4106 - acc: 0.8306\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4346 - acc: 0.8278\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4259 - acc: 0.8222\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4485 - acc: 0.7962\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4248 - acc: 0.8236\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4236 - acc: 0.8148\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4231 - acc: 0.8281\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4004 - acc: 0.8434\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4221 - acc: 0.8355\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4215 - acc: 0.8176\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4246 - acc: 0.8264\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4414 - acc: 0.8190\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4281 - acc: 0.8145\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3979 - acc: 0.8315\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4199 - acc: 0.8371\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3992 - acc: 0.8473\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3976 - acc: 0.8410\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4220 - acc: 0.8213\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3950 - acc: 0.8347\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3987 - acc: 0.8401\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3918 - acc: 0.8435\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3896 - acc: 0.8490\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4100 - acc: 0.8331\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.4295 - acc: 0.8201\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4057 - acc: 0.8310\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3911 - acc: 0.8441\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3892 - acc: 0.8398\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4038 - acc: 0.8398\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4009 - acc: 0.8401\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3775 - acc: 0.8511\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4039 - acc: 0.8353\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3872 - acc: 0.8286\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3754 - acc: 0.8507\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3799 - acc: 0.8512\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3815 - acc: 0.8496\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3591 - acc: 0.8526\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3939 - acc: 0.8384\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3787 - acc: 0.8496\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3741 - acc: 0.8430\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3698 - acc: 0.8478\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3423 - acc: 0.8667\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4069 - acc: 0.8340\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3473 - acc: 0.8648\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3251 - acc: 0.8739\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3729 - acc: 0.8623\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3660 - acc: 0.8537\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3401 - acc: 0.8671\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3717 - acc: 0.8451\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 39ms/step - loss: 0.3497 - acc: 0.8521\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3572 - acc: 0.8558\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3380 - acc: 0.8722\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3523 - acc: 0.8597\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3784 - acc: 0.8455\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3659 - acc: 0.8466\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3503 - acc: 0.8575\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3707 - acc: 0.8502\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3417 - acc: 0.8623\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3450 - acc: 0.8658\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.3409 - acc: 0.8635\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 1.4084 - acc: 0.5186\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.9199 - acc: 0.5264\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.7440 - acc: 0.5703\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6944 - acc: 0.6567\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6540 - acc: 0.6793\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6254 - acc: 0.7305\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5991 - acc: 0.7332\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.6212 - acc: 0.7167\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.5723 - acc: 0.7575\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5796 - acc: 0.7297\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5600 - acc: 0.7567\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5542 - acc: 0.7438\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5763 - acc: 0.7369\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5316 - acc: 0.7606\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5549 - acc: 0.7480\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5390 - acc: 0.7630\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5198 - acc: 0.7695\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5143 - acc: 0.7695\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5510 - acc: 0.7576\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5133 - acc: 0.7766\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5294 - acc: 0.7771\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5176 - acc: 0.7829\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4839 - acc: 0.8021\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4837 - acc: 0.7859\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4910 - acc: 0.7845\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4908 - acc: 0.7932\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5047 - acc: 0.7657\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4614 - acc: 0.8211\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4637 - acc: 0.8053\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4801 - acc: 0.8001\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4623 - acc: 0.8063\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4716 - acc: 0.7933\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4461 - acc: 0.8217\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4560 - acc: 0.8129\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4630 - acc: 0.8160\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4637 - acc: 0.8082\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4612 - acc: 0.8138\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4297 - acc: 0.8247\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4718 - acc: 0.8164\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4726 - acc: 0.7967\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4541 - acc: 0.7976\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4241 - acc: 0.8295\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4244 - acc: 0.8327\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4440 - acc: 0.8291\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4222 - acc: 0.8277\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4277 - acc: 0.8170\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4157 - acc: 0.8340\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4496 - acc: 0.8103\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4087 - acc: 0.8328\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4271 - acc: 0.8112\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4268 - acc: 0.8344\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4479 - acc: 0.8192\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4128 - acc: 0.8237\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4261 - acc: 0.8319\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4182 - acc: 0.8409\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4297 - acc: 0.8188\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3961 - acc: 0.8358\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4145 - acc: 0.8430\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4200 - acc: 0.8306\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4082 - acc: 0.8466\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4404 - acc: 0.8237\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4161 - acc: 0.8307\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4285 - acc: 0.8405\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4058 - acc: 0.8346\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3970 - acc: 0.8461\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3934 - acc: 0.8396\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4343 - acc: 0.8126\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3715 - acc: 0.8370\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4021 - acc: 0.8432\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4191 - acc: 0.8285\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4138 - acc: 0.8285\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4216 - acc: 0.8253\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4045 - acc: 0.8428\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4134 - acc: 0.8362\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4167 - acc: 0.8456\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4074 - acc: 0.8353\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4167 - acc: 0.8325\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4061 - acc: 0.8390\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4074 - acc: 0.8351\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4101 - acc: 0.8466\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4192 - acc: 0.8320\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3952 - acc: 0.8513\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4116 - acc: 0.8423\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3965 - acc: 0.8453\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3773 - acc: 0.8589\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4274 - acc: 0.8265\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3823 - acc: 0.8457\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4185 - acc: 0.8310\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3965 - acc: 0.8262\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3884 - acc: 0.8500\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3641 - acc: 0.8514\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3911 - acc: 0.8365\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3911 - acc: 0.8485\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3733 - acc: 0.8632\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3849 - acc: 0.8501\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3707 - acc: 0.8645\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3868 - acc: 0.8467\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3774 - acc: 0.8600\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3954 - acc: 0.8487\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3725 - acc: 0.8586\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3499 - acc: 0.8577\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 1.4048 - acc: 0.5617\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.9176 - acc: 0.5511\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.7496 - acc: 0.5416\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.7094 - acc: 0.5670\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.6856 - acc: 0.6339\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6416 - acc: 0.6741\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.6053 - acc: 0.7131\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.6088 - acc: 0.7049\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5839 - acc: 0.7321\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5871 - acc: 0.7184\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5669 - acc: 0.7394\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5751 - acc: 0.7250\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5641 - acc: 0.7222\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5376 - acc: 0.7642\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5776 - acc: 0.7328\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5609 - acc: 0.7484\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5483 - acc: 0.7432\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5650 - acc: 0.7326\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5543 - acc: 0.7381\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5604 - acc: 0.7305\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5375 - acc: 0.7552\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5384 - acc: 0.7367\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5345 - acc: 0.7504\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5187 - acc: 0.7691\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5309 - acc: 0.7541\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5446 - acc: 0.7458\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5480 - acc: 0.7438\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5376 - acc: 0.7659\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5273 - acc: 0.7616\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5513 - acc: 0.7629\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5112 - acc: 0.7766\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5079 - acc: 0.7758\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5014 - acc: 0.7861\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5217 - acc: 0.7692\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5089 - acc: 0.7792\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5241 - acc: 0.7663\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4940 - acc: 0.7878\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5316 - acc: 0.7574\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4800 - acc: 0.7977\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5093 - acc: 0.7892\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4947 - acc: 0.7987\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4748 - acc: 0.7970\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4993 - acc: 0.7771\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4912 - acc: 0.7965\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5000 - acc: 0.7791\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4619 - acc: 0.8186\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4945 - acc: 0.7873\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4717 - acc: 0.8109\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5079 - acc: 0.7803\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4716 - acc: 0.8110\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4710 - acc: 0.7946\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4580 - acc: 0.8202\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4854 - acc: 0.7957\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4864 - acc: 0.8002\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4686 - acc: 0.8142\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4785 - acc: 0.7989\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4938 - acc: 0.7724\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4426 - acc: 0.8176\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4775 - acc: 0.7850\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4419 - acc: 0.8050\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4409 - acc: 0.8364\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4223 - acc: 0.8256\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4712 - acc: 0.8090\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4530 - acc: 0.7973\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4450 - acc: 0.8224\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4701 - acc: 0.8151\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4384 - acc: 0.8238\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4268 - acc: 0.8164\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4481 - acc: 0.8051\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4431 - acc: 0.8083\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4546 - acc: 0.8258\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4557 - acc: 0.8093\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4487 - acc: 0.8174\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4206 - acc: 0.8326\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4390 - acc: 0.8071\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4207 - acc: 0.8171\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4276 - acc: 0.8243\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4542 - acc: 0.8164\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4173 - acc: 0.8119\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4435 - acc: 0.8310\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4288 - acc: 0.8241\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4157 - acc: 0.8286\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4350 - acc: 0.8178\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4191 - acc: 0.8271\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4347 - acc: 0.8216\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4092 - acc: 0.8334\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4387 - acc: 0.8121\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3918 - acc: 0.8537\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3972 - acc: 0.8369\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4026 - acc: 0.8266\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4136 - acc: 0.8347\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4146 - acc: 0.8366\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4148 - acc: 0.8388\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4026 - acc: 0.8413\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4072 - acc: 0.8362\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4059 - acc: 0.8325\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4001 - acc: 0.8359\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4072 - acc: 0.8305\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3873 - acc: 0.8460\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4016 - acc: 0.8333\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2471 - acc: 0.9192\n",
            "processing fold # 4\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 1.4233 - acc: 0.5137\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.9311 - acc: 0.5649\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.7514 - acc: 0.5889\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6934 - acc: 0.6399\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6433 - acc: 0.7149\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.6055 - acc: 0.7450\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5825 - acc: 0.7372\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6018 - acc: 0.7147\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5808 - acc: 0.7484\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5976 - acc: 0.7270\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5579 - acc: 0.7400\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5552 - acc: 0.7611\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5689 - acc: 0.7498\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5580 - acc: 0.7494\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5402 - acc: 0.7707\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5386 - acc: 0.7772\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5758 - acc: 0.7534\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5383 - acc: 0.7586\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5395 - acc: 0.7669\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5403 - acc: 0.7574\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5433 - acc: 0.7578\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5191 - acc: 0.7716\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5120 - acc: 0.7837\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4953 - acc: 0.7989\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4736 - acc: 0.8122\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5082 - acc: 0.7799\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5013 - acc: 0.7806\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5191 - acc: 0.7785\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5039 - acc: 0.7775\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4700 - acc: 0.8006\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4894 - acc: 0.7923\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4806 - acc: 0.7906\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4584 - acc: 0.7996\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4780 - acc: 0.7889\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4420 - acc: 0.8218\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4571 - acc: 0.8138\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4584 - acc: 0.8273\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4657 - acc: 0.7996\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4694 - acc: 0.8078\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4290 - acc: 0.8263\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4686 - acc: 0.8015\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4214 - acc: 0.8302\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4251 - acc: 0.8288\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4141 - acc: 0.8330\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4340 - acc: 0.8284\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4449 - acc: 0.8261\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4477 - acc: 0.8225\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4442 - acc: 0.8184\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4244 - acc: 0.8325\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4336 - acc: 0.8254\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4211 - acc: 0.8298\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4329 - acc: 0.8173\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4399 - acc: 0.8248\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4436 - acc: 0.8195\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4037 - acc: 0.8430\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3930 - acc: 0.8479\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3821 - acc: 0.8529\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3957 - acc: 0.8316\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4398 - acc: 0.8146\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3904 - acc: 0.8370\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3925 - acc: 0.8384\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4080 - acc: 0.8305\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4089 - acc: 0.8278\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4228 - acc: 0.8277\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4094 - acc: 0.8327\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4055 - acc: 0.8286\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4247 - acc: 0.8326\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4020 - acc: 0.8371\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4148 - acc: 0.8306\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4111 - acc: 0.8299\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3719 - acc: 0.8460\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3837 - acc: 0.8441\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3888 - acc: 0.8296\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3728 - acc: 0.8530\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4091 - acc: 0.8384\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.4063 - acc: 0.8351\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3880 - acc: 0.8413\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3838 - acc: 0.8374\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3903 - acc: 0.8556\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3972 - acc: 0.8272\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3717 - acc: 0.8595\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3771 - acc: 0.8399\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3794 - acc: 0.8484\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3702 - acc: 0.8427\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4017 - acc: 0.8325\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3763 - acc: 0.8529\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3658 - acc: 0.8597\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3699 - acc: 0.8498\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3693 - acc: 0.8663\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3826 - acc: 0.8347\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3731 - acc: 0.8546\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3697 - acc: 0.8553\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3368 - acc: 0.8679\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3462 - acc: 0.8615\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3663 - acc: 0.8527\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 40ms/step - loss: 0.3638 - acc: 0.8469\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3564 - acc: 0.8623\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3473 - acc: 0.8556\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3707 - acc: 0.8463\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3545 - acc: 0.8553\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.3325 - acc: 0.8846\n",
            "-----------------------------------------------------\n",
            "batch_size: \t 20\n",
            "num_epochs: \t 100\n",
            "units_per_layer: [32  64  128  256]\n",
            "optimizer: \t RMSprop\n",
            "learning_rate: \t 0.0001\n",
            "num_folds CV: \t 5\n",
            "-----------------------------------------------------\n",
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 1.4192 - acc: 0.5314\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.9346 - acc: 0.5515\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.7540 - acc: 0.5977\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.6911 - acc: 0.6625\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.6526 - acc: 0.7032\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5997 - acc: 0.7402\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5920 - acc: 0.7232\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5935 - acc: 0.7328\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5966 - acc: 0.7240\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5925 - acc: 0.7193\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5748 - acc: 0.7420\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5630 - acc: 0.7572\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5627 - acc: 0.7538\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5608 - acc: 0.7571\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5556 - acc: 0.7365\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5669 - acc: 0.7416\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5263 - acc: 0.7710\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5380 - acc: 0.7679\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5404 - acc: 0.7646\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5517 - acc: 0.7690\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5041 - acc: 0.7801\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.5557 - acc: 0.7442\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.5230 - acc: 0.7647\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5207 - acc: 0.7727\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4847 - acc: 0.7935\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.5087 - acc: 0.7810\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4920 - acc: 0.7842\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4753 - acc: 0.7983\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4943 - acc: 0.8014\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4856 - acc: 0.7950\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4598 - acc: 0.8086\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4697 - acc: 0.8070\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4663 - acc: 0.7948\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4548 - acc: 0.8068\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4556 - acc: 0.8070\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4675 - acc: 0.8005\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4505 - acc: 0.8192\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4518 - acc: 0.8185\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4442 - acc: 0.8144\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4508 - acc: 0.8094\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4455 - acc: 0.8099\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4646 - acc: 0.8017\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4316 - acc: 0.8325\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4498 - acc: 0.8164\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4633 - acc: 0.8041\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4153 - acc: 0.8317\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4352 - acc: 0.8248\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4326 - acc: 0.8234\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4176 - acc: 0.8375\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4283 - acc: 0.8280\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4191 - acc: 0.8308\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4453 - acc: 0.8093\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4373 - acc: 0.8223\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4061 - acc: 0.8431\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4000 - acc: 0.8402\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4179 - acc: 0.8174\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4282 - acc: 0.8405\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3982 - acc: 0.8383\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4217 - acc: 0.8289\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4099 - acc: 0.8288\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4059 - acc: 0.8396\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3949 - acc: 0.8514\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4064 - acc: 0.8308\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4281 - acc: 0.8211\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3875 - acc: 0.8601\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.4031 - acc: 0.8428\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3830 - acc: 0.8394\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3984 - acc: 0.8427\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3705 - acc: 0.8637\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4035 - acc: 0.8441\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3794 - acc: 0.8443\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4145 - acc: 0.8378\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3849 - acc: 0.8533\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4112 - acc: 0.8353\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3947 - acc: 0.8341\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.4118 - acc: 0.8342\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3777 - acc: 0.8485\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3722 - acc: 0.8491\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3938 - acc: 0.8386\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3628 - acc: 0.8469\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3645 - acc: 0.8526\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3999 - acc: 0.8190\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3795 - acc: 0.8443\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3791 - acc: 0.8466\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3713 - acc: 0.8500\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3809 - acc: 0.8401\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3406 - acc: 0.8585\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3668 - acc: 0.8478\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3568 - acc: 0.8622\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3650 - acc: 0.8491\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3957 - acc: 0.8403\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 0.3702 - acc: 0.8508\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3731 - acc: 0.8463\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.4017 - acc: 0.8438\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3552 - acc: 0.8581\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3641 - acc: 0.8634\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 4s 41ms/step - loss: 0.3914 - acc: 0.8408\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3692 - acc: 0.8512\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 4s 42ms/step - loss: 0.3700 - acc: 0.8457\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3591 - acc: 0.8591\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.3085 - acc: 0.8769\n",
            "processing fold # 1\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 5s 42ms/step - loss: 1.4169 - acc: 0.5235\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.9200 - acc: 0.5456\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.7408 - acc: 0.5569\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.6934 - acc: 0.6275\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.6729 - acc: 0.6556\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.6071 - acc: 0.7095\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5944 - acc: 0.7180\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5844 - acc: 0.7526\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5776 - acc: 0.7314\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5679 - acc: 0.7385\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5468 - acc: 0.7376\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5567 - acc: 0.7444\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5530 - acc: 0.7473\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5427 - acc: 0.7459\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5678 - acc: 0.7402\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5601 - acc: 0.7290\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5366 - acc: 0.7677\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5322 - acc: 0.7556\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5361 - acc: 0.7562\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5364 - acc: 0.7630\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5362 - acc: 0.7579\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5326 - acc: 0.7480\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5208 - acc: 0.7628\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5292 - acc: 0.7574\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5286 - acc: 0.7653\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5087 - acc: 0.7775\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5196 - acc: 0.7787\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4846 - acc: 0.7766\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5402 - acc: 0.7626\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5338 - acc: 0.7603\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5040 - acc: 0.7691\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5038 - acc: 0.7905\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4880 - acc: 0.7831\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4857 - acc: 0.7991\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4896 - acc: 0.7942\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5067 - acc: 0.7795\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4886 - acc: 0.7769\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4864 - acc: 0.7868\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4861 - acc: 0.7919\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4709 - acc: 0.7969\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4697 - acc: 0.8025\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4633 - acc: 0.7852\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4673 - acc: 0.7921\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4707 - acc: 0.7916\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4689 - acc: 0.7984\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4770 - acc: 0.7923\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4534 - acc: 0.8139\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4961 - acc: 0.7718\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4613 - acc: 0.7939\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4602 - acc: 0.8077\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4415 - acc: 0.8358\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4432 - acc: 0.8090\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4282 - acc: 0.8279\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4480 - acc: 0.7988\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4562 - acc: 0.8015\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4383 - acc: 0.8218\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4284 - acc: 0.8312\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4125 - acc: 0.8453\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4465 - acc: 0.8180\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4431 - acc: 0.8236\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4674 - acc: 0.8183\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4192 - acc: 0.8225\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4350 - acc: 0.8179\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4292 - acc: 0.8240\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4280 - acc: 0.8311\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4354 - acc: 0.8174\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4248 - acc: 0.8239\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4289 - acc: 0.8342\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4161 - acc: 0.8336\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3951 - acc: 0.8322\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4071 - acc: 0.8329\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4045 - acc: 0.8371\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4023 - acc: 0.8298\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4120 - acc: 0.8371\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4171 - acc: 0.8285\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3658 - acc: 0.8548\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4016 - acc: 0.8293\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4202 - acc: 0.8278\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4052 - acc: 0.8400\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3994 - acc: 0.8464\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3876 - acc: 0.8458\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4013 - acc: 0.8281\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3693 - acc: 0.8594\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3947 - acc: 0.8344\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3918 - acc: 0.8372\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.3892 - acc: 0.8453\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 5s 49ms/step - loss: 0.3695 - acc: 0.8580\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.3788 - acc: 0.8465\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.3836 - acc: 0.8490\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3688 - acc: 0.8512\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3901 - acc: 0.8451\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3803 - acc: 0.8401\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4199 - acc: 0.8385\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3971 - acc: 0.8422\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3610 - acc: 0.8642\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3759 - acc: 0.8441\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3853 - acc: 0.8552\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3674 - acc: 0.8477\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3736 - acc: 0.8477\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3563 - acc: 0.8580\n",
            "26/26 [==============================] - 0s 9ms/step - loss: 0.3055 - acc: 0.8673\n",
            "processing fold # 2\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 6s 45ms/step - loss: 1.4215 - acc: 0.5269\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.9316 - acc: 0.5311\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.7461 - acc: 0.5766\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.6977 - acc: 0.6179\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.6580 - acc: 0.6726\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.6274 - acc: 0.7023\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6053 - acc: 0.7147\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5852 - acc: 0.7396\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5920 - acc: 0.7281\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5715 - acc: 0.7441\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5421 - acc: 0.7592\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5634 - acc: 0.7426\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5640 - acc: 0.7352\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5626 - acc: 0.7549\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5537 - acc: 0.7529\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5458 - acc: 0.7588\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5404 - acc: 0.7489\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5325 - acc: 0.7648\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5137 - acc: 0.7550\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5341 - acc: 0.7579\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5379 - acc: 0.7566\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5118 - acc: 0.7808\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5025 - acc: 0.7729\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5460 - acc: 0.7578\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5008 - acc: 0.7678\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5377 - acc: 0.7725\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5065 - acc: 0.7722\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5070 - acc: 0.7623\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4851 - acc: 0.7973\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4923 - acc: 0.7867\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5062 - acc: 0.7812\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4644 - acc: 0.7967\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4942 - acc: 0.7771\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4895 - acc: 0.8067\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4738 - acc: 0.8020\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5020 - acc: 0.7788\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4629 - acc: 0.8042\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4878 - acc: 0.7797\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4624 - acc: 0.8055\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4630 - acc: 0.8014\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4660 - acc: 0.8123\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4956 - acc: 0.7815\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4238 - acc: 0.8222\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4323 - acc: 0.8173\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4077 - acc: 0.8317\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4653 - acc: 0.8011\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4296 - acc: 0.8256\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4385 - acc: 0.8269\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4247 - acc: 0.8265\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4593 - acc: 0.8200\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4354 - acc: 0.8187\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4193 - acc: 0.8372\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4153 - acc: 0.8278\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4240 - acc: 0.8318\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4224 - acc: 0.8321\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4287 - acc: 0.8254\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4590 - acc: 0.8153\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4211 - acc: 0.8233\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4199 - acc: 0.8494\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4137 - acc: 0.8333\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3983 - acc: 0.8560\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4059 - acc: 0.8382\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4109 - acc: 0.8479\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4124 - acc: 0.8247\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3950 - acc: 0.8450\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3866 - acc: 0.8510\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4124 - acc: 0.8298\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4133 - acc: 0.8274\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4102 - acc: 0.8403\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3989 - acc: 0.8546\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4072 - acc: 0.8404\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4002 - acc: 0.8469\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3931 - acc: 0.8487\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3835 - acc: 0.8472\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3826 - acc: 0.8455\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3978 - acc: 0.8439\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3779 - acc: 0.8456\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3964 - acc: 0.8379\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3991 - acc: 0.8425\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4068 - acc: 0.8349\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3779 - acc: 0.8545\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3704 - acc: 0.8622\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3758 - acc: 0.8490\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3817 - acc: 0.8501\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3696 - acc: 0.8602\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3644 - acc: 0.8533\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3524 - acc: 0.8618\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.3623 - acc: 0.8680\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3694 - acc: 0.8547\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3951 - acc: 0.8425\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3454 - acc: 0.8628\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3317 - acc: 0.8766\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3683 - acc: 0.8532\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3946 - acc: 0.8348\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3737 - acc: 0.8496\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3507 - acc: 0.8571\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3839 - acc: 0.8520\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3658 - acc: 0.8555\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3685 - acc: 0.8487\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3790 - acc: 0.8506\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.3642 - acc: 0.8481\n",
            "processing fold # 3\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 6s 46ms/step - loss: 1.4084 - acc: 0.5348\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.9132 - acc: 0.5466\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.7422 - acc: 0.5863\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.6781 - acc: 0.6472\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6328 - acc: 0.6969\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6034 - acc: 0.7167\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5949 - acc: 0.7245\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5873 - acc: 0.7160\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5835 - acc: 0.7370\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5606 - acc: 0.7377\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5813 - acc: 0.7342\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.5536 - acc: 0.7489\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5785 - acc: 0.7596\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5446 - acc: 0.7672\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5421 - acc: 0.7597\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5454 - acc: 0.7457\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5611 - acc: 0.7578\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5267 - acc: 0.7816\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.5329 - acc: 0.7598\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5340 - acc: 0.7699\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5202 - acc: 0.7659\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4843 - acc: 0.8003\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4865 - acc: 0.8080\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4747 - acc: 0.7999\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5270 - acc: 0.7714\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4916 - acc: 0.8060\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4714 - acc: 0.8084\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4819 - acc: 0.7958\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4558 - acc: 0.7990\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4697 - acc: 0.8126\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4941 - acc: 0.8106\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4324 - acc: 0.8320\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4679 - acc: 0.8063\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4563 - acc: 0.8063\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4697 - acc: 0.8145\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4581 - acc: 0.8072\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4621 - acc: 0.8090\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4281 - acc: 0.8183\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4559 - acc: 0.8184\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4256 - acc: 0.8349\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4283 - acc: 0.8256\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4270 - acc: 0.8270\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4365 - acc: 0.8196\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4590 - acc: 0.8217\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4375 - acc: 0.8310\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4300 - acc: 0.8261\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4440 - acc: 0.8103\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4460 - acc: 0.8244\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4429 - acc: 0.8028\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4169 - acc: 0.8344\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4454 - acc: 0.8139\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4489 - acc: 0.8298\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4342 - acc: 0.8234\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4343 - acc: 0.8221\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4263 - acc: 0.8249\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3978 - acc: 0.8494\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4366 - acc: 0.8314\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3839 - acc: 0.8420\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4235 - acc: 0.8300\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4257 - acc: 0.8265\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4040 - acc: 0.8456\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4238 - acc: 0.8171\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4182 - acc: 0.8365\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4237 - acc: 0.8267\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.4014 - acc: 0.8467\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4223 - acc: 0.8172\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3948 - acc: 0.8482\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4126 - acc: 0.8369\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4051 - acc: 0.8333\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3940 - acc: 0.8464\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3826 - acc: 0.8383\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3963 - acc: 0.8470\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3860 - acc: 0.8420\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3946 - acc: 0.8422\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3884 - acc: 0.8560\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3877 - acc: 0.8445\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3733 - acc: 0.8531\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3847 - acc: 0.8474\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3697 - acc: 0.8549\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3740 - acc: 0.8507\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4047 - acc: 0.8345\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3823 - acc: 0.8453\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3514 - acc: 0.8578\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3710 - acc: 0.8562\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3894 - acc: 0.8443\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3955 - acc: 0.8350\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3736 - acc: 0.8519\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3593 - acc: 0.8613\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3707 - acc: 0.8455\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3792 - acc: 0.8426\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3802 - acc: 0.8467\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3801 - acc: 0.8442\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3508 - acc: 0.8542\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3862 - acc: 0.8500\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3652 - acc: 0.8595\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3768 - acc: 0.8403\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3566 - acc: 0.8482\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3463 - acc: 0.8581\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3792 - acc: 0.8477\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3633 - acc: 0.8550\n",
            "26/26 [==============================] - 0s 8ms/step - loss: 0.2387 - acc: 0.9269\n",
            "processing fold # 4\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 6s 45ms/step - loss: 1.4229 - acc: 0.5102\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.9318 - acc: 0.5482\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.7396 - acc: 0.5614\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.6947 - acc: 0.6082\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.6513 - acc: 0.6986\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.6421 - acc: 0.6749\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.6296 - acc: 0.7036\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5946 - acc: 0.7188\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5980 - acc: 0.7258\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5801 - acc: 0.7462\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5661 - acc: 0.7467\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5964 - acc: 0.7351\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5652 - acc: 0.7222\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5498 - acc: 0.7516\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5767 - acc: 0.7394\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5293 - acc: 0.7717\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5692 - acc: 0.7537\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5444 - acc: 0.7470\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5399 - acc: 0.7562\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5489 - acc: 0.7604\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5291 - acc: 0.7639\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5326 - acc: 0.7603\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5255 - acc: 0.7617\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5392 - acc: 0.7587\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5116 - acc: 0.7712\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.5273 - acc: 0.7654\n",
            "Epoch 27/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5086 - acc: 0.7652\n",
            "Epoch 28/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5192 - acc: 0.7715\n",
            "Epoch 29/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4983 - acc: 0.7767\n",
            "Epoch 30/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.5038 - acc: 0.7703\n",
            "Epoch 31/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4970 - acc: 0.7901\n",
            "Epoch 32/100\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 0.5230 - acc: 0.7801\n",
            "Epoch 33/100\n",
            "107/107 [==============================] - 5s 48ms/step - loss: 0.4890 - acc: 0.7886\n",
            "Epoch 34/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.5205 - acc: 0.7720\n",
            "Epoch 35/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5028 - acc: 0.7798\n",
            "Epoch 36/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4683 - acc: 0.8118\n",
            "Epoch 37/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4721 - acc: 0.8069\n",
            "Epoch 38/100\n",
            "107/107 [==============================] - 5s 47ms/step - loss: 0.4615 - acc: 0.8148\n",
            "Epoch 39/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5051 - acc: 0.7694\n",
            "Epoch 40/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4779 - acc: 0.7973\n",
            "Epoch 41/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4573 - acc: 0.7988\n",
            "Epoch 42/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4602 - acc: 0.8079\n",
            "Epoch 43/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4788 - acc: 0.7780\n",
            "Epoch 44/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4863 - acc: 0.7804\n",
            "Epoch 45/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4496 - acc: 0.8269\n",
            "Epoch 46/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4755 - acc: 0.8052\n",
            "Epoch 47/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4446 - acc: 0.8195\n",
            "Epoch 48/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4674 - acc: 0.8209\n",
            "Epoch 49/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4526 - acc: 0.8090\n",
            "Epoch 50/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4492 - acc: 0.8107\n",
            "Epoch 51/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4523 - acc: 0.8008\n",
            "Epoch 52/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4671 - acc: 0.8077\n",
            "Epoch 53/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4370 - acc: 0.8246\n",
            "Epoch 54/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4731 - acc: 0.8160\n",
            "Epoch 55/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4483 - acc: 0.8108\n",
            "Epoch 56/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4318 - acc: 0.8295\n",
            "Epoch 57/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4452 - acc: 0.8062\n",
            "Epoch 58/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4354 - acc: 0.8111\n",
            "Epoch 59/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4308 - acc: 0.8151\n",
            "Epoch 60/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4177 - acc: 0.8446\n",
            "Epoch 61/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4389 - acc: 0.8086\n",
            "Epoch 62/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4318 - acc: 0.8244\n",
            "Epoch 63/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4173 - acc: 0.8382\n",
            "Epoch 64/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4313 - acc: 0.8279\n",
            "Epoch 65/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4023 - acc: 0.8368\n",
            "Epoch 66/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4370 - acc: 0.8243\n",
            "Epoch 67/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4307 - acc: 0.8183\n",
            "Epoch 68/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4482 - acc: 0.8076\n",
            "Epoch 69/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4389 - acc: 0.8213\n",
            "Epoch 70/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4058 - acc: 0.8444\n",
            "Epoch 71/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4071 - acc: 0.8441\n",
            "Epoch 72/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4001 - acc: 0.8369\n",
            "Epoch 73/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4029 - acc: 0.8393\n",
            "Epoch 74/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.4319 - acc: 0.8184\n",
            "Epoch 75/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4026 - acc: 0.8255\n",
            "Epoch 76/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3871 - acc: 0.8439\n",
            "Epoch 77/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3963 - acc: 0.8435\n",
            "Epoch 78/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3852 - acc: 0.8372\n",
            "Epoch 79/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4091 - acc: 0.8366\n",
            "Epoch 80/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4152 - acc: 0.8408\n",
            "Epoch 81/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3809 - acc: 0.8480\n",
            "Epoch 82/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.4022 - acc: 0.8407\n",
            "Epoch 83/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3973 - acc: 0.8341\n",
            "Epoch 84/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3949 - acc: 0.8474\n",
            "Epoch 85/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4064 - acc: 0.8293\n",
            "Epoch 86/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3827 - acc: 0.8421\n",
            "Epoch 87/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3923 - acc: 0.8520\n",
            "Epoch 88/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.3849 - acc: 0.8463\n",
            "Epoch 89/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3869 - acc: 0.8363\n",
            "Epoch 90/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3975 - acc: 0.8391\n",
            "Epoch 91/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3865 - acc: 0.8485\n",
            "Epoch 92/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4071 - acc: 0.8276\n",
            "Epoch 93/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4007 - acc: 0.8375\n",
            "Epoch 94/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3554 - acc: 0.8669\n",
            "Epoch 95/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.4063 - acc: 0.8207\n",
            "Epoch 96/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3692 - acc: 0.8660\n",
            "Epoch 97/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3821 - acc: 0.8402\n",
            "Epoch 98/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.3876 - acc: 0.8551\n",
            "Epoch 99/100\n",
            "107/107 [==============================] - 5s 46ms/step - loss: 0.3848 - acc: 0.8506\n",
            "Epoch 100/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.3797 - acc: 0.8415\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.4332 - acc: 0.8327\n",
            "-----------------------------------------------------\n",
            "batch_size: \t 20\n",
            "num_epochs: \t 100\n",
            "units_per_layer: [32  64  128  128]\n",
            "optimizer: \t Adam\n",
            "learning_rate: \t 0.0001\n",
            "num_folds CV: \t 5\n",
            "-----------------------------------------------------\n",
            "processing fold # 0\n",
            "Epoch 1/100\n",
            "107/107 [==============================] - 6s 46ms/step - loss: 1.4210 - acc: 0.5615\n",
            "Epoch 2/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.9339 - acc: 0.5524\n",
            "Epoch 3/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.7531 - acc: 0.5955\n",
            "Epoch 4/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6923 - acc: 0.6326\n",
            "Epoch 5/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6524 - acc: 0.6884\n",
            "Epoch 6/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.6238 - acc: 0.7157\n",
            "Epoch 7/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5984 - acc: 0.7405\n",
            "Epoch 8/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5994 - acc: 0.7419\n",
            "Epoch 9/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5925 - acc: 0.7336\n",
            "Epoch 10/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5866 - acc: 0.7312\n",
            "Epoch 11/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5769 - acc: 0.7368\n",
            "Epoch 12/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5616 - acc: 0.7523\n",
            "Epoch 13/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5434 - acc: 0.7610\n",
            "Epoch 14/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5547 - acc: 0.7529\n",
            "Epoch 15/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5564 - acc: 0.7466\n",
            "Epoch 16/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5470 - acc: 0.7526\n",
            "Epoch 17/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5653 - acc: 0.7511\n",
            "Epoch 18/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5269 - acc: 0.7887\n",
            "Epoch 19/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5429 - acc: 0.7603\n",
            "Epoch 20/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5531 - acc: 0.7548\n",
            "Epoch 21/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5052 - acc: 0.7969\n",
            "Epoch 22/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5048 - acc: 0.7713\n",
            "Epoch 23/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5136 - acc: 0.7737\n",
            "Epoch 24/100\n",
            "107/107 [==============================] - 5s 45ms/step - loss: 0.5263 - acc: 0.7736\n",
            "Epoch 25/100\n",
            "107/107 [==============================] - 5s 43ms/step - loss: 0.5040 - acc: 0.7923\n",
            "Epoch 26/100\n",
            "107/107 [==============================] - 5s 44ms/step - loss: 0.5013 - acc: 0.7809\n",
            "Epoch 27/100\n",
            " 47/107 [============>.................] - ETA: 2s - loss: 0.5066 - acc: 0.7806Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SheVoIOTYxfa"
      },
      "source": [
        "##Testing best k models: \r\n",
        "feeding the models with all available data and evaluating these one last time on the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VKyXizMIfAT",
        "outputId": "6c7982d6-b76e-409a-84b2-ba5712aa05ce"
      },
      "source": [
        "#full training set non-splitted \r\n",
        "print(train_images.shape)\r\n",
        "print(train_labels.shape)\r\n",
        "print(test_images.shape)\r\n",
        "print(test_labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2676, 150, 150, 1)\n",
            "(2676,)\n",
            "(336, 150, 150, 1)\n",
            "(336,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PFZGbUeZPI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "fab1e200-aed7-47dd-ca16-9e19616810c9"
      },
      "source": [
        "#top k models \r\n",
        "k = 3\r\n",
        "\r\n",
        "#load results  \r\n",
        "file_path = \"./results_full.csv\"\r\n",
        "data = pd.read_csv(file_path)\r\n",
        "\r\n",
        "#sort results by accuracies \r\n",
        "data.sort_values(by=[' mean_val_acc'], ascending=False, inplace=True)\r\n",
        "data.head()\r\n",
        "\r\n",
        "#init variables\r\n",
        "layers_number = 4\r\n",
        "batch_size = 0\r\n",
        "num_epochs = 0\r\n",
        "units_per_layer = []\r\n",
        "optimizer = 0\r\n",
        "learning_rate = 0\r\n",
        "dropout=True\r\n",
        "\r\n",
        "file_path_2 = \"./top3_results.csv\"\r\n",
        "with open(file_path_2, 'w') as f:\r\n",
        "  header = \"batch_size,num_epochs,units_per_layer,optimizer,learning_rate,mean_val_acc,mean_val_loss\\n\"\r\n",
        "  f.write(header)\r\n",
        "\r\n",
        "#get parameters values\r\n",
        "for index, row in data[:k].iterrows():\r\n",
        "  batch_size = int(row[\"batch_size\"])\r\n",
        "  num_epochs = int(row[\" num_epochs\"])\r\n",
        "  units_per_layer = ast.literal_eval(row[\" units_per_layer\"].replace(\"  \", \",\"))\r\n",
        "  optimizer = row[\" optimizer\"]\r\n",
        "  learning_rate = row[\" learning_rate\"]\r\n",
        "\r\n",
        "  if optimizer == \"Adam\":\r\n",
        "    opt = optimizers.Adam(learning_rate=float(learning_rate))\r\n",
        "  else: \r\n",
        "    opt = optimizers.RMSprop(learning_rate=float(learning_rate))\r\n",
        "\r\n",
        "  #build model\r\n",
        "  model = build_custom_model(layers_number, units_per_layer, batch_size, dropout, opt)\r\n",
        "\r\n",
        "  #fit model on all the available data\r\n",
        "  history = model.fit(train_datagen.flow(train_images, \r\n",
        "                                         train_labels,\r\n",
        "                                         batch_size=batch_size,\r\n",
        "                                         shuffle=False),\r\n",
        "                      epochs=num_epochs,\r\n",
        "                      steps_per_epoch=len(train_images) // batch_size,\r\n",
        "                      callbacks=[GarbageCollectorCallback()])\r\n",
        "  \r\n",
        "  #evaluate model on test set \r\n",
        "  test_loss, test_acc = model.evaluate(test_datagen.flow(test_images,\r\n",
        "                                                       test_labels,\r\n",
        "                                                       batch_size=batch_size,\r\n",
        "                                                       shuffle=False),\r\n",
        "                                      steps=len(test_images) // batch_size)\r\n",
        "\r\n",
        "  print(test_acc)\r\n",
        "\r\n",
        "  #save results on csv file \r\n",
        "  with open(file_path_2, 'a') as f:\r\n",
        "    row = row[\"batch_size\"] + \",\" \\\r\n",
        "        + row[\" num_epochs\"] + \",\" \\\r\n",
        "        + row[\" units_per_layer\"] + \",\" \\\r\n",
        "        + row[\" optimizer\"] + \",\" \\\r\n",
        "        + row[\" learning_rate\"] + \",\" \\\r\n",
        "        + \"%0.4f\" % (test_acc) + \",\" \\\r\n",
        "        + \"%0.4f\" % (test_loss) + \"\\n\"\r\n",
        "    f.write(row)\r\n",
        "  \r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-4358921312bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#load results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./results_full.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#sort results by accuracies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    686\u001b[0m     )\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2008\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2011\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results_full.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ib4nzirrh6Jn",
        "outputId": "a64f2312-c0a6-4f3b-b6c1-1f5588883d0f"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>batch_size</th>\n",
              "      <th>num_epochs</th>\n",
              "      <th>units_per_layer</th>\n",
              "      <th>optimizer</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>mean_val_acc</th>\n",
              "      <th>mean_val_loss</th>\n",
              "      <th>num_folds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>[32  64  128  128]</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.8758</td>\n",
              "      <td>0.3278</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20</td>\n",
              "      <td>100</td>\n",
              "      <td>[32  64  128  128]</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.8754</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20</td>\n",
              "      <td>100</td>\n",
              "      <td>[32  64  128  256]</td>\n",
              "      <td>Adam</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.3279</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20</td>\n",
              "      <td>100</td>\n",
              "      <td>[32  64  128  256]</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.8719</td>\n",
              "      <td>0.3292</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>32</td>\n",
              "      <td>100</td>\n",
              "      <td>[32  64  128  128]</td>\n",
              "      <td>RMSprop</td>\n",
              "      <td>0.0001</td>\n",
              "      <td>0.8715</td>\n",
              "      <td>0.3324</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   batch_size   num_epochs  ...  mean_val_loss  num_folds \n",
              "6          32          100  ...         0.3278           5\n",
              "0          20          100  ...         0.3217           5\n",
              "3          20          100  ...         0.3279           5\n",
              "1          20          100  ...         0.3292           5\n",
              "4          32          100  ...         0.3324           5\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}